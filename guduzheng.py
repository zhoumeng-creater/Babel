import streamlit as st
import pandas as pd
import json
import re
import time
import requests
import datetime
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Any
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import threading
import io
import base64
import zipfile
import tempfile

# å¯é€‰å¯¼å…¥ - ExcelåŠŸèƒ½
EXCEL_AVAILABLE = False
try:
    from openpyxl import Workbook
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.chart import BarChart, Reference
    EXCEL_AVAILABLE = True
except ImportError:
    st.warning("âš ï¸ æ³¨æ„: æœªå®‰è£…openpyxlæ¨¡å—ï¼ŒExcelå¯¼å‡ºåŠŸèƒ½ä¸å¯ç”¨ã€‚è¦å¯ç”¨ExcelåŠŸèƒ½ï¼Œè¯·è¿è¡Œ: pip install openpyxl")

# é¡µé¢é…ç½®
st.set_page_config(page_title="å­¤ç‹¬ç—‡å„¿ç«¥AIæ¨¡æ‹Ÿå®éªŒå¹³å° - åŒ»å­¦æ ‡å‡†ç‰ˆ", layout="wide")

# APIé…ç½®
API_KEY = "sk-DQY3QAIcPGWTMfqZN1itL0qwl3y7ejrqyQwyGLyPom6TGz2v"  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„API Key
API_URL = "https://api.moonshot.cn/v1/chat/completions"

# åˆå§‹åŒ–session state
if 'experiment_records' not in st.session_state:
    st.session_state.experiment_records = []
if 'current_batch_results' not in st.session_state:
    st.session_state.current_batch_results = []
if 'experiment_progress' not in st.session_state:
    st.session_state.experiment_progress = {'current': 0, 'total': 0}

# åŸºäºDSM-5æ ‡å‡†çš„åœºæ™¯é…ç½®
CLINICAL_SCENE_CONFIG = {
    "ç»“æ„åŒ–æ•™å­¦ç¯å¢ƒ": {
        "roles": ["å­¤ç‹¬ç—‡å„¿ç«¥", "ç‰¹æ®Šæ•™è‚²è€å¸ˆ", "åŒç­åŒå­¦", "æ•™å­¦åŠ©ç†", "è¯„ä¼°å¸ˆ"],
        "target": "è§‚å¯Ÿå­¤ç‹¬ç—‡å„¿ç«¥åœ¨ç»“æ„åŒ–æ•™å­¦ç¯å¢ƒä¸­çš„ç¤¾äº¤æ²Ÿé€šè¡Œä¸ºå’Œé€‚åº”æ€§è¡¨ç°",
        "desc": "ğŸ« ç»“æ„åŒ–æ•™å­¦ç¯å¢ƒï¼ˆåŸºäºTEACCHæ•™å­¦æ³•ï¼‰",
        "activities": [
            "ä¸ªåˆ«åŒ–æ•™å­¦ä»»åŠ¡", "è§†è§‰æç¤ºå­¦ä¹ ", "ç¤¾äº¤æ•…äº‹è®­ç»ƒ", 
            "è½®æµæ´»åŠ¨ç»ƒä¹ ", "æ—¥ç¨‹è¡¨ä½¿ç”¨è®­ç»ƒ", "å·¥ä½œç³»ç»Ÿæ“ä½œ"
        ],
        "triggers": [
            "æ—¥ç¨‹çªç„¶æ”¹å˜", "æ–°ä»»åŠ¡å¼•å…¥", "ç¤¾äº¤è¦æ±‚å¢åŠ ", 
            "æ„Ÿå®˜åˆºæ¿€è¿‡è½½", "è§„åˆ™å˜åŒ–", "æ—¶é—´å‹åŠ›"
        ],
        "observation_points": [
            "å¯¹ç»“æ„åŒ–æç¤ºçš„ååº”", "ä»»åŠ¡è½¬æ¢èƒ½åŠ›", "ç¤¾äº¤ä¸»åŠ¨æ€§",
            "é‡å¤è¡Œä¸ºé¢‘ç‡", "æƒ…ç»ªè°ƒèŠ‚è¡¨ç°", "æ²Ÿé€šåŠŸèƒ½æ€§"
        ]
    },
    "è‡ªç„¶ç¤¾äº¤æƒ…å¢ƒ": {
        "roles": ["å­¤ç‹¬ç—‡å„¿ç«¥", "å…¸å‹å‘è‚²åŒä¼´", "ç¤¾äº¤æŠ€èƒ½æ²»ç–—å¸ˆ", "è§‚å¯Ÿå‘˜", "å®¶é•¿"],
        "target": "è¯„ä¼°å­¤ç‹¬ç—‡å„¿ç«¥åœ¨è‡ªç„¶ç¤¾äº¤ç¯å¢ƒä¸­çš„äº’åŠ¨æ¨¡å¼å’Œç¤¾äº¤è®¤çŸ¥èƒ½åŠ›",
        "desc": "ğŸ‘¥ è‡ªç„¶ç¤¾äº¤æƒ…å¢ƒï¼ˆåŒä¼´äº’åŠ¨è§‚å¯Ÿï¼‰", 
        "activities": [
            "è‡ªç”±æ¸¸æˆæ—¶é—´", "åˆä½œæ¸¸æˆä»»åŠ¡", "è§’è‰²æ‰®æ¼”æ¸¸æˆ",
            "åˆ†äº«æ´»åŠ¨", "å†²çªè§£å†³æƒ…å¢ƒ", "é›†ä½“è®¨è®º"
        ],
        "triggers": [
            "åŒä¼´æ‹’ç»", "æ¸¸æˆè§„åˆ™äº‰è®®", "æ³¨æ„åŠ›ç«äº‰",
            "èº«ä½“æ¥è§¦è¦æ±‚", "æƒ…ç»ªè¡¨è¾¾éœ€æ±‚", "å¸®åŠ©è¯·æ±‚"
        ],
        "observation_points": [
            "ç¤¾äº¤ä¸»åŠ¨å‘èµ·", "éè¯­è¨€æ²Ÿé€š", "æƒ…ç»ªç†è§£",
            "æ¸¸æˆæŠ€èƒ½", "å†²çªå¤„ç†", "å‹è°Šå»ºç«‹"
        ]
    },
    "æ„Ÿå®˜è°ƒèŠ‚ç¯å¢ƒ": {
        "roles": ["å­¤ç‹¬ç—‡å„¿ç«¥", "èŒä¸šæ²»ç–—å¸ˆ", "æ„Ÿç»Ÿè®­ç»ƒå¸ˆ", "æŠ¤ç†äººå‘˜", "è¯„ä¼°ä¸“å®¶"],
        "target": "è§‚å¯Ÿå­¤ç‹¬ç—‡å„¿ç«¥çš„æ„Ÿå®˜å¤„ç†æ¨¡å¼å’Œè‡ªæˆ‘è°ƒèŠ‚ç­–ç•¥",
        "desc": "ğŸŒˆ æ„Ÿå®˜è°ƒèŠ‚ç¯å¢ƒï¼ˆæ„Ÿè§‰ç»Ÿåˆè¯„ä¼°ï¼‰",
        "activities": [
            "æ„Ÿå®˜æ¢ç´¢æ´»åŠ¨", "æ·±å‹è§‰è¾“å…¥", "å‰åº­åˆºæ¿€è®­ç»ƒ",
            "ç²¾ç»†åŠ¨ä½œç»ƒä¹ ", "æ„Ÿå®˜ä¼‘æ¯æ—¶é—´", "é€‚åº”æ€§è¡Œä¸ºè®­ç»ƒ"
        ],
        "triggers": [
            "å™ªéŸ³åˆºæ¿€", "å…‰çº¿å˜åŒ–", "è´¨åœ°å˜åŒ–",
            "è¿åŠ¨è¦æ±‚", "æ‹¥æŒ¤ç¯å¢ƒ", "å¤šé‡æ„Ÿå®˜è¾“å…¥"
        ],
        "observation_points": [
            "æ„Ÿå®˜å¯»æ±‚è¡Œä¸º", "æ„Ÿå®˜é€ƒé¿ååº”", "è‡ªæˆ‘è°ƒèŠ‚ç­–ç•¥",
            "é€‚åº”æ€§è¡Œä¸º", "æ³¨æ„åŠ›é›†ä¸­", "æƒ…ç»ªç¨³å®šæ€§"
        ]
    },
    "æ—¥å¸¸ç”Ÿæ´»æŠ€èƒ½": {
        "roles": ["å­¤ç‹¬ç—‡å„¿ç«¥", "ç”Ÿæ´»æŠ€èƒ½è®­ç»ƒå¸ˆ", "å®¶åº­æˆå‘˜", "åº·å¤å¸ˆ", "è¡Œä¸ºåˆ†æå¸ˆ"],
        "target": "è¯„ä¼°å­¤ç‹¬ç—‡å„¿ç«¥åœ¨æ—¥å¸¸ç”Ÿæ´»æŠ€èƒ½æ–¹é¢çš„ç‹¬ç«‹æ€§å’Œé€‚åº”èƒ½åŠ›",
        "desc": "ğŸ  æ—¥å¸¸ç”Ÿæ´»æŠ€èƒ½è®­ç»ƒç¯å¢ƒ",
        "activities": [
            "è‡ªç†æŠ€èƒ½ç»ƒä¹ ", "å®¶åŠ¡å‚ä¸", "è´­ç‰©æ¨¡æ‹Ÿ",
            "æ—¶é—´ç®¡ç†", "å®‰å…¨æ„è¯†è®­ç»ƒ", "ç¤¾åŒºé€‚åº”"
        ],
        "triggers": [
            "ç¨‹åºè¢«æ‰“æ–­", "æ–°ç¯å¢ƒé€‚åº”", "é€‰æ‹©è¦æ±‚",
            "æ—¶é—´é™åˆ¶", "ç‹¬ç«‹è¦æ±‚", "é—®é¢˜è§£å†³éœ€æ±‚"
        ],
        "observation_points": [
            "ç‹¬ç«‹æ€§æ°´å¹³", "æŒ‡ä»¤ç†è§£", "é—®é¢˜è§£å†³",
            "çµæ´»æ€§è¡¨ç°", "å®‰å…¨æ„è¯†", "è‡ªæˆ‘å€¡å¯¼"
        ]
    },
    "è¯­è¨€æ²Ÿé€šè¯„ä¼°": {
        "roles": ["å­¤ç‹¬ç—‡å„¿ç«¥", "è¯­è¨€æ²»ç–—å¸ˆ", "æ²Ÿé€šä¼™ä¼´", "è¯„ä¼°å¸ˆ", "æŠ€æœ¯æ”¯æŒ"],
        "target": "ä¸“é—¨è¯„ä¼°å­¤ç‹¬ç—‡å„¿ç«¥çš„è¯­è¨€æ²Ÿé€šèƒ½åŠ›å’Œæ›¿ä»£æ²Ÿé€šä½¿ç”¨",
        "desc": "ğŸ’¬ è¯­è¨€æ²Ÿé€šä¸“é¡¹è¯„ä¼°ç¯å¢ƒ",
        "activities": [
            "è¯­è¨€è¡¨è¾¾è®­ç»ƒ", "ç†è§£èƒ½åŠ›æµ‹è¯•", "éè¯­è¨€æ²Ÿé€š",
            "AACè®¾å¤‡ä½¿ç”¨", "ç¤¾äº¤è¯­è¨€ç»ƒä¹ ", "å™äº‹èƒ½åŠ›è¯„ä¼°"
        ],
        "triggers": [
            "å¤æ‚æŒ‡ä»¤", "æŠ½è±¡æ¦‚å¿µ", "æƒ…ç»ªè¡¨è¾¾è¦æ±‚",
            "ç¤¾äº¤è¯­è¨€éœ€æ±‚", "æ–°è¯æ±‡å­¦ä¹ ", "è¯­ç”¨æŠ€èƒ½æŒ‘æˆ˜"
        ],
        "observation_points": [
            "è¡¨è¾¾æ€§è¯­è¨€", "æ¥å—æ€§è¯­è¨€", "è¯­ç”¨æŠ€èƒ½",
            "éè¯­è¨€æ²Ÿé€š", "æ²Ÿé€šæ„å›¾", "å¯¹è¯æŠ€èƒ½"
        ]
    }
}

# åŸºäºåŒ»å­¦æ ‡å‡†çš„å­¤ç‹¬ç—‡ä¸¥é‡ç¨‹åº¦åˆ†çº§
CLINICAL_AUTISM_PROFILES = {
    "éœ€è¦æ”¯æŒï¼ˆè½»åº¦ï¼‰": {
        "social_communication": 3,  # ç¤¾äº¤æ²Ÿé€šç¼ºé™·ç¨‹åº¦ (1-5, 5ä¸ºæœ€ä¸¥é‡)
        "restricted_repetitive": 2,  # åˆ»æ¿é‡å¤è¡Œä¸ºç¨‹åº¦
        "sensory_processing": 3,     # æ„Ÿå®˜å¤„ç†å¼‚å¸¸
        "cognitive_function": 4,     # è®¤çŸ¥åŠŸèƒ½æ°´å¹³
        "adaptive_behavior": 3,      # é€‚åº”è¡Œä¸ºèƒ½åŠ›
        "language_level": 4,         # è¯­è¨€å‘å±•æ°´å¹³
        "special_interests": "æ•°å­¦è®¡ç®—ã€äº¤é€šå·¥å…·ã€åœ°å›¾",
        "support_needs": "æœ€å°æ”¯æŒ",
        "dsm5_severity": "éœ€è¦æ”¯æŒ"
    },
    "éœ€è¦å¤§é‡æ”¯æŒï¼ˆä¸­åº¦ï¼‰": {
        "social_communication": 4,
        "restricted_repetitive": 4,
        "sensory_processing": 4,
        "cognitive_function": 2,
        "adaptive_behavior": 2,
        "language_level": 2,
        "special_interests": "æ—‹è½¬ç‰©ä½“ã€ç‰¹å®šéŸ³ä¹ã€é‡å¤åŠ¨ä½œ",
        "support_needs": "å¤§é‡æ”¯æŒ",
        "dsm5_severity": "éœ€è¦å¤§é‡æ”¯æŒ"
    },
    "éœ€è¦éå¸¸å¤§é‡æ”¯æŒï¼ˆé‡åº¦ï¼‰": {
        "social_communication": 5,
        "restricted_repetitive": 5,
        "sensory_processing": 5,
        "cognitive_function": 1,
        "adaptive_behavior": 1,
        "language_level": 1,
        "special_interests": "å…‰å½±å˜åŒ–ã€è‡ªæˆ‘åˆºæ¿€è¡Œä¸ºã€é‡å¤å‘å£°",
        "support_needs": "éå¸¸å¤§é‡æ”¯æŒ",
        "dsm5_severity": "éœ€è¦éå¸¸å¤§é‡æ”¯æŒ"
    },
    "é˜¿æ–¯ä¼¯æ ¼æ ·è¡¨ç°": {
        "social_communication": 3,
        "restricted_repetitive": 3,
        "sensory_processing": 4,
        "cognitive_function": 5,
        "adaptive_behavior": 3,
        "language_level": 4,
        "special_interests": "ç§‘å­¦ã€å†å²ã€ç¼–ç¨‹ã€æ”¶é›†",
        "support_needs": "éƒ¨åˆ†æ”¯æŒ",
        "dsm5_severity": "éœ€è¦æ”¯æŒï¼ˆé«˜åŠŸèƒ½ï¼‰"
    },
    "å…±æ‚£ADHD": {
        "social_communication": 3,
        "restricted_repetitive": 3,
        "sensory_processing": 4,
        "cognitive_function": 3,
        "adaptive_behavior": 2,
        "language_level": 3,
        "special_interests": "è¿åŠ¨ã€æ¸¸æˆã€åŠ¨æ€æ´»åŠ¨",
        "support_needs": "ä¸­ç­‰æ”¯æŒ",
        "dsm5_severity": "éœ€è¦æ”¯æŒ+æ³¨æ„ç¼ºé™·å¤šåŠ¨éšœç¢"
    }
}

# åŸºäºCARSã€ABCã€SCQç­‰é‡è¡¨çš„ç»¼åˆè¯„ä¼°æŒ‡æ ‡
CLINICAL_EVALUATION_METRICS = {
    "ç¤¾äº¤äº’åŠ¨è´¨é‡": {
        "description": "ç¤¾ä¼šæƒ…æ„Ÿäº’æƒ æ€§ç¼ºé™·çš„ç¨‹åº¦",
        "subscales": {
            "ç¤¾äº¤å‘èµ·": "ä¸»åŠ¨å‘èµ·ç¤¾äº¤äº’åŠ¨çš„é¢‘ç‡å’Œè´¨é‡",
            "ç¤¾äº¤ååº”": "å¯¹ä»–äººç¤¾äº¤ä¿¡å·çš„ååº”æ€§å’Œé€‚å½“æ€§", 
            "ç¤¾äº¤ç»´æŒ": "ç»´æŒç¤¾äº¤äº’åŠ¨çš„èƒ½åŠ›å’ŒæŒç»­æ€§",
            "æƒ…æ„Ÿåˆ†äº«": "åˆ†äº«æƒ…æ„Ÿå’Œå…´è¶£çš„èƒ½åŠ›"
        },
        "scoring_criteria": {
            5: "ä¸¥é‡ç¼ºé™· - æå°‘ä¸»åŠ¨ç¤¾äº¤ï¼Œä¸å›åº”ç¤¾äº¤ä¿¡å·",
            4: "æ˜æ˜¾ç¼ºé™· - ç¤¾äº¤å‘èµ·æœ‰é™ï¼Œååº”ä¸å½“",
            3: "ä¸­åº¦ç¼ºé™· - å¯ä»¥ç¤¾äº¤ä½†è´¨é‡å·®ï¼Œéœ€è¦æ”¯æŒ", 
            2: "è½»åº¦ç¼ºé™· - åŸºæœ¬ç¤¾äº¤èƒ½åŠ›ï¼Œå¶æœ‰å›°éš¾",
            1: "æ— æ˜æ˜¾ç¼ºé™· - ç¤¾äº¤äº’åŠ¨åŸºæœ¬æ­£å¸¸"
        }
    },
    "æ²Ÿé€šäº¤æµèƒ½åŠ›": {
        "description": "è¯­è¨€å’Œéè¯­è¨€æ²Ÿé€šçš„ç¼ºé™·ç¨‹åº¦",
        "subscales": {
            "è¡¨è¾¾æ€§æ²Ÿé€š": "è¯­è¨€æˆ–æ›¿ä»£æ–¹å¼è¡¨è¾¾éœ€æ±‚å’Œæƒ³æ³•çš„èƒ½åŠ›",
            "æ¥å—æ€§æ²Ÿé€š": "ç†è§£ä»–äººè¯­è¨€å’Œéè¯­è¨€ä¿¡æ¯çš„èƒ½åŠ›",
            "ç¤¾äº¤æ€§æ²Ÿé€š": "åœ¨ç¤¾äº¤æƒ…å¢ƒä¸­ä½¿ç”¨æ²Ÿé€šçš„è¯­ç”¨æŠ€èƒ½",
            "éè¯­è¨€æ²Ÿé€š": "çœ¼ç¥ã€æ‰‹åŠ¿ã€è¡¨æƒ…ç­‰éè¯­è¨€æ²Ÿé€šçš„ä½¿ç”¨"
        },
        "scoring_criteria": {
            5: "ä¸¥é‡ç¼ºé™· - æ— åŠŸèƒ½æ€§æ²Ÿé€šæˆ–ä»…æœ‰å°‘é‡å•è¯",
            4: "æ˜æ˜¾ç¼ºé™· - æœ‰é™çš„åŠŸèƒ½æ€§è¯­è¨€ï¼Œè¯­ç”¨ä¸¥é‡å—æŸ",
            3: "ä¸­åº¦ç¼ºé™· - åŸºæœ¬æ²Ÿé€šèƒ½åŠ›ä½†è¯­ç”¨æŠ€èƒ½å·®",
            2: "è½»åº¦ç¼ºé™· - æ²Ÿé€šåŸºæœ¬æµç•…ä½†æœ‰ç¤¾äº¤è¯­ç”¨å›°éš¾",
            1: "æ— æ˜æ˜¾ç¼ºé™· - æ²Ÿé€šèƒ½åŠ›å¹´é¾„é€‚å®œ"
        }
    },
    "åˆ»æ¿é‡å¤è¡Œä¸º": {
        "description": "é™åˆ¶æ€§é‡å¤è¡Œä¸ºæ¨¡å¼çš„ä¸¥é‡ç¨‹åº¦",
        "subscales": {
            "åˆ»æ¿åŠ¨ä½œ": "é‡å¤çš„è¿åŠ¨æ¨¡å¼æˆ–åŠ¨ä½œçš„é¢‘ç‡å’Œå¼ºåº¦",
            "ä»ªå¼åŒ–è¡Œä¸º": "åšæŒå›ºå®šç¨‹åºå’Œä»ªå¼çš„ç¨‹åº¦",
            "ç‹­éš˜å…´è¶£": "å¼‚å¸¸å¼ºçƒˆæˆ–é™åˆ¶æ€§å…´è¶£çš„ç¨‹åº¦",
            "æ„Ÿå®˜è¡Œä¸º": "å¼‚å¸¸æ„Ÿå®˜å…´è¶£æˆ–æ„Ÿå®˜å¯»æ±‚/é€ƒé¿è¡Œä¸º"
        },
        "scoring_criteria": {
            5: "ä¸¥é‡ç¨‹åº¦ - é‡å¤è¡Œä¸ºä¸¥é‡å¹²æ‰°åŠŸèƒ½",
            4: "æ˜æ˜¾ç¨‹åº¦ - é‡å¤è¡Œä¸ºæ˜æ˜¾ä¸”å½±å“æ—¥å¸¸æ´»åŠ¨",
            3: "ä¸­åº¦ç¨‹åº¦ - æœ‰æ˜æ˜¾é‡å¤è¡Œä¸ºä½†å¯ä»¥ä¸­æ–­",
            2: "è½»åº¦ç¨‹åº¦ - å¶æœ‰é‡å¤è¡Œä¸ºï¼Œå½±å“è½»å¾®",
            1: "æ— æˆ–æè½»å¾® - å¾ˆå°‘é‡å¤è¡Œä¸º"
        }
    },
    "æ„Ÿå®˜å¤„ç†èƒ½åŠ›": {
        "description": "æ„Ÿå®˜ä¿¡æ¯å¤„ç†çš„å¼‚å¸¸ç¨‹åº¦",
        "subscales": {
            "æ„Ÿå®˜è¿‡æ•": "å¯¹æ„Ÿå®˜åˆºæ¿€è¿‡åº¦æ•æ„Ÿçš„ç¨‹åº¦",
            "æ„Ÿå®˜å¯»æ±‚": "ä¸»åŠ¨å¯»æ±‚æ„Ÿå®˜åˆºæ¿€çš„è¡Œä¸º",
            "æ„Ÿå®˜è°ƒèŠ‚": "è°ƒèŠ‚æ„Ÿå®˜è¾“å…¥çš„èƒ½åŠ›",
            "æ„Ÿå®˜æ•´åˆ": "æ•´åˆå¤šç§æ„Ÿå®˜ä¿¡æ¯çš„èƒ½åŠ›"
        },
        "scoring_criteria": {
            5: "ä¸¥é‡å¼‚å¸¸ - æ„Ÿå®˜é—®é¢˜ä¸¥é‡å½±å“æ—¥å¸¸åŠŸèƒ½",
            4: "æ˜æ˜¾å¼‚å¸¸ - æ„Ÿå®˜æ•æ„Ÿæ€§æ˜æ˜¾ä¸”ç»å¸¸å‡ºç°",
            3: "ä¸­åº¦å¼‚å¸¸ - æœ‰æ„Ÿå®˜å¤„ç†å›°éš¾éœ€è¦ç­–ç•¥æ”¯æŒ",
            2: "è½»åº¦å¼‚å¸¸ - å¶æœ‰æ„Ÿå®˜æ•æ„Ÿä½†å¯ä»¥é€‚åº”",
            1: "æ­£å¸¸èŒƒå›´ - æ„Ÿå®˜å¤„ç†åŸºæœ¬æ­£å¸¸"
        }
    },
    "æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚": {
        "description": "æƒ…ç»ªè¯†åˆ«ã€è¡¨è¾¾å’Œè°ƒèŠ‚çš„èƒ½åŠ›",
        "subscales": {
            "æƒ…ç»ªè¯†åˆ«": "è¯†åˆ«è‡ªå·±å’Œä»–äººæƒ…ç»ªçš„èƒ½åŠ›",
            "æƒ…ç»ªè¡¨è¾¾": "é€‚å½“è¡¨è¾¾æƒ…ç»ªçš„èƒ½åŠ›",
            "æƒ…ç»ªè°ƒèŠ‚": "ç®¡ç†å’Œè°ƒèŠ‚æƒ…ç»ªçš„ç­–ç•¥å’Œèƒ½åŠ›",
            "è¡Œä¸ºæ§åˆ¶": "æ§åˆ¶å†²åŠ¨å’Œä¸å½“è¡Œä¸ºçš„èƒ½åŠ›"
        },
        "scoring_criteria": {
            5: "ä¸¥é‡å›°éš¾ - æƒ…ç»ªå¤±è°ƒé¢‘ç¹ï¼Œè‡ªä¼¤æˆ–æ”»å‡»è¡Œä¸º",
            4: "æ˜æ˜¾å›°éš¾ - ç»å¸¸æƒ…ç»ªçˆ†å‘ï¼Œè°ƒèŠ‚èƒ½åŠ›å·®",
            3: "ä¸­åº¦å›°éš¾ - æƒ…ç»ªè°ƒèŠ‚æœ‰å›°éš¾ä½†æœ‰æ”¹å–„ç©ºé—´",
            2: "è½»åº¦å›°éš¾ - å¤§å¤šæ•°æ—¶å€™èƒ½è°ƒèŠ‚æƒ…ç»ª",
            1: "è‰¯å¥½ - æƒ…ç»ªè°ƒèŠ‚å¹´é¾„é€‚å®œ"
        }
    },
    "è®¤çŸ¥é€‚åº”åŠŸèƒ½": {
        "description": "è®¤çŸ¥åŠŸèƒ½å’Œé€‚åº”æ€§è¡Œä¸ºçš„æ°´å¹³",
        "subscales": {
            "å­¦ä¹ èƒ½åŠ›": "å­¦ä¹ æ–°æŠ€èƒ½å’Œæ¦‚å¿µçš„èƒ½åŠ›",
            "é—®é¢˜è§£å†³": "è§£å†³æ—¥å¸¸é—®é¢˜çš„èƒ½åŠ›",
            "æ‰§è¡ŒåŠŸèƒ½": "è®¡åˆ’ã€ç»„ç»‡å’Œçµæ´»æ€ç»´çš„èƒ½åŠ›",
            "é€‚åº”æ€§è¡Œä¸º": "åœ¨æ—¥å¸¸ç¯å¢ƒä¸­ç‹¬ç«‹åŠŸèƒ½çš„èƒ½åŠ›"
        },
        "scoring_criteria": {
            5: "é‡åº¦ç¼ºé™· - æ˜æ˜¾æ™ºåŠ›éšœç¢ï¼Œé€‚åº”èƒ½åŠ›æå·®",
            4: "ä¸­åº¦ç¼ºé™· - å­¦ä¹ å›°éš¾ï¼Œéœ€è¦å¤§é‡æ”¯æŒ",
            3: "è½»åº¦ç¼ºé™· - å­¦ä¹ èƒ½åŠ›æœ‰é™ä½†å¯è®­ç»ƒ",
            2: "è¾¹ç¼˜æ°´å¹³ - è®¤çŸ¥èƒ½åŠ›åŸºæœ¬æ­£å¸¸ä½†æœ‰å¼±é¡¹",
            1: "æ­£å¸¸èŒƒå›´ - è®¤çŸ¥å’Œé€‚åº”åŠŸèƒ½å¹´é¾„é€‚å®œ"
        }
    }
}

def call_kimi_with_profile(prompt, autism_profile, max_retries=3):
    """è°ƒç”¨AI APIç”Ÿæˆå¯¹è¯ï¼Œå¸¦é‡è¯•æœºåˆ¶ï¼ŒåŸºäºä¸´åºŠç‰¹å¾æè¿°"""
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    profile_description = f"""
    å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠç‰¹å¾é…ç½®ï¼ˆåŸºäºDSM-5æ ‡å‡†ï¼‰ï¼š
    - DSM-5ä¸¥é‡ç¨‹åº¦: {autism_profile.get('dsm5_severity', 'æœªæŒ‡å®š')}
    - ç¤¾äº¤æ²Ÿé€šç¼ºé™·ç¨‹åº¦: {autism_profile['social_communication']}/5 (5ä¸ºæœ€ä¸¥é‡)
    - åˆ»æ¿é‡å¤è¡Œä¸ºç¨‹åº¦: {autism_profile['restricted_repetitive']}/5
    - æ„Ÿå®˜å¤„ç†å¼‚å¸¸: {autism_profile['sensory_processing']}/5
    - è®¤çŸ¥åŠŸèƒ½æ°´å¹³: {autism_profile['cognitive_function']}/5 (1ä¸ºé‡åº¦éšœç¢ï¼Œ5ä¸ºæ­£å¸¸)
    - é€‚åº”è¡Œä¸ºèƒ½åŠ›: {autism_profile['adaptive_behavior']}/5
    - è¯­è¨€å‘å±•æ°´å¹³: {autism_profile['language_level']}/5
    - ç‰¹æ®Šå…´è¶£é¢†åŸŸ: {autism_profile['special_interests']}
    - æ‰€éœ€æ”¯æŒæ°´å¹³: {autism_profile.get('support_needs', 'æœªæŒ‡å®š')}
    """
    
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¤ç‹¬ç—‡ä¸´åºŠè¡Œä¸ºä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹DSM-5è¯Šæ–­æ ‡å‡†å’Œä¸´åºŠç‰¹å¾æ¥æ¨¡æ‹Ÿå­¤ç‹¬ç—‡å„¿ç«¥çš„è¡Œä¸ºï¼š\n"
        + profile_description +
        "\næ ¸å¿ƒç—‡çŠ¶è¡¨ç°è¦æ±‚ï¼š"
        "\n1. ç¤¾äº¤æ²Ÿé€šç¼ºé™·ï¼šæ ¹æ®ä¸¥é‡ç¨‹åº¦å±•ç°çœ¼ç¥å›é¿ã€ç¤¾äº¤å‘èµ·å›°éš¾ã€æƒ…æ„Ÿåˆ†äº«å—é™ç­‰"
        "\n2. åˆ»æ¿é‡å¤è¡Œä¸ºï¼šä½“ç°é‡å¤åŠ¨ä½œã€ä»ªå¼åŒ–è¡Œä¸ºã€ç‹­éš˜å…´è¶£ã€æ„Ÿå®˜å¼‚å¸¸ç­‰"
        "\n3. æ„Ÿå®˜å¤„ç†ï¼šæ ¹æ®æ•æ„Ÿåº¦æ˜¾ç¤ºè¿‡æ•ã€å¯»æ±‚æˆ–é€ƒé¿ç‰¹å®šæ„Ÿå®˜åˆºæ¿€"
        "\n4. è¯­è¨€ç‰¹ç‚¹ï¼šæ ¹æ®è¯­è¨€æ°´å¹³å±•ç°å›å£°å¼è¯­è¨€ã€å­—é¢ç†è§£ã€è¯­ç”¨å›°éš¾ç­‰"
        "\n5. æƒ…ç»ªè°ƒèŠ‚ï¼šæ ¹æ®è°ƒèŠ‚èƒ½åŠ›æ˜¾ç¤ºæƒ…ç»ªçˆ†å‘ã€è‡ªæˆ‘å®‰æŠšè¡Œä¸ºç­‰"
        "\nä¸¥æ ¼æ ¼å¼ï¼š\"è§’è‰²å:å‘è¨€å†…å®¹\"ã€‚æ¯å¥æ¢è¡Œï¼Œè¯­è¨€çœŸå®è‡ªç„¶ï¼Œè¡Œä¸ºç¬¦åˆä¸´åºŠè§‚å¯Ÿç‰¹ç‚¹ã€‚"
    )
    
    payload = {
        "model": "moonshot-v1-8k",
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.6,
        "max_tokens": 2048
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
            
            if response.status_code == 200:
                return response.json()['choices'][0]['message']['content']
            elif response.status_code == 429:
                wait_time = (attempt + 1) * 5
                print(f"APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                if 'st' in globals():
                    st.warning(f"â±ï¸ APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…{wait_time}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
                continue
            else:
                return f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}"
                
        except requests.exceptions.Timeout:
            if attempt == max_retries - 1:
                return "APIè°ƒç”¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•"
            time.sleep(2)
            continue
        except Exception as e:
            if attempt == max_retries - 1:
                return f"ç½‘ç»œé”™è¯¯: {str(e)}"
            time.sleep(2)
            continue
    
    return "APIè°ƒç”¨å¤±è´¥ï¼šè¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°"

def clinical_evaluate_dialogue(dialogue, autism_profile, scene_info):
    """åŸºäºä¸´åºŠæ ‡å‡†è¯„ä¼°å¯¹è¯è´¨é‡"""
    lines = dialogue.split('\n')
    autism_child_lines = [line for line in lines if 'å­¤ç‹¬ç—‡å„¿ç«¥' in line]
    
    if not autism_child_lines:
        return {metric: 0.0 for metric in CLINICAL_EVALUATION_METRICS.keys()}
    
    evaluation_scores = {}
    
    # ç¤¾äº¤äº’åŠ¨è´¨é‡è¯„ä¼°
    social_base = autism_profile['social_communication']
    interaction_indicators = 0
    
    # æ£€æŸ¥ç¤¾äº¤å‘èµ·è¡Œä¸º
    proactive_social = len([line for line in autism_child_lines if any(word in line for word in ['æˆ‘æƒ³', 'æˆ‘ä»¬ä¸€èµ·', 'å¯ä»¥å—', 'ä½ å¥½'])])
    if proactive_social > 0:
        interaction_indicators += 1
    
    # æ£€æŸ¥ç¤¾äº¤ååº”
    responsive_social = len([line for line in autism_child_lines if any(word in line for word in ['å¥½çš„', 'æ˜¯çš„', 'ä¸è¦', 'è°¢è°¢'])])
    if responsive_social > len(autism_child_lines) * 0.3:
        interaction_indicators += 1
    
    social_score = social_base - (interaction_indicators * 0.5)
    evaluation_scores["ç¤¾äº¤äº’åŠ¨è´¨é‡"] = max(1, min(5, social_score))
    
    # æ²Ÿé€šäº¤æµèƒ½åŠ›è¯„ä¼°
    comm_base = autism_profile['social_communication']
    communication_quality = 0
    
    # æ£€æŸ¥è¯­è¨€åŠŸèƒ½æ€§
    functional_language = len([line for line in autism_child_lines if any(word in line for word in ['æˆ‘è¦', 'å¸®åŠ©', 'ä¸æ‡‚', 'ä¸ºä»€ä¹ˆ'])])
    if functional_language > 0:
        communication_quality += 1
    
    # æ£€æŸ¥å›å£°å¼è¯­è¨€ï¼ˆé‡å¤ä»–äººè¯è¯­ï¼‰
    echolalia_signs = len([line for line in autism_child_lines if '?' in line and len(line.split()) < 5])
    if echolalia_signs > 0:
        communication_quality -= 0.5
    
    # æ ¹æ®è¯­è¨€æ°´å¹³è°ƒæ•´
    language_modifier = (autism_profile['language_level'] - 3) * 0.3
    comm_score = comm_base - communication_quality + language_modifier
    evaluation_scores["æ²Ÿé€šäº¤æµèƒ½åŠ›"] = max(1, min(5, comm_score))
    
    # åˆ»æ¿é‡å¤è¡Œä¸ºè¯„ä¼°
    repetitive_base = autism_profile['restricted_repetitive']
    repetitive_indicators = 0
    
    # æ£€æŸ¥é‡å¤è¡¨è¾¾
    repeated_phrases = len(set(autism_child_lines)) / len(autism_child_lines) if autism_child_lines else 1
    if repeated_phrases < 0.7:  # å¦‚æœé‡å¤ç‡é«˜
        repetitive_indicators += 1
    
    # æ£€æŸ¥ç‰¹æ®Šå…´è¶£ç›¸å…³è¡¨è¾¾
    special_interest_mentions = len([line for line in autism_child_lines 
                                   if any(interest.lower() in line.lower() 
                                         for interest in autism_profile['special_interests'].split('ã€'))])
    if special_interest_mentions > len(autism_child_lines) * 0.3:
        repetitive_indicators += 1
    
    repetitive_score = repetitive_base + (repetitive_indicators * 0.5)
    evaluation_scores["åˆ»æ¿é‡å¤è¡Œä¸º"] = max(1, min(5, repetitive_score))
    
    # æ„Ÿå®˜å¤„ç†èƒ½åŠ›è¯„ä¼°  
    sensory_base = autism_profile['sensory_processing']
    sensory_responses = 0
    
    # æ£€æŸ¥æ„Ÿå®˜ç›¸å…³ååº”
    sensory_words = ['å¤ªåµ', 'å¤ªäº®', 'ä¸å–œæ¬¢', 'å®³æ€•', 'ç–¼', 'èˆ’æœ']
    sensory_mentions = len([line for line in autism_child_lines 
                           if any(word in line for word in sensory_words)])
    if sensory_mentions > 0:
        sensory_responses = min(sensory_mentions * 0.3, 1.0)
    
    sensory_score = sensory_base - (sensory_responses * 0.5)
    evaluation_scores["æ„Ÿå®˜å¤„ç†èƒ½åŠ›"] = max(1, min(5, sensory_score))
    
    # æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚è¯„ä¼°
    emotion_base = autism_profile['social_communication']  # åŸºäºç¤¾äº¤æ²Ÿé€šç¼ºé™·æ¨æ–­æƒ…ç»ªè°ƒèŠ‚
    emotion_regulation = 0
    
    # æ£€æŸ¥æƒ…ç»ªè¡¨è¾¾
    emotion_words = ['å¼€å¿ƒ', 'éš¾è¿‡', 'ç”Ÿæ°”', 'å®³æ€•', 'ç€æ€¥', 'ä¸é«˜å…´']
    emotion_expressions = len([line for line in autism_child_lines 
                              if any(word in line for word in emotion_words)])
    if emotion_expressions > 0:
        emotion_regulation += 0.5
    
    # æ£€æŸ¥è°ƒèŠ‚ç­–ç•¥
    regulation_words = ['æˆ‘éœ€è¦', 'ä¼‘æ¯', 'å®‰é™', 'åœæ­¢']
    regulation_attempts = len([line for line in autism_child_lines 
                              if any(word in line for word in regulation_words)])
    if regulation_attempts > 0:
        emotion_regulation += 0.5
    
    emotion_score = emotion_base - emotion_regulation
    evaluation_scores["æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚"] = max(1, min(5, emotion_score))
    
    # è®¤çŸ¥é€‚åº”åŠŸèƒ½è¯„ä¼°
    cognitive_base = 6 - autism_profile['cognitive_function']  # è½¬æ¢è¯„åˆ†æ–¹å‘
    adaptation_quality = 0
    
    # æ£€æŸ¥é—®é¢˜è§£å†³å°è¯•
    problem_solving = len([line for line in autism_child_lines 
                          if any(word in line for word in ['æ€ä¹ˆåŠ', 'è¯•è¯•', 'æƒ³æƒ³', 'åŠæ³•'])])
    if problem_solving > 0:
        adaptation_quality += 0.5
    
    # æ£€æŸ¥å­¦ä¹ è¡¨ç°
    learning_indicators = len([line for line in autism_child_lines 
                              if any(word in line for word in ['å­¦ä¼š', 'çŸ¥é“äº†', 'æ˜ç™½', 'è®°ä½'])])
    if learning_indicators > 0:
        adaptation_quality += 0.5
    
    cognitive_score = cognitive_base - adaptation_quality
    evaluation_scores["è®¤çŸ¥é€‚åº”åŠŸèƒ½"] = max(1, min(5, cognitive_score))
    
    # æ·»åŠ éšæœºå˜å¼‚æ¨¡æ‹ŸçœŸå®è¯„ä¼°çš„ä¸ç¡®å®šæ€§
    for metric in evaluation_scores:
        variation = np.random.normal(0, 0.2)  # å°å¹…éšæœºå˜åŒ–
        evaluation_scores[metric] = max(1, min(5, evaluation_scores[metric] + variation))
        evaluation_scores[metric] = round(evaluation_scores[metric], 2)
    
    return evaluation_scores

def generate_experiment_batch(templates, scenes, num_experiments_per_combo=3):
    """ç”Ÿæˆæ‰¹é‡å®éªŒé…ç½®"""
    experiments = []
    experiment_counter = 0
    
    for template_name, profile in templates.items():
        for scene_name, scene_data in scenes.items():
            for activity in scene_data['activities'][:2]:
                for trigger in scene_data['triggers'][:2]:
                    for i in range(num_experiments_per_combo):
                        experiment_counter += 1
                        
                        # æ·»åŠ è½»å¾®ä¸´åºŠå˜å¼‚
                        varied_profile = profile.copy()
                        for key in ['social_communication', 'restricted_repetitive', 'sensory_processing']:
                            if key in varied_profile:
                                variation = np.random.randint(-1, 2)
                                varied_profile[key] = max(1, min(5, varied_profile[key] + variation))
                        
                        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
                        unique_id = f"CLIN_{experiment_counter:03d}_{template_name[:4]}_{scene_name[:4]}_{timestamp}"
                        
                        experiments.append({
                            'template': template_name,
                            'scene': scene_name,
                            'activity': activity,
                            'trigger': trigger,
                            'autism_profile': varied_profile,
                            'experiment_id': unique_id,
                            'batch_index': experiment_counter
                        })
    
    return experiments

def run_single_experiment(experiment_config):
    """è¿è¡Œå•ä¸ªå®éªŒ"""
    try:
        scene_data = CLINICAL_SCENE_CONFIG[experiment_config['scene']]
        
        # æ„å»ºåŸºäºä¸´åºŠè§‚å¯Ÿçš„prompt
        prompt = (
            f"ä¸´åºŠè§‚å¯Ÿæƒ…å¢ƒï¼š{experiment_config['scene']} - {experiment_config['activity']}\n"
            f"è§‚å¯Ÿè¦ç‚¹ï¼š{', '.join(scene_data['observation_points'][:3])}\n"
            f"è§¦å‘å› ç´ ï¼š{experiment_config['trigger']}\n"
            f"å‚ä¸è§’è‰²ï¼šå­¤ç‹¬ç—‡å„¿ç«¥ã€{scene_data['roles'][1]}ã€{scene_data['roles'][2]}\n"
            f"è¯·åŸºäºDSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡†ï¼Œæ¨¡æ‹Ÿè¯¥å„¿ç«¥åœ¨æ­¤æƒ…å¢ƒä¸‹çš„çœŸå®è¡Œä¸ºè¡¨ç°ã€‚\n"
            f"è¦æ±‚ï¼š15-20è½®å¯¹è¯ï¼Œä½“ç°æ ¸å¿ƒç—‡çŠ¶ï¼ˆç¤¾äº¤æ²Ÿé€šç¼ºé™·ã€åˆ»æ¿é‡å¤è¡Œä¸ºï¼‰ï¼Œ"
            f"è¯­è¨€å’Œè¡Œä¸ºç¬¦åˆè¯¥ä¸¥é‡ç¨‹åº¦çš„ä¸´åºŠç‰¹å¾ã€‚\n"
            f"æ ¼å¼ï¼š'è§’è‰²å:å†…å®¹'ï¼Œæ¯å¥æ¢è¡Œã€‚"
        )
        
        dialogue = call_kimi_with_profile(prompt, experiment_config['autism_profile'])
        
        # ä½¿ç”¨ä¸´åºŠæ ‡å‡†è¯„ä¼°
        evaluation_scores = clinical_evaluate_dialogue(
            dialogue, 
            experiment_config['autism_profile'], 
            CLINICAL_SCENE_CONFIG[experiment_config['scene']]
        )
        
        record = {
            'experiment_id': experiment_config['experiment_id'],
            'timestamp': datetime.datetime.now(),
            'template': experiment_config['template'],
            'scene': experiment_config['scene'],
            'activity': experiment_config['activity'],
            'trigger': experiment_config['trigger'],
            'autism_profile': experiment_config['autism_profile'],
            'dialogue': dialogue,
            'evaluation_scores': evaluation_scores,
            'clinical_observations': extract_clinical_observations(dialogue),
            'notes': f"ä¸´åºŠæ ‡å‡†è¯„ä¼° - {experiment_config['template']}"
        }
        
        return record
        
    except Exception as e:
        return {
            'experiment_id': experiment_config['experiment_id'],
            'timestamp': datetime.datetime.now(),
            'error': str(e),
            'template': experiment_config.get('template', 'unknown'),
            'scene': experiment_config.get('scene', 'unknown')
        }

def extract_clinical_observations(dialogue):
    """ä»å¯¹è¯ä¸­æå–ä¸´åºŠè§‚å¯Ÿè¦ç‚¹"""
    lines = dialogue.split('\n')
    autism_child_lines = [line for line in lines if 'å­¤ç‹¬ç—‡å„¿ç«¥' in line]
    
    observations = {
        "ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ": [],
        "è¯­è¨€æ²Ÿé€šç‰¹ç‚¹": [],
        "é‡å¤è¡Œä¸ºè¡¨ç°": [],
        "æ„Ÿå®˜ååº”": [],
        "æƒ…ç»ªè°ƒèŠ‚": []
    }
    
    for line in autism_child_lines:
        # ç¤¾äº¤è¡Œä¸ºè¯†åˆ«
        if any(word in line for word in ['ä½ å¥½', 'å†è§', 'ä¸€èµ·', 'æœ‹å‹']):
            observations["ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ"].append("ä¸»åŠ¨ç¤¾äº¤å°è¯•")
        elif any(word in line for word in ['ä¸è¦', 'ä¸å–œæ¬¢', 'èµ°å¼€']):
            observations["ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ"].append("ç¤¾äº¤å›é¿è¡Œä¸º")
        
        # è¯­è¨€ç‰¹ç‚¹è¯†åˆ«  
        if line.count('æ˜¯') > 2 or line.count('ä¸') > 2:
            observations["è¯­è¨€æ²Ÿé€šç‰¹ç‚¹"].append("å›å£°å¼è¯­è¨€ç‰¹å¾")
        if any(word in line for word in ['ä¸ºä»€ä¹ˆ', 'ä»€ä¹ˆæ—¶å€™', 'åœ¨å“ªé‡Œ']):
            observations["è¯­è¨€æ²Ÿé€šç‰¹ç‚¹"].append("ç–‘é—®å¥ä½¿ç”¨")
        
        # é‡å¤è¡Œä¸ºè¯†åˆ«
        if any(word in line for word in ['åˆ', 'è¿˜è¦', 'ä¸€ç›´', 'å†']):
            observations["é‡å¤è¡Œä¸ºè¡¨ç°"].append("é‡å¤éœ€æ±‚è¡¨è¾¾")
        
        # æ„Ÿå®˜ååº”è¯†åˆ«
        if any(word in line for word in ['å¤ªåµ', 'å¤ªäº®', 'ç–¼', 'ç—’']):
            observations["æ„Ÿå®˜ååº”"].append("æ„Ÿå®˜è¿‡æ•ååº”")
        
        # æƒ…ç»ªè¯†åˆ«
        if any(word in line for word in ['ç”Ÿæ°”', 'éš¾è¿‡', 'å®³æ€•', 'å¼€å¿ƒ']):
            observations["æƒ…ç»ªè°ƒèŠ‚"].append("æƒ…ç»ªè¡¨è¾¾å°è¯•")
    
    # æ¸…ç†ç©ºåˆ—è¡¨
    observations = {k: v for k, v in observations.items() if v}
    
    return observations

def run_batch_experiments(experiments, progress_callback=None):
    """è¿è¡Œæ‰¹é‡å®éªŒ"""
    results = []
    delay_between_requests = 25
    
    for i, experiment in enumerate(experiments):
        if progress_callback:
            progress_callback(i + 1, len(experiments))
        
        if 'st' in globals():
            remaining_experiments = len(experiments) - i - 1
            estimated_time = remaining_experiments * delay_between_requests / 60
            st.info(f"â³ æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(experiments)} ä¸ªä¸´åºŠå®éªŒï¼Œé¢„è®¡è¿˜éœ€ {estimated_time:.1f} åˆ†é’Ÿ")
        
        result = run_single_experiment(experiment)
        results.append(result)
        
        if i < len(experiments) - 1:
            print(f"ç­‰å¾…{delay_between_requests}ç§’é¿å…APIé™åˆ¶...")
            if 'st' in globals():
                progress_bar = st.progress(0)
                for wait_second in range(delay_between_requests):
                    progress_bar.progress((wait_second + 1) / delay_between_requests)
                    time.sleep(1)
                progress_bar.empty()
            else:
                time.sleep(delay_between_requests)
    
    return results

def generate_clinical_analysis(records):
    """ç”Ÿæˆä¸´åºŠæ ‡å‡†çš„ç»Ÿè®¡åˆ†ææŠ¥å‘Š"""
    if not records:
        return {}
    
    analysis = {}
    
    # åŸºç¡€ä¸´åºŠç»Ÿè®¡
    analysis['ä¸´åºŠè¯„ä¼°æ¦‚å†µ'] = {
        'è¯„ä¼°æ€»æ•°': len(records),
        'è¯„ä¼°æ—¶é—´è·¨åº¦': f"{min(r['timestamp'] for r in records).strftime('%Y-%m-%d')} è‡³ {max(r['timestamp'] for r in records).strftime('%Y-%m-%d')}",
        'æ¶‰åŠæƒ…å¢ƒæ•°': len(set(r['scene'] for r in records)),
        'æ¶‰åŠä¸¥é‡ç¨‹åº¦æ•°': len(set(r.get('template', 'è‡ªå®šä¹‰') for r in records))
    }
    
    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†æ
    severity_stats = {}
    for record in records:
        severity = record.get('template', 'è‡ªå®šä¹‰')
        if severity not in severity_stats:
            severity_stats[severity] = {
                'è¯„ä¼°æ¬¡æ•°': 0,
                'ç¤¾äº¤äº’åŠ¨å¾—åˆ†': [],
                'æ²Ÿé€šäº¤æµå¾—åˆ†': [],
                'åˆ»æ¿è¡Œä¸ºå¾—åˆ†': [],
                'æ„Ÿå®˜å¤„ç†å¾—åˆ†': [],
                'æƒ…ç»ªè°ƒèŠ‚å¾—åˆ†': [],
                'è®¤çŸ¥é€‚åº”å¾—åˆ†': []
            }
        severity_stats[severity]['è¯„ä¼°æ¬¡æ•°'] += 1
        severity_stats[severity]['ç¤¾äº¤äº’åŠ¨å¾—åˆ†'].append(record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'])
        severity_stats[severity]['æ²Ÿé€šäº¤æµå¾—åˆ†'].append(record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'])
        severity_stats[severity]['åˆ»æ¿è¡Œä¸ºå¾—åˆ†'].append(record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'])
        severity_stats[severity]['æ„Ÿå®˜å¤„ç†å¾—åˆ†'].append(record['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'])
        severity_stats[severity]['æƒ…ç»ªè°ƒèŠ‚å¾—åˆ†'].append(record['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'])
        severity_stats[severity]['è®¤çŸ¥é€‚åº”å¾—åˆ†'].append(record['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½'])
    
    # è®¡ç®—ç»Ÿè®¡å€¼
    for severity, stats in severity_stats.items():
        for metric in ['ç¤¾äº¤äº’åŠ¨å¾—åˆ†', 'æ²Ÿé€šäº¤æµå¾—åˆ†', 'åˆ»æ¿è¡Œä¸ºå¾—åˆ†', 'æ„Ÿå®˜å¤„ç†å¾—åˆ†', 'æƒ…ç»ªè°ƒèŠ‚å¾—åˆ†', 'è®¤çŸ¥é€‚åº”å¾—åˆ†']:
            scores = stats[metric]
            stats[f'{metric}_å‡å€¼'] = np.mean(scores)
            stats[f'{metric}_æ ‡å‡†å·®'] = np.std(scores)
            stats[f'{metric}_èŒƒå›´'] = f"{np.min(scores):.1f}-{np.max(scores):.1f}"
            del stats[metric]
    
    analysis['ä¸¥é‡ç¨‹åº¦åˆ†æ'] = severity_stats
    
    # æŒ‰è¯„ä¼°æƒ…å¢ƒåˆ†æ
    context_stats = {}
    for record in records:
        context = record['scene']
        if context not in context_stats:
            context_stats[context] = {
                'è¯„ä¼°æ¬¡æ•°': 0,
                'ç¤¾äº¤è¡¨ç°': [],
                'æ²Ÿé€šè¡¨ç°': [],
                'é€‚åº”è¡¨ç°': []
            }
        context_stats[context]['è¯„ä¼°æ¬¡æ•°'] += 1
        context_stats[context]['ç¤¾äº¤è¡¨ç°'].append(record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'])
        context_stats[context]['æ²Ÿé€šè¡¨ç°'].append(record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'])
        context_stats[context]['é€‚åº”è¡¨ç°'].append(record['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½'])
    
    for context, stats in context_stats.items():
        for metric in ['ç¤¾äº¤è¡¨ç°', 'æ²Ÿé€šè¡¨ç°', 'é€‚åº”è¡¨ç°']:
            scores = stats[metric]
            stats[f'{metric}_å‡å€¼'] = np.mean(scores)
            del stats[metric]
    
    analysis['æƒ…å¢ƒåˆ†æ'] = context_stats
    
    # æ•´ä½“ä¸´åºŠè¡¨ç°
    all_social = [r['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] for r in records]
    all_comm = [r['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] for r in records]
    all_repetitive = [r['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'] for r in records]
    all_sensory = [r['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'] for r in records]
    all_emotion = [r['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'] for r in records]
    all_cognitive = [r['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½'] for r in records]
    
    analysis['æ•´ä½“ä¸´åºŠè¡¨ç°'] = {
        'ç¤¾äº¤äº’åŠ¨ç¼ºé™·ç¨‹åº¦': f"{np.mean(all_social):.2f} Â± {np.std(all_social):.2f}",
        'æ²Ÿé€šäº¤æµç¼ºé™·ç¨‹åº¦': f"{np.mean(all_comm):.2f} Â± {np.std(all_comm):.2f}",
        'åˆ»æ¿é‡å¤è¡Œä¸ºç¨‹åº¦': f"{np.mean(all_repetitive):.2f} Â± {np.std(all_repetitive):.2f}",
        'æ„Ÿå®˜å¤„ç†å¼‚å¸¸ç¨‹åº¦': f"{np.mean(all_sensory):.2f} Â± {np.std(all_sensory):.2f}",
        'æƒ…ç»ªè°ƒèŠ‚å›°éš¾ç¨‹åº¦': f"{np.mean(all_emotion):.2f} Â± {np.std(all_emotion):.2f}",
        'è®¤çŸ¥é€‚åº”ç¼ºé™·ç¨‹åº¦': f"{np.mean(all_cognitive):.2f} Â± {np.std(all_cognitive):.2f}",
        'æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦': f"{(np.mean(all_social) + np.mean(all_comm) + np.mean(all_repetitive))/3:.2f}"
    }
    
    # ä¸´åºŠå‘ç°å’Œå»ºè®®
    findings = []
    
    # åˆ†ææ ¸å¿ƒç—‡çŠ¶
    core_symptom_avg = (np.mean(all_social) + np.mean(all_comm) + np.mean(all_repetitive)) / 3
    if core_symptom_avg >= 4.0:
        findings.append("æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡ï¼Œå»ºè®®å¯†é›†å‹å¹²é¢„æ²»ç–—")
    elif core_symptom_avg >= 3.0:
        findings.append("æ ¸å¿ƒç—‡çŠ¶ä¸­ç­‰ï¼Œå»ºè®®ç»“æ„åŒ–æ•™å­¦å’Œè¡Œä¸ºå¹²é¢„")
    else:
        findings.append("æ ¸å¿ƒç—‡çŠ¶ç›¸å¯¹è¾ƒè½»ï¼Œå»ºè®®ç¤¾äº¤æŠ€èƒ½è®­ç»ƒ")
    
    # åˆ†æå…±æ‚£æƒ…å†µ
    if np.mean(all_sensory) >= 4.0:
        findings.append("å­˜åœ¨æ˜æ˜¾æ„Ÿå®˜å¤„ç†å¼‚å¸¸ï¼Œå»ºè®®æ„Ÿè§‰ç»Ÿåˆæ²»ç–—")
    
    if np.mean(all_emotion) >= 4.0:
        findings.append("æƒ…ç»ªè°ƒèŠ‚å›°éš¾æ˜¾è‘—ï¼Œå»ºè®®å¿ƒç†è¡Œä¸ºå¹²é¢„")
    
    # åˆ†ææœ€ä¼˜æƒ…å¢ƒ
    if context_stats:
        best_context = min(context_stats.keys(), 
                          key=lambda x: (context_stats[x]['ç¤¾äº¤è¡¨ç°_å‡å€¼'] + 
                                       context_stats[x]['æ²Ÿé€šè¡¨ç°_å‡å€¼']) / 2)
        findings.append(f"åœ¨{best_context}ä¸­è¡¨ç°ç›¸å¯¹è¾ƒå¥½ï¼Œå¯ä½œä¸ºå¹²é¢„èµ·ç‚¹")
    
    analysis['ä¸´åºŠå‘ç°ä¸å»ºè®®'] = findings
    
    return analysis

def create_clinical_excel_report(records, analysis):
    """åˆ›å»ºä¸´åºŠæ ‡å‡†çš„ExcelæŠ¥å‘Š"""
    if not EXCEL_AVAILABLE:
        return None
    
    output = io.BytesIO()
    workbook = Workbook()
    workbook.remove(workbook.active)
    
    # 1. ä¸´åºŠè¯„ä¼°æ¦‚è§ˆ
    overview_sheet = workbook.create_sheet("ä¸´åºŠè¯„ä¼°æ¦‚è§ˆ")
    overview_sheet.append(["å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¡Œä¸ºè¯„ä¼°æŠ¥å‘Šï¼ˆåŸºäºDSM-5æ ‡å‡†ï¼‰"])
    overview_sheet.append([])
    overview_sheet.append(["æŠ¥å‘Šç”Ÿæˆæ—¶é—´", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
    overview_sheet.append(["è¯„ä¼°æ ‡å‡†", "DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡† + CARS/ABC/SCQé‡è¡¨"])
    overview_sheet.append([])
    
    overview_sheet.append(["è¯„ä¼°æ¦‚å†µ"])
    for key, value in analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["æ•´ä½“ä¸´åºŠè¡¨ç°"])
    for key, value in analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["ä¸´åºŠå‘ç°ä¸å»ºè®®"])
    for finding in analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []):
        overview_sheet.append([finding])
    
    # 2. è¯¦ç»†è¯„ä¼°æ•°æ®
    data_sheet = workbook.create_sheet("è¯¦ç»†è¯„ä¼°æ•°æ®")
    headers = ["è¯„ä¼°ID", "æ—¶é—´", "ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "è§‚å¯Ÿæ´»åŠ¨", "è§¦å‘å› ç´ ",
              "ç¤¾äº¤äº’åŠ¨ç¼ºé™·", "æ²Ÿé€šäº¤æµç¼ºé™·", "åˆ»æ¿é‡å¤è¡Œä¸º", "æ„Ÿå®˜å¤„ç†å¼‚å¸¸", 
              "æƒ…ç»ªè°ƒèŠ‚å›°éš¾", "è®¤çŸ¥é€‚åº”ç¼ºé™·", "æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦",
              "DSM-5ä¸¥é‡ç¨‹åº¦", "æ‰€éœ€æ”¯æŒæ°´å¹³", "ç‰¹æ®Šå…´è¶£", "å¤‡æ³¨"]
    data_sheet.append(headers)
    
    for record in records:
        profile = record.get('autism_profile', {})
        scores = record['evaluation_scores']
        core_symptom_severity = (scores['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + scores['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + scores['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        row = [
            record['experiment_id'],
            record['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
            record.get('template', 'è‡ªå®šä¹‰'),
            record['scene'],
            record.get('activity', ''),
            record.get('trigger', ''),
            scores['ç¤¾äº¤äº’åŠ¨è´¨é‡'],
            scores['æ²Ÿé€šäº¤æµèƒ½åŠ›'],
            scores['åˆ»æ¿é‡å¤è¡Œä¸º'],
            scores['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'],
            scores['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'],
            scores['è®¤çŸ¥é€‚åº”åŠŸèƒ½'],
            f"{core_symptom_severity:.2f}",
            profile.get('dsm5_severity', ''),
            profile.get('support_needs', ''),
            profile.get('special_interests', ''),
            record.get('notes', '')
        ]
        data_sheet.append(row)
    
    # 3. ä¸¥é‡ç¨‹åº¦å¯¹æ¯”åˆ†æ
    if analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†æ'):
        severity_sheet = workbook.create_sheet("ä¸¥é‡ç¨‹åº¦åˆ†æ")
        severity_headers = ["ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æ¬¡æ•°", "ç¤¾äº¤ç¼ºé™·å‡å€¼", "æ²Ÿé€šç¼ºé™·å‡å€¼", 
                          "åˆ»æ¿è¡Œä¸ºå‡å€¼", "æ„Ÿå®˜å¼‚å¸¸å‡å€¼", "æƒ…ç»ªå›°éš¾å‡å€¼", "è®¤çŸ¥ç¼ºé™·å‡å€¼",
                          "æ ¸å¿ƒç—‡çŠ¶ç»¼åˆ"]
        severity_sheet.append(severity_headers)
        
        for severity, stats in analysis['ä¸¥é‡ç¨‹åº¦åˆ†æ'].items():
            core_avg = (stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼'] + stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼'] + stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']) / 3
            row = [
                severity,
                stats['è¯„ä¼°æ¬¡æ•°'],
                f"{stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æ„Ÿå®˜å¤„ç†å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æƒ…ç»ªè°ƒèŠ‚å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['è®¤çŸ¥é€‚åº”å¾—åˆ†_å‡å€¼']:.2f}",
                f"{core_avg:.2f}"
            ]
            severity_sheet.append(row)
    
    # 4. ä¸´åºŠè§‚å¯Ÿè®°å½•
    if any('clinical_observations' in record for record in records):
        obs_sheet = workbook.create_sheet("ä¸´åºŠè§‚å¯Ÿè®°å½•")
        obs_sheet.append(["è¯„ä¼°ID", "ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ", "è¯­è¨€æ²Ÿé€šç‰¹ç‚¹", "é‡å¤è¡Œä¸ºè¡¨ç°", "æ„Ÿå®˜ååº”", "æƒ…ç»ªè°ƒèŠ‚"])
        
        for record in records:
            if 'clinical_observations' in record:
                obs = record['clinical_observations']
                row = [
                    record['experiment_id'],
                    '; '.join(obs.get('ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ', [])),
                    '; '.join(obs.get('è¯­è¨€æ²Ÿé€šç‰¹ç‚¹', [])),
                    '; '.join(obs.get('é‡å¤è¡Œä¸ºè¡¨ç°', [])),
                    '; '.join(obs.get('æ„Ÿå®˜ååº”', [])),
                    '; '.join(obs.get('æƒ…ç»ªè°ƒèŠ‚', []))
                ]
                obs_sheet.append(row)
    
    # 5. å¯¹è¯è®°å½•ï¼ˆç”¨äºè´¨æ€§åˆ†æï¼‰
    dialogue_sheet = workbook.create_sheet("å¯¹è¯è®°å½•")
    dialogue_sheet.append(["è¯„ä¼°ID", "ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "å¯¹è¯å†…å®¹"])
    
    for record in records:
        dialogue_sheet.append([
            record['experiment_id'],
            record.get('template', 'è‡ªå®šä¹‰'),
            record['scene'],
            record['dialogue']
        ])
    
    # åº”ç”¨ä¸“ä¸šæ ·å¼
    for sheet in workbook.worksheets:
        for row in sheet.iter_rows():
            for cell in row:
                if cell.row == 1:
                    cell.font = Font(bold=True, size=12)
                    cell.fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
                    cell.font = Font(bold=True, color="FFFFFF")
                elif any(keyword in str(cell.value) for keyword in ['ä¸¥é‡', 'æ˜æ˜¾', 'éœ€è¦æ”¯æŒ']) if cell.value else False:
                    cell.fill = PatternFill(start_color="FFE6E6", end_color="FFE6E6", fill_type="solid")
                cell.alignment = Alignment(wrap_text=True, vertical="top")
    
    workbook.save(output)
    output.seek(0)
    return output.getvalue()

# ä¸»é¡µé¢
st.title("ğŸ¥ å­¤ç‹¬ç—‡å„¿ç«¥AIæ¨¡æ‹Ÿå®éªŒå¹³å° - åŒ»å­¦æ ‡å‡†ç‰ˆ")
st.markdown("**åŸºäºDSM-5è¯Šæ–­æ ‡å‡†å’Œæƒå¨è¯„ä¼°é‡è¡¨ï¼ˆCARSã€ABCã€SCQã€M-CHATç­‰ï¼‰**")

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("ğŸ” å¯¼èˆª")
page = st.sidebar.selectbox("é€‰æ‹©åŠŸèƒ½é¡µé¢", [
    "ä¸´åºŠå¿«é€Ÿè¯„ä¼°", "æ‰¹é‡ä¸´åºŠç ”ç©¶", "ä¸ªæ€§åŒ–è¯„ä¼°è®¾è®¡", 
    "ä¸´åºŠæ•°æ®åˆ†æ", "è¯„ä¼°è®°å½•ç®¡ç†", "ğŸ“Š ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒ"
])

# é¡µé¢è·¯ç”±
if page == "ä¸´åºŠå¿«é€Ÿè¯„ä¼°":
    st.header("ğŸ©º ä¸´åºŠå¿«é€Ÿè¯„ä¼°")
    st.markdown("ä½¿ç”¨æ ‡å‡†åŒ–ä¸¥é‡ç¨‹åº¦åˆ†çº§è¿›è¡Œå¿«é€Ÿä¸´åºŠè¡Œä¸ºè¯„ä¼°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ é€‰æ‹©è¯„ä¼°å¯¹è±¡")
        selected_severity = st.selectbox("ä¸¥é‡ç¨‹åº¦åˆ†çº§", list(CLINICAL_AUTISM_PROFILES.keys()))
        
        profile = CLINICAL_AUTISM_PROFILES[selected_severity]
        
        # æ˜¾ç¤ºä¸´åºŠç‰¹å¾
        with st.expander("æŸ¥çœ‹DSM-5ç‰¹å¾é…ç½®", expanded=True):
            st.write(f"**DSM-5ä¸¥é‡ç¨‹åº¦**: {profile['dsm5_severity']}")
            st.write(f"**ç¤¾äº¤æ²Ÿé€šç¼ºé™·**: {profile['social_communication']}/5")
            st.write(f"**åˆ»æ¿é‡å¤è¡Œä¸º**: {profile['restricted_repetitive']}/5")
            st.write(f"**æ„Ÿå®˜å¤„ç†å¼‚å¸¸**: {profile['sensory_processing']}/5")
            st.write(f"**è®¤çŸ¥åŠŸèƒ½æ°´å¹³**: {profile['cognitive_function']}/5")
            st.write(f"**é€‚åº”è¡Œä¸ºèƒ½åŠ›**: {profile['adaptive_behavior']}/5")
            st.write(f"**è¯­è¨€å‘å±•æ°´å¹³**: {profile['language_level']}/5")
            st.write(f"**ç‰¹æ®Šå…´è¶£**: {profile['special_interests']}")
            st.write(f"**æ‰€éœ€æ”¯æŒ**: {profile['support_needs']}")
        
        selected_scene = st.selectbox("é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ", list(CLINICAL_SCENE_CONFIG.keys()))
        
        scene_data = CLINICAL_SCENE_CONFIG[selected_scene]
        
        # æ˜¾ç¤ºåœºæ™¯ä¿¡æ¯
        with st.expander("è¯„ä¼°æƒ…å¢ƒè¯¦æƒ…"):
            st.write(f"**ç›®æ ‡**: {scene_data['target']}")
            st.write(f"**è§‚å¯Ÿè¦ç‚¹**: {', '.join(scene_data['observation_points'])}")
        
        selected_activity = st.selectbox("é€‰æ‹©è§‚å¯Ÿæ´»åŠ¨", scene_data['activities'])
        selected_trigger = st.selectbox("é€‰æ‹©è§¦å‘å› ç´ ", scene_data['triggers'])
    
    with col2:
        st.subheader("ğŸ”¬ æ‰§è¡Œè¯„ä¼°")
        
        if st.button("ğŸ©º å¼€å§‹ä¸´åºŠè¯„ä¼°", type="primary", use_container_width=True):
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
            experiment_config = {
                'template': selected_severity,
                'scene': selected_scene,
                'activity': selected_activity,
                'trigger': selected_trigger,
                'autism_profile': profile.copy(),
                'experiment_id': f"CLIN_{selected_severity[:4]}_{timestamp}"
            }
            
            with st.spinner("ğŸ¤– æ­£åœ¨ç”Ÿæˆä¸´åºŠè¯„ä¼°å¯¹è¯..."):
                result = run_single_experiment(experiment_config)
            
            if 'error' not in result:
                st.session_state.experiment_records.append(result)
                
                st.success(f"âœ… ä¸´åºŠè¯„ä¼°å®Œæˆï¼ID: {result['experiment_id']}")
                
                # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                st.subheader("ğŸ“Š ä¸´åºŠè¯„ä¼°ç»“æœ")
                
                col_result1, col_result2 = st.columns(2)
                
                with col_result1:
                    st.write("**æ ¸å¿ƒç—‡çŠ¶è¯„ä¼°å¾—åˆ†** (5åˆ†ä¸ºæœ€ä¸¥é‡):")
                    for metric, score in result['evaluation_scores'].items():
                        # æ ¹æ®å¾—åˆ†æ˜¾ç¤ºä¸åŒé¢œè‰²
                        if score >= 4.0:
                            st.error(f"{metric}: {score}/5.0 (ä¸¥é‡)")
                        elif score >= 3.0:
                            st.warning(f"{metric}: {score}/5.0 (ä¸­åº¦)")
                        else:
                            st.success(f"{metric}: {score}/5.0 (è½»åº¦)")
                
                with col_result2:
                    st.write("**ä¸´åºŠè§‚å¯Ÿè¦ç‚¹**:")
                    if 'clinical_observations' in result:
                        for category, observations in result['clinical_observations'].items():
                            if observations:
                                st.write(f"**{category}**: {', '.join(observations)}")
                    
                    st.write("**å¯¹è¯é¢„è§ˆ**:")
                    dialogue_lines = result['dialogue'].split('\n')[:8]
                    for line in dialogue_lines:
                        if ':' in line and line.strip():
                            if 'å­¤ç‹¬ç—‡å„¿ç«¥' in line:
                                st.markdown(f"ğŸ§’ {line}")
                            else:
                                st.markdown(f"ğŸ‘¤ {line}")
                    
                    if len(result['dialogue'].split('\n')) > 8:
                        st.markdown("*...æŸ¥çœ‹å®Œæ•´è®°å½•è¯·å‰å¾€'è¯„ä¼°è®°å½•ç®¡ç†'*")
                
                # æ˜¾ç¤ºä¸´åºŠå»ºè®®
                st.subheader("ğŸ’¡ ä¸´åºŠå»ºè®®")
                core_avg = (result['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                           result['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                           result['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                
                if core_avg >= 4.0:
                    st.error("ğŸš¨ å»ºè®®ï¼šæ ¸å¿ƒç—‡çŠ¶ä¸¥é‡ï¼Œéœ€è¦å¯†é›†å‹å¹²é¢„å’Œä¸“ä¸šæ”¯æŒ")
                elif core_avg >= 3.0:
                    st.warning("âš ï¸ å»ºè®®ï¼šæ ¸å¿ƒç—‡çŠ¶ä¸­ç­‰ï¼Œå»ºè®®ç»“æ„åŒ–æ•™å­¦å’Œè¡Œä¸ºå¹²é¢„")
                else:
                    st.success("âœ… å»ºè®®ï¼šç—‡çŠ¶ç›¸å¯¹è¾ƒè½»ï¼Œå¯é‡ç‚¹è¿›è¡Œç¤¾äº¤æŠ€èƒ½è®­ç»ƒ")
                    
            else:
                st.error(f"âŒ è¯„ä¼°å¤±è´¥: {result['error']}")

elif page == "æ‰¹é‡ä¸´åºŠç ”ç©¶":
    st.header("ğŸ”¬ æ‰¹é‡ä¸´åºŠç ”ç©¶")
    st.markdown("è¿›è¡Œå¤šç»„ä¸´åºŠå¯¹ç…§ç ”ç©¶ï¼Œè·å–ç»Ÿè®¡å­¦æœ‰æ•ˆçš„è¯„ä¼°æ•°æ®")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ¯ ç ”ç©¶è®¾è®¡")
        
        research_scale = st.radio(
            "é€‰æ‹©ç ”ç©¶è§„æ¨¡",
            ["è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰", "æ ‡å‡†ç ”ç©¶", "å¤§æ ·æœ¬ç ”ç©¶"],
            help="æ ¹æ®ç ”ç©¶éœ€è¦é€‰æ‹©åˆé€‚çš„æ ·æœ¬è§„æ¨¡"
        )
        
        if research_scale == "è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰":
            default_severities = list(CLINICAL_AUTISM_PROFILES.keys())[:2]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:2]
            default_repeats = 1
            st.info("ğŸš€ è¯•ç‚¹ç ”ç©¶ï¼šéªŒè¯è¯„ä¼°å·¥å…·æ•ˆæœï¼Œçº¦éœ€5-8åˆ†é’Ÿ")
        elif research_scale == "æ ‡å‡†ç ”ç©¶":
            default_severities = list(CLINICAL_AUTISM_PROFILES.keys())[:3]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:3]
            default_repeats = 2
            st.info("â³ æ ‡å‡†ç ”ç©¶ï¼šè·å¾—å¯é ç»Ÿè®¡æ•°æ®ï¼Œçº¦éœ€20-30åˆ†é’Ÿ")
        else:
            default_severities = list(CLINICAL_AUTISM_PROFILES.keys())
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())
            default_repeats = 2
            st.warning("â° å¤§æ ·æœ¬ç ”ç©¶ï¼šå®Œæ•´ä¸´åºŠç ”ç©¶æ•°æ®ï¼Œçº¦éœ€60-90åˆ†é’Ÿ")
        
        selected_severities = st.multiselect(
            "é€‰æ‹©ä¸¥é‡ç¨‹åº¦ç»„", 
            list(CLINICAL_AUTISM_PROFILES.keys()),
            default=default_severities
        )
        
        selected_contexts = st.multiselect(
            "é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ",
            list(CLINICAL_SCENE_CONFIG.keys()),
            default=default_contexts
        )
        
        repeats_per_combo = st.slider(
            "æ¯ç»„åˆé‡å¤æ¬¡æ•°", 
            1, 3, 
            default_repeats,
            help="å¢åŠ é‡å¤æ¬¡æ•°æé«˜ç»Ÿè®¡å¯é æ€§"
        )
        
        if selected_severities and selected_contexts:
            severity_dict = {k: CLINICAL_AUTISM_PROFILES[k] for k in selected_severities}
            context_dict = {k: CLINICAL_SCENE_CONFIG[k] for k in selected_contexts}
            
            experiments = generate_experiment_batch(
                severity_dict, 
                context_dict, 
                repeats_per_combo
            )
            
            st.info(f"ğŸ“Š å°†ç”Ÿæˆ {len(experiments)} ä¸ªä¸´åºŠè¯„ä¼°")
            
            # ç ”ç©¶è®¾è®¡é¢„è§ˆ
            with st.expander("ç ”ç©¶è®¾è®¡é¢„è§ˆ", expanded=False):
                preview_df = pd.DataFrame([
                    {
                        'ä¸¥é‡ç¨‹åº¦': exp['template'],
                        'è¯„ä¼°æƒ…å¢ƒ': exp['scene'],
                        'è§‚å¯Ÿæ´»åŠ¨': exp['activity'],
                        'è§¦å‘å› ç´ ': exp['trigger']
                    } for exp in experiments[:10]
                ])
                st.dataframe(preview_df)
                if len(experiments) > 10:
                    st.write(f"*...è¿˜æœ‰ {len(experiments) - 10} ä¸ªè¯„ä¼°*")
    
    with col2:
        st.subheader("ğŸš€ æ‰§è¡Œç ”ç©¶")
        
        if 'clinical_batch_ready' not in st.session_state:
            st.session_state.clinical_batch_ready = False
        if 'clinical_batch_running' not in st.session_state:
            st.session_state.clinical_batch_running = False
        
        if selected_severities and selected_contexts:
            estimated_minutes = len(experiments) * 25 / 60
            st.info(f"ğŸ“Š è¯„ä¼°æ•°é‡: {len(experiments)}")
            st.info(f"â° é¢„è®¡æ—¶é—´: {estimated_minutes:.1f} åˆ†é’Ÿ")
            
            if not st.session_state.clinical_batch_ready and not st.session_state.clinical_batch_running:
                if st.button("âš¡ å‡†å¤‡å¼€å§‹ç ”ç©¶", use_container_width=True):
                    st.session_state.clinical_batch_ready = True
                    st.rerun()
            
            elif st.session_state.clinical_batch_ready and not st.session_state.clinical_batch_running:
                st.warning("â° **é‡è¦**: ç”±äºAPIé™åˆ¶ï¼Œæ‰¹é‡ç ”ç©¶éœ€è¦è¾ƒé•¿æ—¶é—´")
                st.info("ğŸ’¡ ç¡®è®¤åå°†ç«‹å³å¼€å§‹ï¼Œè¯·ä¿æŒç½‘ç»œç¨³å®š")
                
                col_btn1, col_btn2 = st.columns(2)
                
                with col_btn1:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        st.session_state.clinical_batch_ready = False
                        st.rerun()
                
                with col_btn2:
                    if st.button("âœ… å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True):
                        st.session_state.clinical_batch_running = True
                        st.session_state.clinical_batch_ready = False
                        st.rerun()
            
            elif st.session_state.clinical_batch_running:
                st.success("ğŸ”¬ ä¸´åºŠç ”ç©¶è¿›è¡Œä¸­...")
                
                progress_container = st.container()
                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    result_container = st.empty()
                
                def update_progress(current, total):
                    progress = current / total
                    progress_bar.progress(progress)
                    remaining_time = (total - current) * 25 / 60
                    status_text.text(f"ç ”ç©¶è¿›åº¦: {current}/{total} ({progress:.1%}) - é¢„è®¡è¿˜éœ€ {remaining_time:.1f} åˆ†é’Ÿ")
                
                try:
                    results = run_batch_experiments(experiments, update_progress)
                    
                    successful_results = [r for r in results if 'error' not in r]
                    failed_results = [r for r in results if 'error' in r]
                    
                    st.session_state.experiment_records.extend(successful_results)
                    st.session_state.current_batch_results = successful_results
                    
                    with result_container:
                        st.success(f"âœ… ä¸´åºŠç ”ç©¶å®Œæˆï¼")
                        st.write(f"**æˆåŠŸè¯„ä¼°**: {len(successful_results)} ä¸ª")
                        
                        if failed_results:
                            st.error(f"**å¤±è´¥è¯„ä¼°**: {len(failed_results)} ä¸ª")
                        
                        if successful_results:
                            st.subheader("ğŸ“ˆ ç ”ç©¶ç»“æœæ¦‚è§ˆ")
                            
                            # æŒ‰ä¸¥é‡ç¨‹åº¦ç»Ÿè®¡
                            severity_stats = {}
                            for result in successful_results:
                                severity = result['template']
                                if severity not in severity_stats:
                                    severity_stats[severity] = []
                                
                                # è®¡ç®—æ ¸å¿ƒç—‡çŠ¶ç»¼åˆå¾—åˆ†
                                core_score = (result['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                                            result['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                                            result['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                                severity_stats[severity].append(core_score)
                            
                            stats_df = pd.DataFrame([
                                {
                                    'ä¸¥é‡ç¨‹åº¦': severity,
                                    'æ ·æœ¬æ•°': len(scores),
                                    'æ ¸å¿ƒç—‡çŠ¶å‡å€¼': f"{np.mean(scores):.2f}",
                                    'æ ‡å‡†å·®': f"{np.std(scores):.2f}",
                                    '95%ç½®ä¿¡åŒºé—´': f"{np.mean(scores) - 1.96*np.std(scores)/np.sqrt(len(scores)):.2f}-{np.mean(scores) + 1.96*np.std(scores)/np.sqrt(len(scores)):.2f}"
                                } for severity, scores in severity_stats.items()
                            ])
                            
                            st.dataframe(stats_df, use_container_width=True)
                    
                    st.session_state.clinical_batch_running = False
                    
                    if st.button("ğŸ”„ è¿›è¡Œæ–°ç ”ç©¶", use_container_width=True):
                        st.session_state.clinical_batch_ready = False
                        st.session_state.clinical_batch_running = False
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"âŒ ç ”ç©¶å‡ºé”™: {str(e)}")
                    st.session_state.clinical_batch_running = False
                    if st.button("ğŸ”„ é‡æ–°å°è¯•", use_container_width=True):
                        st.rerun()
        
        else:
            st.error("è¯·å…ˆé€‰æ‹©ä¸¥é‡ç¨‹åº¦å’Œè¯„ä¼°æƒ…å¢ƒ")

elif page == "ä¸ªæ€§åŒ–è¯„ä¼°è®¾è®¡":
    st.header("âš™ï¸ ä¸ªæ€§åŒ–è¯„ä¼°è®¾è®¡")
    st.markdown("åŸºäºDSM-5æ ‡å‡†è‡ªå®šä¹‰ä¸ªä½“åŒ–ä¸´åºŠè¯„ä¼°å‚æ•°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ­ è¯„ä¼°æƒ…å¢ƒè®¾ç½®")
        selected_scene = st.selectbox("é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ", list(CLINICAL_SCENE_CONFIG.keys()))
        scene_data = CLINICAL_SCENE_CONFIG[selected_scene]
        
        st.info(f"**è¯„ä¼°ç›®æ ‡**: {scene_data['target']}")
        
        # æ˜¾ç¤ºè§‚å¯Ÿè¦ç‚¹
        with st.expander("ä¸´åºŠè§‚å¯Ÿè¦ç‚¹"):
            for point in scene_data['observation_points']:
                st.write(f"â€¢ {point}")
        
        selected_activity = st.selectbox("é€‰æ‹©è§‚å¯Ÿæ´»åŠ¨", scene_data['activities'])
        selected_trigger = st.selectbox("é€‰æ‹©è§¦å‘å› ç´ ", scene_data['triggers'])
    
    with col2:
        st.subheader("ğŸ‘¤ DSM-5ç‰¹å¾é…ç½®")
        
        template_base = st.selectbox("åŸºäºæ ‡å‡†åˆ†çº§", ["è‡ªå®šä¹‰"] + list(CLINICAL_AUTISM_PROFILES.keys()))
        
        if template_base != "è‡ªå®šä¹‰":
            base_profile = CLINICAL_AUTISM_PROFILES[template_base]
            st.info(f"åŸºäº: {base_profile['dsm5_severity']}")
        else:
            base_profile = {
                'social_communication': 3,
                'restricted_repetitive': 3,
                'sensory_processing': 3,
                'cognitive_function': 3,
                'adaptive_behavior': 3,
                'language_level': 3,
                'special_interests': "ç‰¹å®šç‰©ä½“ã€æ´»åŠ¨æˆ–ä¸»é¢˜",
                'support_needs': "ä¸­ç­‰æ”¯æŒ",
                'dsm5_severity': "è‡ªå®šä¹‰é…ç½®"
            }
        
        st.write("**æ ¸å¿ƒç—‡çŠ¶é…ç½®** (åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Aã€Bæ¡ç›®)")
        
        social_comm = st.slider(
            "A. ç¤¾äº¤æ²Ÿé€šç¼ºé™·ç¨‹åº¦", 1, 5, base_profile['social_communication'],
            help="1=æ— æ˜æ˜¾ç¼ºé™·ï¼Œ5=ä¸¥é‡ç¼ºé™·ï¼ˆç¤¾ä¼šæƒ…æ„Ÿäº’æƒ æ€§ã€éè¯­è¨€æ²Ÿé€šã€å…³ç³»å‘å±•å›°éš¾ï¼‰"
        )
        
        repetitive_behavior = st.slider(
            "B. åˆ»æ¿é‡å¤è¡Œä¸ºç¨‹åº¦", 1, 5, base_profile['restricted_repetitive'],
            help="1=å¾ˆå°‘é‡å¤è¡Œä¸ºï¼Œ5=ä¸¥é‡é‡å¤è¡Œä¸ºï¼ˆåˆ»æ¿åŠ¨ä½œã€ä»ªå¼ã€ç‹­éš˜å…´è¶£ã€æ„Ÿå®˜å¼‚å¸¸ï¼‰"
        )
        
        st.write("**ç›¸å…³åŠŸèƒ½é…ç½®**")
        
        sensory_processing = st.slider(
            "æ„Ÿå®˜å¤„ç†å¼‚å¸¸ç¨‹åº¦", 1, 5, base_profile['sensory_processing'],
            help="1=æ­£å¸¸å¤„ç†ï¼Œ5=ä¸¥é‡å¼‚å¸¸ï¼ˆè¿‡æ•ã€å¯»æ±‚ã€é€ƒé¿ï¼‰"
        )
        
        cognitive_function = st.slider(
            "è®¤çŸ¥åŠŸèƒ½æ°´å¹³", 1, 5, base_profile['cognitive_function'],
            help="1=é‡åº¦éšœç¢ï¼Œ5=æ­£å¸¸èŒƒå›´"
        )
        
        adaptive_behavior = st.slider(
            "é€‚åº”è¡Œä¸ºèƒ½åŠ›", 1, 5, base_profile['adaptive_behavior'],
            help="1=ä¸¥é‡å›°éš¾ï¼Œ5=å¹´é¾„é€‚å®œ"
        )
        
        language_level = st.slider(
            "è¯­è¨€å‘å±•æ°´å¹³", 1, 5, base_profile['language_level'],
            help="1=æ— åŠŸèƒ½æ€§è¯­è¨€ï¼Œ5=å¹´é¾„é€‚å®œ"
        )
        
        special_interests = st.text_input(
            "ç‰¹æ®Šå…´è¶£/é™åˆ¶æ€§å…´è¶£", 
            base_profile['special_interests'],
            help="æè¿°å…·ä½“çš„ç‰¹æ®Šå…´è¶£æˆ–é‡å¤è¡Œä¸º"
        )
        
        # æ ¹æ®é…ç½®è‡ªåŠ¨æ¨æ–­æ”¯æŒéœ€æ±‚
        total_severity = social_comm + repetitive_behavior
        if total_severity >= 8:
            support_level = "éœ€è¦éå¸¸å¤§é‡æ”¯æŒ"
            dsm5_level = "éœ€è¦éå¸¸å¤§é‡æ”¯æŒ"
        elif total_severity >= 6:
            support_level = "éœ€è¦å¤§é‡æ”¯æŒ"
            dsm5_level = "éœ€è¦å¤§é‡æ”¯æŒ"
        else:
            support_level = "éœ€è¦æ”¯æŒ"
            dsm5_level = "éœ€è¦æ”¯æŒ"
        
        st.info(f"**æ¨æ–­çš„DSM-5ä¸¥é‡ç¨‹åº¦**: {dsm5_level}")
        st.info(f"**æ¨æ–­çš„æ”¯æŒéœ€æ±‚**: {support_level}")
        
        autism_profile = {
            'social_communication': social_comm,
            'restricted_repetitive': repetitive_behavior,
            'sensory_processing': sensory_processing,
            'cognitive_function': cognitive_function,
            'adaptive_behavior': adaptive_behavior,
            'language_level': language_level,
            'special_interests': special_interests,
            'support_needs': support_level,
            'dsm5_severity': dsm5_level
        }
    
    # æ‰§è¡Œä¸ªæ€§åŒ–è¯„ä¼°
    st.subheader("ğŸ”¬ æ‰§è¡Œä¸ªæ€§åŒ–è¯„ä¼°")
    
    if st.button("ğŸ©º å¼€å§‹ä¸ªæ€§åŒ–è¯„ä¼°", type="primary", use_container_width=True):
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        experiment_config = {
            'template': template_base if template_base != "è‡ªå®šä¹‰" else "ä¸ªæ€§åŒ–é…ç½®",
            'scene': selected_scene,
            'activity': selected_activity,
            'trigger': selected_trigger,
            'autism_profile': autism_profile,
            'experiment_id': f"CUSTOM_{timestamp}"
        }
        
        with st.spinner("ğŸ¤– æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–è¯„ä¼°..."):
            result = run_single_experiment(experiment_config)
        
        if 'error' not in result:
            st.session_state.experiment_records.append(result)
            
            st.success(f"âœ… ä¸ªæ€§åŒ–è¯„ä¼°å®Œæˆï¼ID: {result['experiment_id']}")
            
            # æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ
            st.subheader("ğŸ“Š ä¸ªæ€§åŒ–è¯„ä¼°ç»“æœ")
            
            col_res1, col_res2, col_res3 = st.columns(3)
            
            with col_res1:
                st.write("**æ ¸å¿ƒç—‡çŠ¶è¯„ä¼°**:")
                st.metric("ç¤¾äº¤æ²Ÿé€šç¼ºé™·", f"{result['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡']:.2f}/5")
                st.metric("åˆ»æ¿é‡å¤è¡Œä¸º", f"{result['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']:.2f}/5")
                
                core_avg = (result['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                           result['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 2
                st.metric("æ ¸å¿ƒç—‡çŠ¶ç»¼åˆ", f"{core_avg:.2f}/5")
            
            with col_res2:
                st.write("**ç›¸å…³åŠŸèƒ½è¯„ä¼°**:")
                st.metric("æ²Ÿé€šäº¤æµèƒ½åŠ›", f"{result['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›']:.2f}/5")
                st.metric("æ„Ÿå®˜å¤„ç†èƒ½åŠ›", f"{result['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›']:.2f}/5")
                st.metric("æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚", f"{result['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚']:.2f}/5")
                st.metric("è®¤çŸ¥é€‚åº”åŠŸèƒ½", f"{result['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½']:.2f}/5")
            
            with col_res3:
                st.write("**ä¸´åºŠè§‚å¯Ÿ**:")
                if 'clinical_observations' in result:
                    for category, observations in result['clinical_observations'].items():
                        if observations:
                            st.write(f"**{category}**:")
                            for obs in observations:
                                st.write(f"â€¢ {obs}")
                
            # ä¸ªæ€§åŒ–å»ºè®®
            st.subheader("ğŸ’¡ ä¸ªæ€§åŒ–å¹²é¢„å»ºè®®")
            
            suggestions = []
            
            if result['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] >= 4:
                suggestions.append("ğŸ¯ ä¼˜å…ˆç›®æ ‡ï¼šç¤¾äº¤æŠ€èƒ½è®­ç»ƒï¼ˆçœ¼ç¥æ¥è§¦ã€è½®æµäº¤æ›¿ã€æƒ…æ„Ÿåˆ†äº«ï¼‰")
            
            if result['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] >= 4:
                suggestions.append("ğŸ—£ï¸ æ²Ÿé€šå¹²é¢„ï¼šè¯­è¨€æ²»ç–—ã€AACè¾…åŠ©æ²Ÿé€šã€ç¤¾äº¤è¯­ç”¨è®­ç»ƒ")
            
            if result['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'] >= 4:
                suggestions.append("ğŸ”„ è¡Œä¸ºç®¡ç†ï¼šåŠŸèƒ½æ€§è¡Œä¸ºåˆ†æã€æ›¿ä»£è¡Œä¸ºè®­ç»ƒã€ç¯å¢ƒç»“æ„åŒ–")
            
            if result['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'] >= 4:
                suggestions.append("ğŸŒˆ æ„Ÿå®˜æ”¯æŒï¼šæ„Ÿè§‰ç»Ÿåˆæ²»ç–—ã€ç¯å¢ƒè°ƒé€‚ã€è‡ªæˆ‘è°ƒèŠ‚ç­–ç•¥")
            
            if result['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'] >= 4:
                suggestions.append("ğŸ˜Œ æƒ…ç»ªæ”¯æŒï¼šæƒ…ç»ªè¯†åˆ«è®­ç»ƒã€åº”å¯¹ç­–ç•¥æ•™å­¦ã€è¡Œä¸ºå¹²é¢„")
            
            if not suggestions:
                suggestions.append("âœ… æ•´ä½“è¡¨ç°è‰¯å¥½ï¼Œå»ºè®®ç»´æŒç°æœ‰æ”¯æŒå¹¶ç›‘æµ‹å‘å±•")
            
            for suggestion in suggestions:
                st.success(suggestion)
                
        else:
            st.error(f"âŒ è¯„ä¼°å¤±è´¥: {result['error']}")
    
    # ä¿å­˜é…ç½®
    if st.button("ğŸ’¾ ä¿å­˜è¯„ä¼°é…ç½®", use_container_width=True):
        st.session_state.custom_autism_profile = autism_profile
        st.session_state.custom_scene_config = {
            'scene': selected_scene,
            'activity': selected_activity,
            'trigger': selected_trigger
        }
        st.success("âœ… ä¸ªæ€§åŒ–é…ç½®å·²ä¿å­˜ï¼")

elif page == "ä¸´åºŠæ•°æ®åˆ†æ":
    st.header("ğŸ“ˆ ä¸´åºŠæ•°æ®åˆ†æ")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.warning("ğŸ“Š æš‚æ— è¯„ä¼°æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œä¸´åºŠè¯„ä¼°")
        st.stop()
    
    # ç”Ÿæˆä¸´åºŠåˆ†æ
    analysis = generate_clinical_analysis(records)
    
    # ä¸´åºŠæ¦‚å†µ
    st.subheader("ğŸ¥ ä¸´åºŠè¯„ä¼°æ¦‚å†µ")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("è¯„ä¼°æ€»æ•°", len(records))
    with col2:
        severities = [r.get('template', 'è‡ªå®šä¹‰') for r in records]
        most_common = max(set(severities), key=severities.count) if severities else "æ— "
        st.metric("ä¸»è¦ä¸¥é‡ç¨‹åº¦", most_common.split('ï¼ˆ')[0])
    with col3:
        contexts = [r['scene'] for r in records]
        most_used_context = max(set(contexts), key=contexts.count)
        st.metric("ä¸»è¦è¯„ä¼°æƒ…å¢ƒ", most_used_context.replace('ç»“æ„åŒ–', 'ç»“æ„'))
    with col4:
        all_core_scores = []
        for r in records:
            core_score = (r['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                         r['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                         r['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
            all_core_scores.append(core_score)
        avg_core = np.mean(all_core_scores)
        st.metric("å¹³å‡æ ¸å¿ƒç—‡çŠ¶", f"{avg_core:.2f}/5")
    
    # DSM-5æ ¸å¿ƒç—‡çŠ¶åˆ†æ
    st.subheader("ğŸ§  DSM-5æ ¸å¿ƒç—‡çŠ¶åˆ†æ")
    
    # æ ¸å¿ƒç—‡çŠ¶é›·è¾¾å›¾
    avg_scores = {}
    for metric in CLINICAL_EVALUATION_METRICS.keys():
        scores = [r['evaluation_scores'][metric] for r in records]
        avg_scores[metric] = np.mean(scores)
    
    fig_radar = go.Figure()
    fig_radar.add_trace(go.Scatterpolar(
        r=list(avg_scores.values()),
        theta=list(avg_scores.keys()),
        fill='toself',
        name='å¹³å‡ç¼ºé™·ç¨‹åº¦',
        line_color='rgb(255, 100, 100)'
    ))
    fig_radar.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[1, 5],
                tickvals=[1, 2, 3, 4, 5],
                ticktext=['æ­£å¸¸', 'è½»åº¦', 'ä¸­åº¦', 'æ˜æ˜¾', 'ä¸¥é‡']
            )),
        showlegend=True,
        title="DSM-5æ ¸å¿ƒç—‡çŠ¶åŠç›¸å…³åŠŸèƒ½è¯„ä¼°é›·è¾¾å›¾",
        height=500
    )
    st.plotly_chart(fig_radar, use_container_width=True)
    
    # ä¸¥é‡ç¨‹åº¦å¯¹æ¯”åˆ†æ
    st.subheader("ğŸ“Š ä¸¥é‡ç¨‹åº¦ç»„é—´å¯¹æ¯”")
    
    if len(set([r.get('template', 'è‡ªå®šä¹‰') for r in records])) > 1:
        severity_data = {}
        for record in records:
            severity = record.get('template', 'è‡ªå®šä¹‰')
            if severity not in severity_data:
                severity_data[severity] = {
                    'ç¤¾äº¤æ²Ÿé€šç¼ºé™·': [],
                    'åˆ»æ¿é‡å¤è¡Œä¸º': [],
                    'æ„Ÿå®˜å¤„ç†å¼‚å¸¸': [],
                    'è®¤çŸ¥é€‚åº”ç¼ºé™·': []
                }
            
            severity_data[severity]['ç¤¾äº¤æ²Ÿé€šç¼ºé™·'].append(
                (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                 record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›']) / 2
            )
            severity_data[severity]['åˆ»æ¿é‡å¤è¡Œä¸º'].append(
                record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']
            )
            severity_data[severity]['æ„Ÿå®˜å¤„ç†å¼‚å¸¸'].append(
                record['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›']
            )
            severity_data[severity]['è®¤çŸ¥é€‚åº”ç¼ºé™·'].append(
                record['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½']
            )
        
        # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
        comparison_data = []
        for severity, metrics in severity_data.items():
            for metric, scores in metrics.items():
                comparison_data.append({
                    'ä¸¥é‡ç¨‹åº¦': severity,
                    'ç—‡çŠ¶åŸŸ': metric,
                    'å¹³å‡å¾—åˆ†': np.mean(scores),
                    'æ ‡å‡†å·®': np.std(scores)
                })
        
        df_comparison = pd.DataFrame(comparison_data)
        
        fig_comparison = px.bar(
            df_comparison, 
            x='ä¸¥é‡ç¨‹åº¦', 
            y='å¹³å‡å¾—åˆ†', 
            color='ç—‡çŠ¶åŸŸ',
            title="ä¸åŒä¸¥é‡ç¨‹åº¦ç»„çš„ç—‡çŠ¶åŸŸå¯¹æ¯”",
            labels={'å¹³å‡å¾—åˆ†': 'ç¼ºé™·ç¨‹åº¦ (1-5åˆ†)'},
            height=400
        )
        fig_comparison.update_layout(yaxis_range=[1, 5])
        st.plotly_chart(fig_comparison, use_container_width=True)
    
    # è¯„ä¼°æƒ…å¢ƒæ•ˆåº”åˆ†æ
    st.subheader("ğŸ­ è¯„ä¼°æƒ…å¢ƒæ•ˆåº”åˆ†æ")
    
    context_data = {}
    for record in records:
        context = record['scene']
        if context not in context_data:
            context_data[context] = []
        
        # è®¡ç®—ç»¼åˆè¡¨ç°å¾—åˆ†ï¼ˆå¾—åˆ†è¶Šä½è¡¨ç°è¶Šå¥½ï¼‰
        comprehensive_score = np.mean(list(record['evaluation_scores'].values()))
        context_data[context].append(comprehensive_score)
    
    if len(context_data) > 1:
        context_comparison = []
        for context, scores in context_data.items():
            context_comparison.append({
                'è¯„ä¼°æƒ…å¢ƒ': context,
                'æ ·æœ¬æ•°': len(scores),
                'å¹³å‡è¡¨ç°': np.mean(scores),
                'æ ‡å‡†å·®': np.std(scores),
                'è¡¨ç°æ°´å¹³': 'è¾ƒå¥½' if np.mean(scores) < 3.0 else 'ä¸­ç­‰' if np.mean(scores) < 4.0 else 'å›°éš¾'
            })
        
        df_context = pd.DataFrame(context_comparison)
        
        fig_context = px.bar(
            df_context,
            x='è¯„ä¼°æƒ…å¢ƒ',
            y='å¹³å‡è¡¨ç°',
            color='è¡¨ç°æ°´å¹³',
            title="ä¸åŒè¯„ä¼°æƒ…å¢ƒä¸‹çš„è¡¨ç°å¯¹æ¯”",
            labels={'å¹³å‡è¡¨ç°': 'å¹³å‡å›°éš¾ç¨‹åº¦ (1-5åˆ†)'},
            height=400
        )
        st.plotly_chart(fig_context, use_container_width=True)
        
        # æ˜¾ç¤ºæƒ…å¢ƒåˆ†æè¡¨æ ¼
        st.dataframe(df_context.drop('è¡¨ç°æ°´å¹³', axis=1), use_container_width=True)
    
    # ä¸´åºŠå‘ç°å’Œå»ºè®®
    st.subheader("ğŸ” ä¸´åºŠå‘ç°ä¸å¹²é¢„å»ºè®®")
    
    if analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®'):
        col_finding1, col_finding2 = st.columns(2)
        
        with col_finding1:
            st.write("### ğŸ“‹ ä¸»è¦ä¸´åºŠå‘ç°")
            for i, finding in enumerate(analysis['ä¸´åºŠå‘ç°ä¸å»ºè®®'], 1):
                if 'å»ºè®®' in finding:
                    st.success(f"{i}. {finding}")
                elif 'ä¸¥é‡' in finding:
                    st.error(f"{i}. {finding}")
                else:
                    st.info(f"{i}. {finding}")
        
        with col_finding2:
            st.write("### ğŸ’¡ å¾ªè¯å¹²é¢„å»ºè®®")
            
            # åŸºäºè¯„ä¼°ç»“æœæä¾›å…·ä½“å»ºè®®
            social_avg = np.mean([r['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] for r in records])
            comm_avg = np.mean([r['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] for r in records])
            repetitive_avg = np.mean([r['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'] for r in records])
            
            st.write("**åŸºäºå¾ªè¯å®è·µçš„å¹²é¢„å»ºè®®**:")
            
            if social_avg >= 4.0:
                st.write("â€¢ ğŸ¯ **ç¤¾äº¤æŠ€èƒ½è®­ç»ƒ** (SST)")
                st.write("  - ç»“æ„åŒ–ç¤¾äº¤æŠ€èƒ½æ•™å­¦")
                st.write("  - åŒä¼´ä¸­ä»‹å¹²é¢„")
                st.write("  - è§†é¢‘å»ºæ¨¡æŠ€æœ¯")
            
            if comm_avg >= 4.0:
                st.write("â€¢ ğŸ—£ï¸ **æ²Ÿé€šå¹²é¢„**")
                st.write("  - åŠŸèƒ½æ€§æ²Ÿé€šè®­ç»ƒ")
                st.write("  - å›¾ç‰‡äº¤æ¢æ²Ÿé€šç³»ç»Ÿ(PECS)")
                st.write("  - è¯­è¨€è¡Œä¸ºå¹²é¢„")
            
            if repetitive_avg >= 4.0:
                st.write("â€¢ ğŸ”„ **è¡Œä¸ºå¹²é¢„**")
                st.write("  - åº”ç”¨è¡Œä¸ºåˆ†æ(ABA)")
                st.write("  - åŠŸèƒ½æ€§è¡Œä¸ºè¯„ä¼°")
                st.write("  - æ­£å‘è¡Œä¸ºæ”¯æŒ")
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒï¼ˆå¦‚æœæœ‰å¤šç»„æ•°æ®ï¼‰
    severities = [r.get('template', 'è‡ªå®šä¹‰') for r in records]
    if len(set(severities)) > 1:
        st.subheader("ğŸ“ ç»Ÿè®¡å­¦åˆ†æ")
        
        try:
            from scipy import stats
            
            # è¿›è¡Œæ–¹å·®åˆ†æ
            groups = {}
            for record in records:
                severity = record.get('template', 'è‡ªå®šä¹‰')
                if severity not in groups:
                    groups[severity] = []
                
                core_score = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                             record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                             record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                groups[severity].append(core_score)
            
            if len(groups) >= 2:
                group_values = list(groups.values())
                f_stat, p_value = stats.f_oneway(*group_values)
                
                st.write(f"**å•å› ç´ æ–¹å·®åˆ†æç»“æœ**:")
                st.write(f"- Fç»Ÿè®¡é‡: {f_stat:.3f}")
                st.write(f"- på€¼: {p_value:.3f}")
                
                if p_value < 0.05:
                    st.success("âœ… ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ (p < 0.05)")
                else:
                    st.info("â„¹ï¸ ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´å·®å¼‚æ— ç»Ÿè®¡å­¦æ„ä¹‰ (p â‰¥ 0.05)")
        
        except ImportError:
            st.info("ğŸ’¡ å®‰è£…scipyæ¨¡å—å¯å¯ç”¨ç»Ÿè®¡å­¦åˆ†æåŠŸèƒ½")

elif page == "è¯„ä¼°è®°å½•ç®¡ç†":
    st.header("ğŸ“š è¯„ä¼°è®°å½•ç®¡ç†")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.info("ğŸ“ æš‚æ— è¯„ä¼°è®°å½•")
        st.stop()
    
    st.subheader(f"ğŸ“Š å…±æœ‰ {len(records)} æ¡ä¸´åºŠè¯„ä¼°è®°å½•")
    
    # é«˜çº§ç­›é€‰é€‰é¡¹
    col_filter1, col_filter2, col_filter3, col_filter4 = st.columns(4)
    
    with col_filter1:
        severity_filter = st.selectbox(
            "æŒ‰ä¸¥é‡ç¨‹åº¦ç­›é€‰", 
            ["å…¨éƒ¨"] + list(set([r.get('template', 'è‡ªå®šä¹‰') for r in records]))
        )
    
    with col_filter2:
        context_filter = st.selectbox(
            "æŒ‰è¯„ä¼°æƒ…å¢ƒç­›é€‰",
            ["å…¨éƒ¨"] + list(set([r['scene'] for r in records]))
        )
    
    with col_filter3:
        score_filter = st.selectbox(
            "æŒ‰ä¸¥é‡ç¨‹åº¦ç­›é€‰",
            ["å…¨éƒ¨", "è½»åº¦ (1-2åˆ†)", "ä¸­åº¦ (2-3åˆ†)", "é‡åº¦ (3-4åˆ†)", "æé‡åº¦ (4-5åˆ†)"]
        )
    
    with col_filter4:
        sort_by = st.selectbox(
            "æ’åºæ–¹å¼", 
            ["æ—¶é—´å€’åº", "æ—¶é—´æ­£åº", "æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦", "ç¤¾äº¤ç¼ºé™·ç¨‹åº¦", "æ²Ÿé€šç¼ºé™·ç¨‹åº¦"]
        )
    
    # åº”ç”¨ç­›é€‰
    filtered_records = records
    
    if severity_filter != "å…¨éƒ¨":
        filtered_records = [r for r in filtered_records if r.get('template', 'è‡ªå®šä¹‰') == severity_filter]
    
    if context_filter != "å…¨éƒ¨":
        filtered_records = [r for r in filtered_records if r['scene'] == context_filter]
    
    if score_filter != "å…¨éƒ¨":
        def get_core_score(record):
            return (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                   record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                   record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        if score_filter == "è½»åº¦ (1-2åˆ†)":
            filtered_records = [r for r in filtered_records if get_core_score(r) <= 2.0]
        elif score_filter == "ä¸­åº¦ (2-3åˆ†)":
            filtered_records = [r for r in filtered_records if 2.0 < get_core_score(r) <= 3.0]
        elif score_filter == "é‡åº¦ (3-4åˆ†)":
            filtered_records = [r for r in filtered_records if 3.0 < get_core_score(r) <= 4.0]
        elif score_filter == "æé‡åº¦ (4-5åˆ†)":
            filtered_records = [r for r in filtered_records if get_core_score(r) > 4.0]
    
    # åº”ç”¨æ’åº
    if sort_by == "æ—¶é—´æ­£åº":
        filtered_records = sorted(filtered_records, key=lambda x: x['timestamp'])
    elif sort_by == "æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦":
        filtered_records = sorted(filtered_records, 
            key=lambda x: (x['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                          x['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                          x['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3, 
            reverse=True)
    elif sort_by == "ç¤¾äº¤ç¼ºé™·ç¨‹åº¦":
        filtered_records = sorted(filtered_records, 
            key=lambda x: x['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'], reverse=True)
    elif sort_by == "æ²Ÿé€šç¼ºé™·ç¨‹åº¦":
        filtered_records = sorted(filtered_records, 
            key=lambda x: x['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'], reverse=True)
    else:  # æ—¶é—´å€’åº
        filtered_records = sorted(filtered_records, key=lambda x: x['timestamp'], reverse=True)
    
    st.write(f"ç­›é€‰åè®°å½•æ•°: {len(filtered_records)}")
    
    # è®°å½•åˆ—è¡¨æ˜¾ç¤º
    for i, record in enumerate(filtered_records):
        
        # è®¡ç®—æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                        record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                        record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        severity_label = ""
        if core_severity >= 4.0:
            severity_label = "ğŸ”´ æé‡åº¦"
        elif core_severity >= 3.0:
            severity_label = "ğŸŸ  é‡åº¦"
        elif core_severity >= 2.0:
            severity_label = "ğŸŸ¡ ä¸­åº¦"
        else:
            severity_label = "ğŸŸ¢ è½»åº¦"
        
        template_info = f" - {record.get('template', 'è‡ªå®šä¹‰')}" if record.get('template') else ""
        
        with st.expander(f"ğŸ©º {record['experiment_id']}{template_info} - {record['scene']} - {severity_label} ({record['timestamp'].strftime('%Y-%m-%d %H:%M')})"):
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**ğŸ“‹ è¯„ä¼°åŸºæœ¬ä¿¡æ¯:**")
                if record.get('template'):
                    st.write(f"â€¢ ä¸¥é‡ç¨‹åº¦åˆ†çº§: {record['template']}")
                st.write(f"â€¢ è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
                st.write(f"â€¢ è§‚å¯Ÿæ´»åŠ¨: {record.get('activity', 'æœªæŒ‡å®š')}")
                st.write(f"â€¢ è§¦å‘å› ç´ : {record.get('trigger', 'æœªæŒ‡å®š')}")
                st.write(f"â€¢ è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                
                if record.get('autism_profile'):
                    st.write("**ğŸ‘¤ DSM-5ç‰¹å¾é…ç½®:**")
                    profile = record['autism_profile']
                    st.write(f"â€¢ DSM-5ä¸¥é‡ç¨‹åº¦: {profile.get('dsm5_severity', 'N/A')}")
                    st.write(f"â€¢ ç¤¾äº¤æ²Ÿé€šç¼ºé™·: {profile.get('social_communication', 'N/A')}/5")
                    st.write(f"â€¢ åˆ»æ¿é‡å¤è¡Œä¸º: {profile.get('restricted_repetitive', 'N/A')}/5")
                    st.write(f"â€¢ è®¤çŸ¥åŠŸèƒ½æ°´å¹³: {profile.get('cognitive_function', 'N/A')}/5")
                    st.write(f"â€¢ ç‰¹æ®Šå…´è¶£: {profile.get('special_interests', 'N/A')}")
            
            with col2:
                st.write("**ğŸ“Š ä¸´åºŠè¯„ä¼°å¾—åˆ†:**")
                
                scores = record['evaluation_scores']
                
                # æ ¸å¿ƒç—‡çŠ¶
                st.write("*DSM-5æ ¸å¿ƒç—‡çŠ¶:*")
                social_score = scores['ç¤¾äº¤äº’åŠ¨è´¨é‡']
                comm_score = scores['æ²Ÿé€šäº¤æµèƒ½åŠ›']
                repetitive_score = scores['åˆ»æ¿é‡å¤è¡Œä¸º']
                
                if social_score >= 4.0:
                    st.error(f"â€¢ ç¤¾äº¤äº’åŠ¨è´¨é‡: {social_score}/5 (ä¸¥é‡ç¼ºé™·)")
                elif social_score >= 3.0:
                    st.warning(f"â€¢ ç¤¾äº¤äº’åŠ¨è´¨é‡: {social_score}/5 (æ˜æ˜¾ç¼ºé™·)")
                else:
                    st.success(f"â€¢ ç¤¾äº¤äº’åŠ¨è´¨é‡: {social_score}/5 (è½»åº¦ç¼ºé™·)")
                
                if comm_score >= 4.0:
                    st.error(f"â€¢ æ²Ÿé€šäº¤æµèƒ½åŠ›: {comm_score}/5 (ä¸¥é‡ç¼ºé™·)")
                elif comm_score >= 3.0:
                    st.warning(f"â€¢ æ²Ÿé€šäº¤æµèƒ½åŠ›: {comm_score}/5 (æ˜æ˜¾ç¼ºé™·)")
                else:
                    st.success(f"â€¢ æ²Ÿé€šäº¤æµèƒ½åŠ›: {comm_score}/5 (è½»åº¦ç¼ºé™·)")
                
                if repetitive_score >= 4.0:
                    st.error(f"â€¢ åˆ»æ¿é‡å¤è¡Œä¸º: {repetitive_score}/5 (ä¸¥é‡ç¨‹åº¦)")
                elif repetitive_score >= 3.0:
                    st.warning(f"â€¢ åˆ»æ¿é‡å¤è¡Œä¸º: {repetitive_score}/5 (æ˜æ˜¾ç¨‹åº¦)")
                else:
                    st.success(f"â€¢ åˆ»æ¿é‡å¤è¡Œä¸º: {repetitive_score}/5 (è½»åº¦ç¨‹åº¦)")
                
                # ç›¸å…³åŠŸèƒ½
                st.write("*ç›¸å…³åŠŸèƒ½:*")
                st.write(f"â€¢ æ„Ÿå®˜å¤„ç†èƒ½åŠ›: {scores['æ„Ÿå®˜å¤„ç†èƒ½åŠ›']}/5")
                st.write(f"â€¢ æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚: {scores['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚']}/5")
                st.write(f"â€¢ è®¤çŸ¥é€‚åº”åŠŸèƒ½: {scores['è®¤çŸ¥é€‚åº”åŠŸèƒ½']}/5")
                
                st.write(f"**æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦: {core_severity:.2f}/5**")
            
            with col3:
                st.write("**ğŸ” ä¸´åºŠè§‚å¯Ÿè®°å½•:**")
                if 'clinical_observations' in record and record['clinical_observations']:
                    for category, observations in record['clinical_observations'].items():
                        if observations:
                            st.write(f"*{category}:*")
                            for obs in observations:
                                st.write(f"â€¢ {obs}")
                else:
                    st.write("æš‚æ— ç‰¹æ®Šä¸´åºŠè§‚å¯Ÿè®°å½•")
                
                if record.get('notes'):
                    st.write(f"**ğŸ“ å¤‡æ³¨:** {record['notes']}")
            
            # å¯¹è¯è®°å½•
            st.write("**ğŸ’¬ è¡Œä¸ºè§‚å¯Ÿå¯¹è¯è®°å½•:**")
            dialogue_lines = record['dialogue'].split('\n')
            dialogue_text = '\n'.join([line for line in dialogue_lines if line.strip() and ':' in line])
            
            unique_key = f"clinical_dialogue_{i}_{record['experiment_id']}_{record['timestamp'].strftime('%Y%m%d_%H%M%S')}"
            st.text_area("", dialogue_text, height=200, key=unique_key)
            
            # å¿«é€Ÿæ“ä½œæŒ‰é’®
            col_btn1, col_btn2, col_btn3 = st.columns(3)
            
            with col_btn1:
                if st.button(f"ğŸ“‹ ç”Ÿæˆä¸ªæ¡ˆæŠ¥å‘Š", key=f"report_{record['experiment_id']}"):
                    st.info("ä¸ªæ¡ˆæŠ¥å‘Šç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­...")
            
            with col_btn2:
                if st.button(f"ğŸ“ˆ è¶‹åŠ¿åˆ†æ", key=f"trend_{record['experiment_id']}"):
                    st.info("ä¸ªä½“è¶‹åŠ¿åˆ†æåŠŸèƒ½å¼€å‘ä¸­...")
            
            with col_btn3:
                if st.button(f"ğŸ”„ é‡å¤è¯„ä¼°", key=f"repeat_{record['experiment_id']}"):
                    st.info("é‡å¤è¯„ä¼°åŠŸèƒ½å¼€å‘ä¸­...")

elif page == "ğŸ“Š ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒ":
    st.header("ğŸ“Š ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒ")
    st.markdown("åŸºäºå¾ªè¯å®è·µç”Ÿæˆä¸“ä¸šçš„ä¸´åºŠè¯„ä¼°æŠ¥å‘Šå’Œç ”ç©¶æ•°æ®")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.warning("ğŸ“Š æš‚æ— è¯„ä¼°æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œä¸´åºŠè¯„ä¼°")
        st.stop()
    
    st.success(f"ğŸ“Š å½“å‰å…±æœ‰ {len(records)} æ¡ä¸´åºŠè¯„ä¼°è®°å½•å¯ç”ŸæˆæŠ¥å‘Š")
    
    # æŠ¥å‘Šç±»å‹é€‰æ‹©
    st.subheader("ğŸ“‹ é€‰æ‹©æŠ¥å‘Šç±»å‹")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### ğŸ“„ æ ‡å‡†ä¸´åºŠæŠ¥å‘Š")
        
        # åŸºç¡€CSVæŠ¥å‘Š
        if st.button("ğŸ“Š ä¸‹è½½åŸºç¡€è¯„ä¼°æ•°æ® (CSV)", use_container_width=True):
            df_export = []
            for record in records:
                export_row = {
                    'è¯„ä¼°ID': record['experiment_id'],
                    'è¯„ä¼°æ—¶é—´': record['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                    'ä¸¥é‡ç¨‹åº¦åˆ†çº§': record.get('template', 'è‡ªå®šä¹‰'),
                    'è¯„ä¼°æƒ…å¢ƒ': record['scene'],
                    'è§‚å¯Ÿæ´»åŠ¨': record.get('activity', ''),
                    'è§¦å‘å› ç´ ': record.get('trigger', ''),
                    'ç¤¾äº¤äº’åŠ¨ç¼ºé™·ç¨‹åº¦': record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'],
                    'æ²Ÿé€šäº¤æµç¼ºé™·ç¨‹åº¦': record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'],
                    'åˆ»æ¿é‡å¤è¡Œä¸ºç¨‹åº¦': record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'],
                    'æ„Ÿå®˜å¤„ç†å¼‚å¸¸ç¨‹åº¦': record['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'],
                    'æƒ…ç»ªè°ƒèŠ‚å›°éš¾ç¨‹åº¦': record['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'],
                    'è®¤çŸ¥é€‚åº”ç¼ºé™·ç¨‹åº¦': record['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½'],
                    'å¤‡æ³¨': record.get('notes', '')
                }
                
                # æ·»åŠ DSM-5ç‰¹å¾
                if record.get('autism_profile'):
                    profile = record['autism_profile']
                    export_row.update({
                        'DSM5ä¸¥é‡ç¨‹åº¦': profile.get('dsm5_severity', ''),
                        'æ‰€éœ€æ”¯æŒæ°´å¹³': profile.get('support_needs', ''),
                        'ç¤¾äº¤æ²Ÿé€šç¼ºé™·è®¾ç½®': profile.get('social_communication', ''),
                        'åˆ»æ¿é‡å¤è¡Œä¸ºè®¾ç½®': profile.get('restricted_repetitive', ''),
                        'æ„Ÿå®˜å¤„ç†å¼‚å¸¸è®¾ç½®': profile.get('sensory_processing', ''),
                        'è®¤çŸ¥åŠŸèƒ½æ°´å¹³è®¾ç½®': profile.get('cognitive_function', ''),
                        'é€‚åº”è¡Œä¸ºèƒ½åŠ›è®¾ç½®': profile.get('adaptive_behavior', ''),
                        'è¯­è¨€å‘å±•æ°´å¹³è®¾ç½®': profile.get('language_level', ''),
                        'ç‰¹æ®Šå…´è¶£æè¿°': profile.get('special_interests', '')
                    })
                
                # è®¡ç®—æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦
                core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                               record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                               record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                export_row['æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦'] = round(core_severity, 2)
                
                df_export.append(export_row)
            
            df = pd.DataFrame(df_export)
            csv = df.to_csv(index=False, encoding='utf-8-sig')
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ä¸´åºŠè¯„ä¼°æ•°æ®",
                data=csv,
                file_name=f"autism_clinical_assessment_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv'
            )
        
        # å¯¹è¯è®°å½•ä¸‹è½½
        if st.button("ğŸ’¬ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½• (TXT)", use_container_width=True):
            observation_content = []
            observation_content.append("=" * 70)
            observation_content.append("å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¡Œä¸ºè§‚å¯Ÿè®°å½•")
            observation_content.append("åŸºäºDSM-5è¯Šæ–­æ ‡å‡† | å¾ªè¯è¯„ä¼°å·¥å…·")
            observation_content.append("=" * 70)
            observation_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            observation_content.append(f"è¯„ä¼°è®°å½•æ€»æ•°: {len(records)}")
            observation_content.append("=" * 70)
            observation_content.append("")
            
            for i, record in enumerate(records, 1):
                core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                               record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                               record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                
                observation_content.append(f"\nã€ä¸´åºŠè¯„ä¼° {i}ã€‘")
                observation_content.append(f"è¯„ä¼°ID: {record['experiment_id']}")
                observation_content.append(f"è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                observation_content.append(f"ä¸¥é‡ç¨‹åº¦åˆ†çº§: {record.get('template', 'è‡ªå®šä¹‰')}")
                observation_content.append(f"è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
                observation_content.append(f"è§‚å¯Ÿæ´»åŠ¨: {record.get('activity', 'æœªæŒ‡å®š')}")
                observation_content.append(f"è§¦å‘å› ç´ : {record.get('trigger', 'æœªæŒ‡å®š')}")
                
                if record.get('autism_profile'):
                    profile = record['autism_profile']
                    observation_content.append(f"DSM-5ä¸¥é‡ç¨‹åº¦: {profile.get('dsm5_severity', '')}")
                    observation_content.append(f"æ‰€éœ€æ”¯æŒæ°´å¹³: {profile.get('support_needs', '')}")
                
                observation_content.append(f"æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦: {core_severity:.2f}/5.0")
                observation_content.append("-" * 50)
                
                observation_content.append("ä¸´åºŠè¯„ä¼°å¾—åˆ†:")
                for metric, score in record['evaluation_scores'].items():
                    observation_content.append(f"  â€¢ {metric}: {score}/5.0")
                
                if 'clinical_observations' in record and record['clinical_observations']:
                    observation_content.append("ä¸´åºŠè§‚å¯Ÿè¦ç‚¹:")
                    for category, observations in record['clinical_observations'].items():
                        if observations:
                            observation_content.append(f"  {category}: {', '.join(observations)}")
                
                observation_content.append("è¡Œä¸ºè§‚å¯Ÿå¯¹è¯:")
                observation_content.append(record['dialogue'])
                observation_content.append("-" * 50)
                observation_content.append("")
            
            observation_text = '\n'.join(observation_content)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½•",
                data=observation_text.encode('utf-8'),
                file_name=f"autism_clinical_observations_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime='text/plain'
            )
        
        # JSONå®Œæ•´æ•°æ®
        if st.button("ğŸ”§ ä¸‹è½½å®Œæ•´ä¸´åºŠæ•°æ® (JSON)", use_container_width=True):
            json_data = {
                'clinical_assessment_report': {
                    'report_metadata': {
                        'generation_time': datetime.datetime.now().isoformat(),
                        'assessment_standard': 'DSM-5è¯Šæ–­æ ‡å‡†',
                        'evaluation_tools': 'CARS, ABC, SCQ, M-CHATå‚è€ƒ',
                        'total_assessments': len(records),
                        'platform_version': 'åŒ»å­¦æ ‡å‡†ç‰ˆ v1.0'
                    },
                    'assessment_summary': generate_clinical_analysis(records),
                    'detailed_assessments': []
                }
            }
            
            for record in records:
                clinical_record = record.copy()
                clinical_record['timestamp'] = record['timestamp'].isoformat()
                
                # æ·»åŠ è®¡ç®—å­—æ®µ
                core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                               record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                               record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                clinical_record['core_symptom_severity'] = round(core_severity, 2)
                
                json_data['clinical_assessment_report']['detailed_assessments'].append(clinical_record)
            
            json_str = json.dumps(json_data, ensure_ascii=False, indent=2)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ä¸´åºŠæ•°æ®",
                data=json_str.encode('utf-8'),
                file_name=f"autism_clinical_complete_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime='application/json'
            )
    
    with col2:
        st.write("### ğŸ“ˆ ä¸“ä¸šåˆ†ææŠ¥å‘Š")
        
        # ç”Ÿæˆä¸´åºŠåˆ†ææŠ¥å‘Š
        if st.button("ğŸ“Š ç”Ÿæˆä¸´åºŠç»Ÿè®¡åˆ†æ", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”Ÿæˆä¸´åºŠåˆ†ææŠ¥å‘Š..."):
                analysis = generate_clinical_analysis(records)
            
            st.success("âœ… ä¸´åºŠåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            
            # æ˜¾ç¤ºåˆ†æé¢„è§ˆ
            with st.expander("ğŸ“‹ ä¸´åºŠåˆ†ææŠ¥å‘Šé¢„è§ˆ", expanded=True):
                if analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ'):
                    st.write("**ä¸´åºŠè¯„ä¼°æ¦‚å†µ:**")
                    for key, value in analysis['ä¸´åºŠè¯„ä¼°æ¦‚å†µ'].items():
                        st.write(f"- {key}: {value}")
                
                if analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°'):
                    st.write("**æ•´ä½“ä¸´åºŠè¡¨ç°:**")
                    for key, value in analysis['æ•´ä½“ä¸´åºŠè¡¨ç°'].items():
                        st.write(f"- {key}: {value}")
                
                if analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®'):
                    st.write("**ä¸´åºŠå‘ç°ä¸å»ºè®®:**")
                    for finding in analysis['ä¸´åºŠå‘ç°ä¸å»ºè®®']:
                        st.write(f"- {finding}")
            
            # æä¾›åˆ†ææŠ¥å‘Šä¸‹è½½
            analysis_json = json.dumps(analysis, ensure_ascii=False, indent=2)
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ä¸´åºŠåˆ†ææŠ¥å‘Š (JSON)",
                data=analysis_json.encode('utf-8'),
                file_name=f"autism_clinical_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime='application/json'
            )
        
        # Excelä¸“ä¸šæŠ¥å‘Š
        if EXCEL_AVAILABLE:
            if st.button("ğŸ“‹ ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š..."):
                    analysis = generate_clinical_analysis(records)
                    excel_data = create_clinical_excel_report(records, analysis)
                
                if excel_data:
                    st.success("âœ… ä¸“ä¸šExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                    
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½ä¸“ä¸šExcelæŠ¥å‘Š",
                        data=excel_data,
                        file_name=f"autism_clinical_professional_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )
                else:
                    st.error("âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ ¼å¼")
        else:
            st.info("ğŸ’¡ ExcelæŠ¥å‘ŠåŠŸèƒ½éœ€è¦å®‰è£…openpyxlæ¨¡å—")
            st.code("pip install openpyxl")
            
            # æ›¿ä»£è¯¦ç»†æŠ¥å‘Š
            if st.button("ğŸ“Š ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š..."):
                    analysis = generate_clinical_analysis(records)
                
                # åˆ›å»ºè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
                detailed_report = []
                detailed_report.append("å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¯„ä¼°è¯¦ç»†æŠ¥å‘Š")
                detailed_report.append("=" * 50)
                detailed_report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                detailed_report.append(f"è¯„ä¼°æ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡†")
                detailed_report.append(f"å‚è€ƒå·¥å…·: CARS, ABC, SCQ, M-CHATé‡è¡¨")
                detailed_report.append("")
                
                # æ·»åŠ ä¸´åºŠè¯„ä¼°æ¦‚å†µ
                detailed_report.append("ä¸€ã€ä¸´åºŠè¯„ä¼°æ¦‚å†µ")
                detailed_report.append("-" * 30)
                for key, value in analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ', {}).items():
                    detailed_report.append(f"{key}: {value}")
                detailed_report.append("")
                
                # æ·»åŠ æ•´ä½“è¡¨ç°
                detailed_report.append("äºŒã€æ•´ä½“ä¸´åºŠè¡¨ç°")
                detailed_report.append("-" * 30)
                for key, value in analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°', {}).items():
                    detailed_report.append(f"{key}: {value}")
                detailed_report.append("")
                
                # æ·»åŠ ä¸¥é‡ç¨‹åº¦åˆ†æ
                if analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†æ'):
                    detailed_report.append("ä¸‰ã€ä¸¥é‡ç¨‹åº¦ç»„é—´åˆ†æ")
                    detailed_report.append("-" * 30)
                    for severity, stats in analysis['ä¸¥é‡ç¨‹åº¦åˆ†æ'].items():
                        detailed_report.append(f"\n{severity} (n={stats['è¯„ä¼°æ¬¡æ•°']}):")
                        detailed_report.append(f"  - ç¤¾äº¤äº’åŠ¨ç¼ºé™·: {stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼']:.2f} Â± {stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_æ ‡å‡†å·®']:.2f}")
                        detailed_report.append(f"  - æ²Ÿé€šäº¤æµç¼ºé™·: {stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼']:.2f} Â± {stats['æ²Ÿé€šäº¤æµå¾—åˆ†_æ ‡å‡†å·®']:.2f}")
                        detailed_report.append(f"  - åˆ»æ¿é‡å¤è¡Œä¸º: {stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']:.2f} Â± {stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_æ ‡å‡†å·®']:.2f}")
                    detailed_report.append("")
                
                # æ·»åŠ ä¸´åºŠå‘ç°
                detailed_report.append("å››ã€ä¸´åºŠå‘ç°ä¸å»ºè®®")
                detailed_report.append("-" * 30)
                for i, finding in enumerate(analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []), 1):
                    detailed_report.append(f"{i}. {finding}")
                detailed_report.append("")
                
                # æ·»åŠ ä¸ªæ¡ˆæ˜ç»†
                detailed_report.append("äº”ã€ä¸ªæ¡ˆè¯„ä¼°æ˜ç»†")
                detailed_report.append("-" * 30)
                for i, record in enumerate(records, 1):
                    core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                                   record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                                   record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                    
                    detailed_report.append(f"\nä¸ªæ¡ˆ {i}: {record['experiment_id']}")
                    detailed_report.append(f"  è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M')}")
                    detailed_report.append(f"  ä¸¥é‡ç¨‹åº¦: {record.get('template', 'è‡ªå®šä¹‰')}")
                    detailed_report.append(f"  è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
                    detailed_report.append(f"  æ ¸å¿ƒç—‡çŠ¶ç»¼åˆ: {core_severity:.2f}/5.0")
                    
                    severity_level = "è½»åº¦" if core_severity < 2.5 else "ä¸­åº¦" if core_severity < 3.5 else "é‡åº¦"
                    detailed_report.append(f"  ä¸¥é‡ç¨‹åº¦åˆ¤æ–­: {severity_level}")
                
                report_content = '\n'.join(detailed_report)
                
                st.success("âœ… è¯¦ç»†æ–‡æœ¬æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š",
                    data=report_content.encode('utf-8'),
                    file_name=f"autism_clinical_detailed_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime='text/plain'
                )
        
        # ç ”ç©¶æ•°æ®åŒ…
        if st.button("ğŸ“¦ ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…", use_container_width=True, type="primary"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…..."):
                # ç”Ÿæˆåˆ†æ
                analysis = generate_clinical_analysis(records)
                
                # åˆ›å»ºåŸºç¡€CSV
                df_basic = []
                for record in records:
                    core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                                   record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                                   record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
                    
                    row = {
                        'è¯„ä¼°ID': record['experiment_id'],
                        'è¯„ä¼°æ—¶é—´': record['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
                        'ä¸¥é‡ç¨‹åº¦åˆ†çº§': record.get('template', 'è‡ªå®šä¹‰'),
                        'è¯„ä¼°æƒ…å¢ƒ': record['scene'],
                        'è§‚å¯Ÿæ´»åŠ¨': record.get('activity', ''),
                        'è§¦å‘å› ç´ ': record.get('trigger', ''),
                        'ç¤¾äº¤äº’åŠ¨ç¼ºé™·': record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'],
                        'æ²Ÿé€šäº¤æµç¼ºé™·': record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'],
                        'åˆ»æ¿é‡å¤è¡Œä¸º': record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º'],
                        'æ„Ÿå®˜å¤„ç†å¼‚å¸¸': record['evaluation_scores']['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'],
                        'æƒ…ç»ªè°ƒèŠ‚å›°éš¾': record['evaluation_scores']['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'],
                        'è®¤çŸ¥é€‚åº”ç¼ºé™·': record['evaluation_scores']['è®¤çŸ¥é€‚åº”åŠŸèƒ½'],
                        'æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦': round(core_severity, 2),
                        'å¤‡æ³¨': record.get('notes', '')
                    }
                    
                    # æ·»åŠ DSM-5é…ç½®
                    if record.get('autism_profile'):
                        profile = record['autism_profile']
                        row.update({
                            'DSM5ä¸¥é‡ç¨‹åº¦': profile.get('dsm5_severity', ''),
                            'æ‰€éœ€æ”¯æŒæ°´å¹³': profile.get('support_needs', ''),
                            'ç¤¾äº¤æ²Ÿé€šç¼ºé™·è®¾ç½®': profile.get('social_communication', ''),
                            'åˆ»æ¿é‡å¤è¡Œä¸ºè®¾ç½®': profile.get('restricted_repetitive', ''),
                            'æ„Ÿå®˜å¤„ç†è®¾ç½®': profile.get('sensory_processing', ''),
                            'è®¤çŸ¥åŠŸèƒ½è®¾ç½®': profile.get('cognitive_function', ''),
                            'é€‚åº”è¡Œä¸ºè®¾ç½®': profile.get('adaptive_behavior', ''),
                            'è¯­è¨€å‘å±•è®¾ç½®': profile.get('language_level', ''),
                            'ç‰¹æ®Šå…´è¶£': profile.get('special_interests', '')
                        })
                    
                    df_basic.append(row)
                
                # åˆ›å»ºå®Œæ•´æ•°æ®JSON
                complete_data = {
                    'research_metadata': {
                        'generation_time': datetime.datetime.now().isoformat(),
                        'assessment_standard': 'DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡†',
                        'evaluation_framework': 'åŸºäºCARS, ABC, SCQ, M-CHATç­‰æƒå¨é‡è¡¨',
                        'total_assessments': len(records),
                        'platform_version': 'åŒ»å­¦æ ‡å‡†ç‰ˆ v1.0'
                    },
                    'statistical_analysis': analysis,
                    'raw_assessment_data': []
                }
                
                for record in records:
                    research_record = record.copy()
                    research_record['timestamp'] = record['timestamp'].isoformat()
                    complete_data['raw_assessment_data'].append(research_record)
            
            st.success("âœ… å®Œæ•´ç ”ç©¶æ•°æ®åŒ…ç”Ÿæˆå®Œæˆï¼")
            
            # åˆ›å»ºZIPæ–‡ä»¶
            zip_buffer = io.BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                
                # 1. åŸºç¡€è¯„ä¼°æ•°æ®
                csv_data = pd.DataFrame(df_basic).to_csv(index=False, encoding='utf-8-sig')
                zip_file.writestr("01_åŸºç¡€è¯„ä¼°æ•°æ®.csv", csv_data)
                
                # 2. Excelä¸“ä¸šæŠ¥å‘Šï¼ˆå¦‚æœå¯ç”¨ï¼‰
                excel_data = None
                if EXCEL_AVAILABLE:
                    try:
                        excel_data = create_clinical_excel_report(records, analysis)
                        if excel_data:
                            zip_file.writestr("02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx", excel_data)
                    except Exception as e:
                        pass  # å¦‚æœExcelç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡
                
                if not excel_data:
                    # ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Šä½œä¸ºæ›¿ä»£
                    detailed_report = []
                    detailed_report.append("å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¯„ä¼°ä¸“ä¸šæŠ¥å‘Š")
                    detailed_report.append("åŸºäºDSM-5è¯Šæ–­æ ‡å‡†")
                    detailed_report.append("=" * 60)
                    detailed_report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    detailed_report.append(f"è¯„ä¼°æ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è°±ç³»éšœç¢è¯Šæ–­æ ‡å‡†")
                    detailed_report.append(f"å‚è€ƒé‡è¡¨: CARS, ABC, SCQ, M-CHAT")
                    detailed_report.append("")
                    
                    # ä¸´åºŠæ¦‚å†µ
                    detailed_report.append("ä¸€ã€ä¸´åºŠè¯„ä¼°æ¦‚å†µ")
                    detailed_report.append("-" * 40)
                    for key, value in analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ', {}).items():
                        detailed_report.append(f"{key}: {value}")
                    
                    # æ•´ä½“è¡¨ç°
                    detailed_report.append("\näºŒã€æ•´ä½“ä¸´åºŠè¡¨ç°")
                    detailed_report.append("-" * 40)
                    for key, value in analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°', {}).items():
                        detailed_report.append(f"{key}: {value}")
                    
                    # ä¸´åºŠå‘ç°
                    detailed_report.append("\nä¸‰ã€ä¸´åºŠå‘ç°ä¸å»ºè®®")
                    detailed_report.append("-" * 40)
                    for i, finding in enumerate(analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []), 1):
                        detailed_report.append(f"{i}. {finding}")
                    
                    report_text = '\n'.join(detailed_report)
                    zip_file.writestr("02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt", report_text.encode('utf-8'))
                
                # 3. å®Œæ•´ç ”ç©¶æ•°æ®
                json_str = json.dumps(complete_data, ensure_ascii=False, indent=2)
                zip_file.writestr("03_å®Œæ•´ç ”ç©¶æ•°æ®.json", json_str.encode('utf-8'))
                
                # 4. è¡Œä¸ºè§‚å¯Ÿè®°å½•
                observation_content = []
                observation_content.append("å­¤ç‹¬ç—‡å„¿ç«¥è¡Œä¸ºè§‚å¯Ÿè®°å½•é›†")
                observation_content.append("=" * 50)
                observation_content.append(f"è§‚å¯Ÿæ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡†")
                observation_content.append(f"è®°å½•æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                observation_content.append(f"è§‚å¯Ÿæ¡ˆä¾‹æ•°: {len(records)}")
                observation_content.append("")
                
                for i, record in enumerate(records, 1):
                    observation_content.append(f"\nã€è§‚å¯Ÿè®°å½• {i}ã€‘")
                    observation_content.append(f"è¯„ä¼°ID: {record['experiment_id']}")
                    observation_content.append(f"æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                    observation_content.append(f"ä¸¥é‡ç¨‹åº¦: {record.get('template', 'è‡ªå®šä¹‰')}")
                    observation_content.append(f"æƒ…å¢ƒ: {record['scene']}")
                    observation_content.append(f"æ´»åŠ¨: {record.get('activity', '')}")
                    observation_content.append(f"è§¦å‘å› ç´ : {record.get('trigger', '')}")
                    observation_content.append("-" * 30)
                    observation_content.append("è¡Œä¸ºè§‚å¯Ÿå¯¹è¯:")
                    observation_content.append(record['dialogue'])
                    observation_content.append("-" * 30)
                    observation_content.append("")
                
                obs_text = '\n'.join(observation_content)
                zip_file.writestr("04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt", obs_text.encode('utf-8'))
                
                # 5. ç ”ç©¶è¯´æ˜æ–‡æ¡£
                readme_content = f"""
å­¤ç‹¬ç—‡å„¿ç«¥AIæ¨¡æ‹Ÿå®éªŒå¹³å° - åŒ»å­¦æ ‡å‡†ç‰ˆ
ç ”ç©¶æ•°æ®åŒ…è¯´æ˜æ–‡æ¡£
======================================

ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
è¯„ä¼°è®°å½•æ•°: {len(records)}
è¯„ä¼°æ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è°±ç³»éšœç¢è¯Šæ–­æ ‡å‡†

æ–‡ä»¶è¯´æ˜:
--------
1. 01_åŸºç¡€è¯„ä¼°æ•°æ®.csv
   - åŒ…å«æ‰€æœ‰è¯„ä¼°çš„æ ¸å¿ƒæ•°æ®
   - é€‚ç”¨äºç»Ÿè®¡åˆ†æå’Œæ•°æ®å¯è§†åŒ–
   - åŒ…å«DSM-5ç‰¹å¾é…ç½®å’Œè¯„ä¼°å¾—åˆ†

"""
                if excel_data:
                    readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx
   - å¤šå·¥ä½œè¡¨Excelä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æã€å›¾è¡¨å’Œä¸´åºŠè§£é‡Š
   - é€‚ç”¨äºä¸´åºŠæŠ¥å‘Šå’Œå­¦æœ¯ç ”ç©¶
"""
                else:
                    readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt
   - è¯¦ç»†çš„æ–‡æœ¬æ ¼å¼ä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æå’Œä¸´åºŠè§£é‡Š
   - æ³¨æ„: ExcelåŠŸèƒ½ä¸å¯ç”¨ï¼Œå¦‚éœ€Excelæ ¼å¼è¯·å®‰è£…openpyxl
"""

                readme_content += """
3. 03_å®Œæ•´ç ”ç©¶æ•°æ®.json
   - åŒ…å«æ‰€æœ‰åŸå§‹æ•°æ®å’Œå…ƒæ•°æ®
   - é€‚ç”¨äºç¨‹åºå¤„ç†å’Œæ·±åº¦åˆ†æ
   - åŒ…å«å®Œæ•´çš„ä¸´åºŠè§‚å¯Ÿè®°å½•

4. 04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt
   - æ‰€æœ‰è¯„ä¼°çš„å¯¹è¯è®°å½•
   - ç”¨äºè´¨æ€§åˆ†æå’Œè¡Œä¸ºæ¨¡å¼ç ”ç©¶
   - ç¬¦åˆä¸´åºŠè§‚å¯Ÿè®°å½•æ ¼å¼

5. README.txt
   - æœ¬è¯´æ˜æ–‡æ¡£

è¯„ä¼°æŒ‡æ ‡è¯´æ˜:
-----------
æ‰€æœ‰è¯„ä¼°å¾—åˆ†é‡‡ç”¨1-5åˆ†åˆ¶ï¼Œå…¶ä¸­:
- 1åˆ†: æ— æ˜æ˜¾é—®é¢˜/æ­£å¸¸èŒƒå›´
- 2åˆ†: è½»åº¦é—®é¢˜/éœ€è¦å…³æ³¨
- 3åˆ†: ä¸­åº¦é—®é¢˜/éœ€è¦æ”¯æŒ
- 4åˆ†: æ˜æ˜¾é—®é¢˜/éœ€è¦å¤§é‡æ”¯æŒ
- 5åˆ†: ä¸¥é‡é—®é¢˜/éœ€è¦éå¸¸å¤§é‡æ”¯æŒ

æ ¸å¿ƒç—‡çŠ¶è¯„ä¼°:
- ç¤¾äº¤äº’åŠ¨è´¨é‡: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Aæ¡ç›®
- æ²Ÿé€šäº¤æµèƒ½åŠ›: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Aæ¡ç›®
- åˆ»æ¿é‡å¤è¡Œä¸º: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Bæ¡ç›®

ç›¸å…³åŠŸèƒ½è¯„ä¼°:
- æ„Ÿå®˜å¤„ç†èƒ½åŠ›: æ„Ÿå®˜å¼‚å¸¸å’Œæ„Ÿå®˜å¯»æ±‚/é€ƒé¿è¡Œä¸º
- æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚: æƒ…ç»ªè¯†åˆ«ã€è¡¨è¾¾å’Œè°ƒèŠ‚èƒ½åŠ›
- è®¤çŸ¥é€‚åº”åŠŸèƒ½: å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”æ€§è¡Œä¸º

ä½¿ç”¨å»ºè®®:
--------
1. ä¸´åºŠåº”ç”¨:
   - ä½¿ç”¨åŸºç¡€æ•°æ®è¿›è¡Œç­›æŸ¥å’Œè¯„ä¼°
   - å‚è€ƒä¸“ä¸šæŠ¥å‘Šåˆ¶å®šå¹²é¢„è®¡åˆ’
   - ç»“åˆè¡Œä¸ºè§‚å¯Ÿè¿›è¡Œä¸ªæ¡ˆåˆ†æ

2. ç ”ç©¶åº”ç”¨:
   - ä½¿ç”¨å®Œæ•´æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ
   - å¯¹ç…§ç»„ç ”ç©¶å’Œçºµå‘ç ”ç©¶
   - å¹²é¢„æ•ˆæœè¯„ä¼°

3. æ•™å­¦åº”ç”¨:
   - æ¡ˆä¾‹æ•™å­¦å’Œä¸´åºŠåŸ¹è®­
   - è¯„ä¼°å·¥å…·ä½¿ç”¨åŸ¹è®­
   - è¡Œä¸ºè§‚å¯ŸæŠ€èƒ½è®­ç»ƒ

æŠ€æœ¯æ”¯æŒ:
--------
- å¦‚éœ€ExcelåŠŸèƒ½ï¼Œè¯·å®‰è£…: pip install openpyxl
- æ•°æ®åˆ†æå»ºè®®ä½¿ç”¨: pandas, numpy, scipy
- å¯è§†åŒ–å»ºè®®ä½¿ç”¨: matplotlib, plotly

å‚è€ƒæ ‡å‡†:
--------
- American Psychiatric Association. (2013). DSM-5
- Childhood Autism Rating Scale (CARS)
- Autism Behavior Checklist (ABC)
- Social Communication Questionnaire (SCQ)
- Modified Checklist for Autism in Toddlers (M-CHAT)

è´¨é‡ä¿è¯:
--------
æœ¬å¹³å°åŸºäºæœ€æ–°çš„DSM-5è¯Šæ–­æ ‡å‡†å’Œæƒå¨è¯„ä¼°å·¥å…·è®¾è®¡ï¼Œ
æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡å‡å‚è€ƒå›½é™…è®¤å¯çš„å­¤ç‹¬ç—‡è¯„ä¼°é‡è¡¨ï¼Œ
ç¡®ä¿è¯„ä¼°ç»“æœçš„ä¸“ä¸šæ€§å’Œå¯é æ€§ã€‚

ç‰ˆæƒå£°æ˜:
--------
æœ¬æ•°æ®åŒ…ä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä¸´åºŠå®è·µä½¿ç”¨ï¼Œ
è¯·éµå¾ªç›¸å…³ä¼¦ç†è§„èŒƒå’Œæ•°æ®ä¿æŠ¤æ³•è§„ã€‚
"""
                zip_file.writestr("README.txt", readme_content)
            
            zip_buffer.seek(0)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ç ”ç©¶æ•°æ®åŒ… (ZIP)",
                data=zip_buffer.getvalue(),
                file_name=f"autism_clinical_research_package_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                mime='application/zip'
            )
    
    # æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ
    st.subheader("ğŸ“ˆ æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ")
    
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    
    with col_stat1:
        st.metric("ä¸´åºŠè¯„ä¼°æ€»æ•°", len(records))
    
    with col_stat2:
        severities = [r.get('template', 'è‡ªå®šä¹‰') for r in records]
        unique_severities = len(set(severities))
        st.metric("æ¶‰åŠä¸¥é‡ç¨‹åº¦ç±»å‹", unique_severities)
    
    with col_stat3:
        contexts = [r['scene'] for r in records]
        unique_contexts = len(set(contexts))
        st.metric("æ¶‰åŠè¯„ä¼°æƒ…å¢ƒ", unique_contexts)
    
    with col_stat4:
        if records:
            time_span = (max(r['timestamp'] for r in records) - min(r['timestamp'] for r in records)).days
            st.metric("è¯„ä¼°æ—¶é—´è·¨åº¦(å¤©)", time_span)
    
    # ä¸´åºŠæ•°æ®é¢„è§ˆ
    st.subheader("ğŸ“Š ä¸´åºŠæ•°æ®é¢„è§ˆ")
    
    preview_data = []
    for record in records[:10]:
        # è®¡ç®—æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                        record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                        record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        severity_level = "è½»åº¦" if core_severity < 2.5 else "ä¸­åº¦" if core_severity < 3.5 else "é‡åº¦"
        
        preview_data.append({
            'è¯„ä¼°ID': record['experiment_id'][:25] + '...' if len(record['experiment_id']) > 25 else record['experiment_id'],
            'æ—¶é—´': record['timestamp'].strftime('%m-%d %H:%M'),
            'ä¸¥é‡ç¨‹åº¦': record.get('template', 'è‡ªå®šä¹‰')[:8] + '...' if len(record.get('template', 'è‡ªå®šä¹‰')) > 8 else record.get('template', 'è‡ªå®šä¹‰'),
            'è¯„ä¼°æƒ…å¢ƒ': record['scene'].replace('ç»“æ„åŒ–', 'ç»“æ„'),
            'æ ¸å¿ƒç—‡çŠ¶': f"{core_severity:.2f}",
            'ç¨‹åº¦åˆ¤æ–­': severity_level
        })
    
    df_preview = pd.DataFrame(preview_data)
    st.dataframe(df_preview, use_container_width=True)
    
    if len(records) > 10:
        st.info(f"æ˜¾ç¤ºå‰10æ¡è®°å½•ï¼Œå…±{len(records)}æ¡ã€‚å®Œæ•´æ•°æ®è¯·é€šè¿‡ä¸Šæ–¹ä¸‹è½½åŠŸèƒ½è·å–ã€‚")

# ä¾§è¾¹æ é¢å¤–ä¿¡æ¯
st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ“ˆ è¯„ä¼°ç»Ÿè®¡")
if st.session_state.experiment_records:
    st.sidebar.metric("è¯„ä¼°æ€»æ•°", len(st.session_state.experiment_records))
    recent_record = st.session_state.experiment_records[-1]
    st.sidebar.write(f"æœ€è¿‘è¯„ä¼°: {recent_record['timestamp'].strftime('%m-%d %H:%M')}")
    
    # æ˜¾ç¤ºä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
    severities = [r.get('template', 'è‡ªå®šä¹‰') for r in st.session_state.experiment_records]
    severity_counts = pd.Series(severities).value_counts()
    st.sidebar.write("**ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:**")
    for severity, count in severity_counts.items():
        short_name = severity.split('ï¼ˆ')[0] if 'ï¼ˆ' in severity else severity
        st.sidebar.write(f"- {short_name}: {count}")
    
    # æ ¸å¿ƒç—‡çŠ¶ç»Ÿè®¡
    all_core_scores = []
    for r in st.session_state.experiment_records:
        core_score = (r['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                     r['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                     r['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        all_core_scores.append(core_score)
    
    avg_core = np.mean(all_core_scores)
    st.sidebar.metric("å¹³å‡æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦", f"{avg_core:.2f}/5")
    
    if avg_core >= 4.0:
        st.sidebar.error("æ•´ä½“è¯„ä¼°æ˜¾ç¤ºé‡åº¦ç—‡çŠ¶")
    elif avg_core >= 3.0:
        st.sidebar.warning("æ•´ä½“è¯„ä¼°æ˜¾ç¤ºä¸­åº¦ç—‡çŠ¶")
    else:
        st.sidebar.success("æ•´ä½“è¯„ä¼°æ˜¾ç¤ºè½»åº¦ç—‡çŠ¶")
        
else:
    st.sidebar.write("æš‚æ— è¯„ä¼°æ•°æ®")

st.sidebar.markdown("---")
st.sidebar.markdown("### â„¹ï¸ åŒ»å­¦æ ‡å‡†è¯´æ˜")
st.sidebar.markdown("""
**è¯„ä¼°æ ‡å‡†**: DSM-5å­¤ç‹¬ç—‡è°±ç³»éšœç¢è¯Šæ–­æ ‡å‡†

**æ ¸å¿ƒç—‡çŠ¶**:
- A. ç¤¾äº¤æ²Ÿé€šç¼ºé™·
- B. åˆ»æ¿é‡å¤è¡Œä¸ºæ¨¡å¼

**å‚è€ƒé‡è¡¨**:
- CARS: å„¿ç«¥å­¤ç‹¬ç—‡è¯„å®šé‡è¡¨
- ABC: å­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨  
- SCQ: ç¤¾äº¤æ²Ÿé€šé—®å·
- M-CHAT: ä¿®è®¢ç‰ˆå­¤ç‹¬ç—‡ç­›æŸ¥é‡è¡¨

**ä¸¥é‡ç¨‹åº¦åˆ†çº§**:
1. éœ€è¦æ”¯æŒï¼ˆè½»åº¦ï¼‰
2. éœ€è¦å¤§é‡æ”¯æŒï¼ˆä¸­åº¦ï¼‰
3. éœ€è¦éå¸¸å¤§é‡æ”¯æŒï¼ˆé‡åº¦ï¼‰
""")

if not EXCEL_AVAILABLE:
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ’¡ åŠŸèƒ½æç¤º")
    st.sidebar.warning("ExcelåŠŸèƒ½ä¸å¯ç”¨")
    st.sidebar.markdown("è¦å¯ç”¨ä¸“ä¸šExcelæŠ¥å‘ŠåŠŸèƒ½ï¼Œè¯·è¿è¡Œï¼š")
    st.sidebar.code("pip install openpyxl")
    st.sidebar.markdown("ç›®å‰å¯ä½¿ç”¨CSVå’ŒJSONæ ¼å¼å¯¼å‡ºä¸´åºŠæ•°æ®ã€‚")

st.sidebar.markdown("---")
st.sidebar.markdown("### âš ï¸ APIé™åˆ¶è¯´æ˜")
st.sidebar.markdown("""
**å½“å‰APIé™åˆ¶**: æ¯åˆ†é’Ÿ3æ¬¡è¯·æ±‚

**å¯¹è¯„ä¼°å½±å“**:
- ä¸´åºŠå¿«é€Ÿè¯„ä¼°: ç«‹å³å®Œæˆ
- æ‰¹é‡ä¸´åºŠç ”ç©¶: æ¯ä¸ªè¯„ä¼°é—´éš”25ç§’

**å»ºè®®**:
- æ‰¹é‡ç ”ç©¶é€‰æ‹©é€‚å½“è§„æ¨¡
- å¯åˆ†æ‰¹æ¬¡è¿›è¡Œå¤§æ ·æœ¬ç ”ç©¶
- ä¿æŒç½‘ç»œè¿æ¥ç¨³å®š
""")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ¥ ä¸´åºŠåº”ç”¨å»ºè®®")
st.sidebar.markdown("""
**ç­›æŸ¥åº”ç”¨**:
- å¿«é€Ÿè¯†åˆ«å¯èƒ½çš„å­¤ç‹¬ç—‡ç‰¹å¾
- è¾…åŠ©ä¸´åºŠè¯Šæ–­å†³ç­–

**å¹²é¢„è§„åˆ’**:
- åŸºäºè¯„ä¼°ç»“æœåˆ¶å®šä¸ªä½“åŒ–å¹²é¢„
- ç›‘æµ‹å¹²é¢„æ•ˆæœ

**ç ”ç©¶ç”¨é€”**:
- ç—‡çŠ¶ä¸¥é‡åº¦é‡åŒ–
- å¹²é¢„å‰åå¯¹æ¯”
- ç¾¤ä½“ç‰¹å¾åˆ†æ

**æ³¨æ„äº‹é¡¹**:
- æœ¬å·¥å…·ä»…ä¾›è¾…åŠ©å‚è€ƒ
- ä¸èƒ½æ›¿ä»£ä¸“ä¸šä¸´åºŠè¯Šæ–­
- å»ºè®®ç»“åˆå…¶ä»–è¯„ä¼°å·¥å…·
""")

st.sidebar.markdown("---")
st.sidebar.markdown("### ğŸ”„ æ•°æ®ç®¡ç†")
if st.sidebar.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è¯„ä¼°æ•°æ®"):
    if st.sidebar.checkbox("ç¡®è®¤æ¸…ç©ºï¼ˆæ­¤æ“ä½œä¸å¯æ¢å¤ï¼‰"):
        st.session_state.experiment_records = []
        st.sidebar.success("âœ… è¯„ä¼°æ•°æ®å·²æ¸…ç©º")
        st.rerun()

# é¡µè„š
st.markdown("---")
st.markdown("""
### ğŸ“‹ å¹³å°ç‰¹ç‚¹

**ğŸ¥ åŒ»å­¦æ ‡å‡†**: ä¸¥æ ¼éµå¾ªDSM-5è¯Šæ–­æ ‡å‡†ï¼Œå‚è€ƒæƒå¨è¯„ä¼°é‡è¡¨  
**ğŸ”¬ ç§‘å­¦è¯„ä¼°**: åŸºäºå¾ªè¯å®è·µçš„è¯„ä¼°æŒ‡æ ‡å’Œè¯„åˆ†æ ‡å‡†  
**ğŸ“Š ä¸“ä¸šæŠ¥å‘Š**: ç”Ÿæˆç¬¦åˆä¸´åºŠè¦æ±‚çš„ä¸“ä¸šè¯„ä¼°æŠ¥å‘Š  
**ğŸ¯ ä¸ªä½“åŒ–**: æ”¯æŒä¸ªæ€§åŒ–é…ç½®å’Œå®šåˆ¶åŒ–è¯„ä¼°è®¾è®¡

**ğŸ’¡ ä½¿ç”¨æç¤º**: 
- å»ºè®®å…ˆè¿›è¡Œ'ä¸´åºŠå¿«é€Ÿè¯„ä¼°'ç†Ÿæ‚‰å¹³å°åŠŸèƒ½
- ä½¿ç”¨'æ‰¹é‡ä¸´åºŠç ”ç©¶'è·å–ç»Ÿè®¡å­¦æœ‰æ•ˆçš„æ•°æ®
- åœ¨'ğŸ“Š ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒ'ä¸‹è½½å®Œæ•´çš„ä¸“ä¸šæŠ¥å‘Š
- æ‰€æœ‰è¯„ä¼°ç»“æœä»…ä¾›ä¸´åºŠå‚è€ƒï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šè¯Šæ–­

**âš ï¸ é‡è¦å£°æ˜**: æœ¬å¹³å°ä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä¸´åºŠè¾…åŠ©ä½¿ç”¨ï¼Œä¸èƒ½æ›¿ä»£ä¸“ä¸šåŒ»å¸ˆçš„ä¸´åºŠè¯Šæ–­ã€‚
""")

st.markdown("*åŸºäºDSM-5æ ‡å‡† | å‚è€ƒCARSã€ABCã€SCQã€M-CHATç­‰æƒå¨é‡è¡¨ | åŒ»å­¦æ ‡å‡†ç‰ˆ v1.0*")