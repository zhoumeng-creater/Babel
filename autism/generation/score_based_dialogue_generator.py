"""åŸºäºåˆ†æ•°çš„å¯¹è¯ç”Ÿæˆå™¨

æ ¹æ®ç›®æ ‡è¯„ä¼°åˆ†æ•°ç”Ÿæˆç›¸åº”çš„å­¤ç‹¬ç—‡å„¿ç«¥è¡Œä¸ºå¯¹è¯
"""
import datetime
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import streamlit as st

from common.api_client import call_kimi_api
from autism.configs import CLINICAL_SCENE_CONFIG
from autism.evaluation.enhanced_unified_evaluator import (
    run_enhanced_experiment,
    evaluate_dialogue_with_scales
)

from .score_to_profile_mapper import ScoreToProfileMapper


class ScoreBasedDialogueGenerator:
    """åŸºäºè¯„ä¼°åˆ†æ•°ç”Ÿæˆå¯¹è¯çš„ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.mapper = ScoreToProfileMapper()
        self.max_generation_attempts = 3
        self.score_tolerance = {
            'abc_total': 10,  # ABCæ€»åˆ†å®¹å·®Â±10åˆ†
            'dsm5_core': 0.5,  # DSM5æ ¸å¿ƒç—‡çŠ¶å®¹å·®Â±0.5
            'cars_total': 5,   # CARSæ€»åˆ†å®¹å·®Â±5åˆ†
            'assq_total': 5    # ASSQç­›æŸ¥åˆ†å®¹å·®Â±5åˆ†
        }
    
    def generate_from_scores(
        self,
        target_scores: Dict[str, float],
        scene_config: Optional[Dict[str, Any]] = None,
        scales_to_validate: Optional[List[str]] = None,
        verbose: bool = True
    ) -> Dict[str, Any]:
        """
        æ ¹æ®ç›®æ ‡è¯„ä¼°åˆ†æ•°ç”Ÿæˆå¯¹è¯
        
        Args:
            target_scores: ç›®æ ‡åˆ†æ•° {'abc_total': 75, 'dsm5_core': 3.5, ...}
            scene_config: åœºæ™¯é…ç½® {'scene': '...', 'activity': '...', 'trigger': '...'}
            scales_to_validate: ç”¨äºéªŒè¯çš„é‡è¡¨åˆ—è¡¨
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        
        Returns:
            åŒ…å«ç”Ÿæˆå¯¹è¯å’ŒéªŒè¯ç»“æœçš„å­—å…¸
        """
        if verbose and st:
            st.info("ğŸ¯ å¼€å§‹æ ¹æ®ç›®æ ‡åˆ†æ•°ç”Ÿæˆå¯¹è¯...")
        
        # 1. å°†åˆ†æ•°æ˜ å°„ä¸ºautism_profile
        initial_profile = self.mapper.map_scores_to_profile(target_scores)
        
        if verbose and st:
            st.write(f"âœ“ å·²ç”Ÿæˆåˆå§‹ç‰¹å¾é…ç½®ï¼Œä¸¥é‡ç¨‹åº¦ï¼š{initial_profile['severity_level']}")
        
        # 2. ä¼˜åŒ–profileä»¥æ›´å¥½åŒ¹é…ç›®æ ‡åˆ†æ•°
        optimized_profile = self.mapper.optimize_profile_for_scores(
            initial_profile,
            target_scores,
            max_iterations=5
        )
        
        # 3. è®¾ç½®é»˜è®¤åœºæ™¯é…ç½®
        if not scene_config:
            scene_config = self._get_default_scene_config()
        
        # 4. ç¡®å®šè¦éªŒè¯çš„é‡è¡¨
        if not scales_to_validate:
            scales_to_validate = self._determine_scales_from_scores(target_scores)
        
        # 5. ç”Ÿæˆå¯¹è¯å¹¶éªŒè¯
        best_result = None
        best_distance = float('inf')
        generation_history = []
        
        for attempt in range(self.max_generation_attempts):
            if verbose and st:
                st.write(f"ğŸ”„ ç”Ÿæˆå°è¯• {attempt + 1}/{self.max_generation_attempts}")
            
            # ç”Ÿæˆå¯¹è¯
            dialogue = self._generate_dialogue_with_scores(
                optimized_profile,
                target_scores,
                scene_config,
                attempt
            )
            
            # è¯„ä¼°ç”Ÿæˆçš„å¯¹è¯
            scene_data = CLINICAL_SCENE_CONFIG[scene_config['scene']]
            evaluation_result = evaluate_dialogue_with_scales(
                dialogue,
                optimized_profile,
                scene_data,
                scales_to_validate
            )
            
            # è®¡ç®—å®é™…åˆ†æ•°
            actual_scores = self._extract_actual_scores(evaluation_result, scales_to_validate)
            
            # è®¡ç®—ä¸ç›®æ ‡çš„è·ç¦»
            distance = self._calculate_score_distance(actual_scores, target_scores)
            
            # è®°å½•ç”Ÿæˆå†å²
            generation_history.append({
                'attempt': attempt + 1,
                'dialogue': dialogue,
                'actual_scores': actual_scores,
                'distance': distance,
                'evaluation': evaluation_result
            })
            
            if verbose and st:
                self._display_score_comparison(target_scores, actual_scores)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å®¹å·®è¦æ±‚
            if self._check_tolerance(actual_scores, target_scores):
                if verbose and st:
                    st.success(f"âœ… æˆåŠŸï¼ç”Ÿæˆçš„å¯¹è¯ç¬¦åˆç›®æ ‡åˆ†æ•°è¦æ±‚")
                
                return self._prepare_final_result(
                    dialogue,
                    optimized_profile,
                    scene_config,
                    target_scores,
                    actual_scores,
                    evaluation_result,
                    generation_history,
                    success=True
                )
            
            # ä¿å­˜æœ€ä½³ç»“æœ
            if distance < best_distance:
                best_distance = distance
                best_result = {
                    'dialogue': dialogue,
                    'actual_scores': actual_scores,
                    'evaluation': evaluation_result
                }
            
            # å¦‚æœå·®è·è¾ƒå¤§ï¼Œè°ƒæ•´profile
            if distance > 0.3:
                optimized_profile = self._adjust_profile_based_on_gap(
                    optimized_profile,
                    actual_scores,
                    target_scores
                )
        
        # è¿”å›æœ€ä½³ç»“æœ
        if verbose and st:
            st.warning(f"âš ï¸ æœªèƒ½å®Œå…¨åŒ¹é…ç›®æ ‡åˆ†æ•°ï¼Œè¿”å›æœ€æ¥è¿‘çš„ç»“æœ")
        
        return self._prepare_final_result(
            best_result['dialogue'],
            optimized_profile,
            scene_config,
            target_scores,
            best_result['actual_scores'],
            best_result['evaluation'],
            generation_history,
            success=False
        )
    
    def generate_batch_from_scores(
        self,
        score_sets: List[Dict[str, float]],
        scene_configs: Optional[List[Dict[str, Any]]] = None,
        scales_to_validate: Optional[List[str]] = None
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç”ŸæˆåŸºäºåˆ†æ•°çš„å¯¹è¯
        
        Args:
            score_sets: ç›®æ ‡åˆ†æ•°é›†åˆåˆ—è¡¨
            scene_configs: åœºæ™¯é…ç½®åˆ—è¡¨
            scales_to_validate: éªŒè¯é‡è¡¨åˆ—è¡¨
        
        Returns:
            ç”Ÿæˆç»“æœåˆ—è¡¨
        """
        results = []
        
        # å¦‚æœæ²¡æœ‰æä¾›åœºæ™¯é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if not scene_configs:
            scene_configs = [self._get_default_scene_config() for _ in score_sets]
        
        # ç¡®ä¿åœºæ™¯é…ç½®æ•°é‡åŒ¹é…
        if len(scene_configs) < len(score_sets):
            scene_configs.extend([self._get_default_scene_config()] * (len(score_sets) - len(scene_configs)))
        
        for i, (scores, scene) in enumerate(zip(score_sets, scene_configs)):
            if st:
                st.write(f"ğŸ“ å¤„ç†ç¬¬ {i+1}/{len(score_sets)} ä¸ªè¯„ä¼°...")
            
            result = self.generate_from_scores(
                scores,
                scene,
                scales_to_validate,
                verbose=False
            )
            
            result['batch_index'] = i + 1
            results.append(result)
        
        return results
    
    def validate_dialogue_against_scores(
        self,
        dialogue: str,
        target_scores: Dict[str, float],
        autism_profile: Dict[str, Any],
        scene_config: Dict[str, Any],
        scales: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        éªŒè¯å¯¹è¯æ˜¯å¦ç¬¦åˆç›®æ ‡åˆ†æ•°
        
        Returns:
            éªŒè¯ç»“æœï¼ŒåŒ…å«å®é™…åˆ†æ•°ã€åå·®å’Œæ˜¯å¦é€šè¿‡
        """
        if not scales:
            scales = self._determine_scales_from_scores(target_scores)
        
        # è¯„ä¼°å¯¹è¯
        scene_data = CLINICAL_SCENE_CONFIG[scene_config['scene']]
        evaluation_result = evaluate_dialogue_with_scales(
            dialogue,
            autism_profile,
            scene_data,
            scales
        )
        
        # æå–å®é™…åˆ†æ•°
        actual_scores = self._extract_actual_scores(evaluation_result, scales)
        
        # è®¡ç®—åå·®
        deviations = {}
        for scale in target_scores:
            if scale in actual_scores:
                deviation = actual_scores[scale] - target_scores[scale]
                deviation_percent = (deviation / target_scores[scale] * 100) if target_scores[scale] != 0 else 0
                deviations[scale] = {
                    'absolute': deviation,
                    'percentage': deviation_percent,
                    'within_tolerance': abs(deviation) <= self.score_tolerance.get(scale, 5)
                }
        
        # åˆ¤æ–­æ˜¯å¦é€šè¿‡éªŒè¯
        all_within_tolerance = all(d['within_tolerance'] for d in deviations.values())
        
        return {
            'target_scores': target_scores,
            'actual_scores': actual_scores,
            'deviations': deviations,
            'passed': all_within_tolerance,
            'evaluation_details': evaluation_result
        }
    
    # ========== ç§æœ‰è¾…åŠ©æ–¹æ³• ==========
    
    def _get_default_scene_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤åœºæ™¯é…ç½®"""
        scene_name = list(CLINICAL_SCENE_CONFIG.keys())[0]
        scene_data = CLINICAL_SCENE_CONFIG[scene_name]
        
        return {
            'scene': scene_name,
            'activity': scene_data['activities'][0],
            'trigger': scene_data['triggers'][0]
        }
    
    def _determine_scales_from_scores(self, target_scores: Dict[str, float]) -> List[str]:
        """æ ¹æ®ç›®æ ‡åˆ†æ•°ç¡®å®šè¦ä½¿ç”¨çš„é‡è¡¨"""
        scales = []
        
        if 'abc_total' in target_scores:
            scales.append('ABC')
        if 'dsm5_core' in target_scores:
            scales.append('DSM5')
        if 'cars_total' in target_scores:
            scales.append('CARS')
        if 'assq_total' in target_scores:
            scales.append('ASSQ')
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œé»˜è®¤ä½¿ç”¨ABCå’ŒDSM5
        if not scales:
            scales = ['ABC', 'DSM5']
        
        return scales
    
    def _generate_dialogue_with_scores(
        self,
        autism_profile: Dict[str, Any],
        target_scores: Dict[str, float],
        scene_config: Dict[str, Any],
        attempt: int
    ) -> str:
        """ç”Ÿæˆç¬¦åˆç›®æ ‡åˆ†æ•°çš„å¯¹è¯"""
        # æ„å»ºå¼ºè°ƒç›®æ ‡åˆ†æ•°çš„system prompt
        system_prompt = self._build_score_targeted_prompt(autism_profile, target_scores, attempt)
        
        # æ„å»ºåœºæ™¯prompt
        scene_data = CLINICAL_SCENE_CONFIG[scene_config['scene']]
        dialogue_prompt = (
            f"ä¸´åºŠè§‚å¯Ÿæƒ…å¢ƒï¼š{scene_config['scene']} - {scene_config['activity']}\n"
            f"è§‚å¯Ÿè¦ç‚¹ï¼š{', '.join(scene_data['observation_points'][:3])}\n"
            f"è§¦å‘å› ç´ ï¼š{scene_config['trigger']}\n"
            f"å‚ä¸è§’è‰²ï¼šå­¤ç‹¬ç—‡å„¿ç«¥ã€{scene_data['roles'][1]}ã€{scene_data['roles'][2]}\n"
            f"\nã€é‡è¦ã€‘ï¼šè¯·ç”Ÿæˆè¡Œä¸ºè¡¨ç°ï¼Œä½¿å¾—ï¼š\n"
        )
        
        # æ·»åŠ å…·ä½“çš„åˆ†æ•°è¦æ±‚
        if 'abc_total' in target_scores:
            dialogue_prompt += f"- ABCé‡è¡¨è¯„åˆ†çº¦ä¸º{target_scores['abc_total']}åˆ†\n"
        if 'dsm5_core' in target_scores:
            dialogue_prompt += f"- DSM-5æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦çº¦ä¸º{target_scores['dsm5_core']}/5\n"
        if 'cars_total' in target_scores:
            dialogue_prompt += f"- CARSæ€»åˆ†çº¦ä¸º{target_scores['cars_total']}åˆ†\n"
        if 'assq_total' in target_scores:
            dialogue_prompt += f"- ASSQç­›æŸ¥åˆ†çº¦ä¸º{target_scores['assq_total']}åˆ†\n"
        
        dialogue_prompt += (
            f"\nè¦æ±‚ï¼š15-20è½®å¯¹è¯ï¼Œå‡†ç¡®ä½“ç°ä¸Šè¿°è¯„åˆ†æ°´å¹³çš„è¡Œä¸ºç‰¹å¾ã€‚\n"
            f"æ ¼å¼ï¼š'è§’è‰²å:å†…å®¹'ï¼Œæ¯å¥æ¢è¡Œã€‚"
        )
        
        # è°ƒæ•´æ¸©åº¦å‚æ•°ï¼ˆåç»­å°è¯•é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„ç»“æœï¼‰
        temperature = 0.7 - (attempt * 0.1)
        
        return call_kimi_api(dialogue_prompt, system_prompt, temperature=temperature)
    
    def _build_score_targeted_prompt(
        self,
        autism_profile: Dict[str, Any],
        target_scores: Dict[str, float],
        attempt: int
    ) -> str:
        """æ„å»ºé’ˆå¯¹ç›®æ ‡åˆ†æ•°çš„system prompt"""
        # åŸºç¡€æè¿°
        prompt = (
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸´åºŠè¡Œä¸ºè§‚å¯Ÿä¸“å®¶ã€‚ä½ éœ€è¦ç”Ÿæˆç¬¦åˆç‰¹å®šè¯„ä¼°åˆ†æ•°çš„å­¤ç‹¬ç—‡å„¿ç«¥è¡Œä¸ºè¡¨ç°ã€‚\n\n"
            f"ç›®æ ‡è¯„ä¼°åˆ†æ•°ï¼š\n"
        )
        
        # æ·»åŠ åˆ†æ•°è¦æ±‚å’Œå¯¹åº”çš„è¡Œä¸ºæŒ‡å¯¼
        severity_guidance = []
        
        if 'abc_total' in target_scores:
            abc_score = target_scores['abc_total']
            prompt += f"- ABCé‡è¡¨æ€»åˆ†ï¼š{abc_score}åˆ†ï¼ˆæ»¡åˆ†158åˆ†ï¼‰\n"
            
            if abc_score >= 100:
                severity_guidance.append("å±•ç°ä¸¥é‡çš„å­¤ç‹¬ç—‡è¡Œä¸ºï¼ŒåŒ…æ‹¬æ˜æ˜¾çš„ç¤¾äº¤éšœç¢ã€è¯­è¨€ç¼ºé™·ã€åˆ»æ¿è¡Œä¸º")
            elif abc_score >= 67:
                severity_guidance.append("å±•ç°ä¸­åº¦å­¤ç‹¬ç—‡è¡Œä¸ºï¼Œç¤¾äº¤å’Œæ²Ÿé€šå›°éš¾æ˜æ˜¾ï¼Œæœ‰é‡å¤è¡Œä¸º")
            elif abc_score >= 53:
                severity_guidance.append("å±•ç°è½»åˆ°ä¸­åº¦çš„å­¤ç‹¬ç—‡ç‰¹å¾ï¼Œéƒ¨åˆ†ç¤¾äº¤å›°éš¾ï¼Œè½»åº¦åˆ»æ¿è¡Œä¸º")
            else:
                severity_guidance.append("å±•ç°è½»å¾®çš„å­¤ç‹¬ç—‡å€¾å‘ï¼Œä¸»è¦æ˜¯ç¤¾äº¤ä¸é€‚å’Œè½»å¾®çš„è¡Œä¸ºç‰¹ç‚¹")
        
        if 'dsm5_core' in target_scores:
            dsm5_score = target_scores['dsm5_core']
            prompt += f"- DSM-5æ ¸å¿ƒç—‡çŠ¶ï¼š{dsm5_score}/5.0\n"
            
            if dsm5_score >= 4.0:
                severity_guidance.append("éœ€è¦éå¸¸å¤§é‡çš„æ”¯æŒï¼ŒåŠŸèƒ½ä¸¥é‡å—æŸ")
            elif dsm5_score >= 3.0:
                severity_guidance.append("éœ€è¦å¤§é‡æ”¯æŒï¼Œæ—¥å¸¸åŠŸèƒ½æ˜æ˜¾å—é™")
            elif dsm5_score >= 2.0:
                severity_guidance.append("éœ€è¦æ”¯æŒï¼Œåœ¨æ— æ”¯æŒæƒ…å†µä¸‹æœ‰æ˜æ˜¾å›°éš¾")
            else:
                severity_guidance.append("éœ€è¦ä¸€äº›æ”¯æŒï¼Œä¸»è¦åœ¨ç¤¾äº¤åœºåˆ")
        
        if 'cars_total' in target_scores:
            cars_score = target_scores['cars_total']
            prompt += f"- CARSæ€»åˆ†ï¼š{cars_score}åˆ†ï¼ˆ15-60åˆ†ï¼‰\n"
            
            if cars_score >= 37:
                severity_guidance.append("é‡åº¦å­¤ç‹¬ç—‡è¡¨ç°ï¼Œå¤šä¸ªé¢†åŸŸä¸¥é‡å¼‚å¸¸")
            elif cars_score >= 30:
                severity_guidance.append("ä¸­åº¦å­¤ç‹¬ç—‡ï¼Œæ˜æ˜¾ä½†éä¸¥é‡çš„å¼‚å¸¸")
            else:
                severity_guidance.append("è½»åº¦æˆ–æ— å­¤ç‹¬ç—‡ï¼Œè½»å¾®å¼‚å¸¸")
        
        if 'assq_total' in target_scores:
            assq_score = target_scores['assq_total']
            prompt += f"- ASSQç­›æŸ¥åˆ†ï¼š{assq_score}åˆ†ï¼ˆ0-54åˆ†ï¼‰\n"
            
            if assq_score >= 22:
                severity_guidance.append("é«˜é£é™©ï¼Œæ˜æ˜¾çš„å­¤ç‹¬ç—‡ç‰¹å¾")
            elif assq_score >= 15:
                severity_guidance.append("ä¸­ç­‰é£é™©ï¼Œéœ€è¦è¿›ä¸€æ­¥è¯„ä¼°")
            else:
                severity_guidance.append("ä½é£é™©ï¼Œè½»å¾®ç‰¹å¾")
        
        # æ·»åŠ è¡Œä¸ºæŒ‡å¯¼
        prompt += f"\nè¡Œä¸ºè¡¨ç°æŒ‡å¯¼ï¼š\n"
        for guidance in severity_guidance:
            prompt += f"- {guidance}\n"
        
        # æ·»åŠ å…·ä½“çš„ç‰¹å¾é…ç½®
        prompt += f"\nå­¤ç‹¬ç—‡å„¿ç«¥ç‰¹å¾é…ç½®ï¼š\n"
        prompt += f"ã€ç¤¾äº¤ç‰¹å¾ã€‘ï¼š{autism_profile['social_characteristics']}\n"
        prompt += f"ã€æ²Ÿé€šç‰¹å¾ã€‘ï¼š{autism_profile['communication_characteristics']}\n"
        prompt += f"ã€è¡Œä¸ºç‰¹å¾ã€‘ï¼š{autism_profile['behavioral_characteristics']}\n"
        prompt += f"ã€è®¤çŸ¥ç‰¹å¾ã€‘ï¼š{autism_profile['cognitive_characteristics']}\n"
        prompt += f"ã€æƒ…ç»ªç‰¹å¾ã€‘ï¼š{autism_profile['emotional_characteristics']}\n"
        prompt += f"ã€æ—¥å¸¸ç”Ÿæ´»ã€‘ï¼š{autism_profile['daily_living']}\n"
        
        # æ·»åŠ è¡Œä¸ºç¤ºä¾‹
        if 'behavioral_examples' in autism_profile:
            prompt += f"\nå…¸å‹è¡Œä¸ºç¤ºä¾‹ï¼š\n"
            for i, example in enumerate(autism_profile['behavioral_examples'][:5], 1):
                prompt += f"{i}. {example}\n"
        
        # æ ¹æ®å°è¯•æ¬¡æ•°è°ƒæ•´æŒ‡å¯¼
        if attempt > 0:
            prompt += (
                f"\nã€ç¬¬{attempt + 1}æ¬¡ç”Ÿæˆã€‘è¯·æ›´ç²¾ç¡®åœ°åŒ¹é…ç›®æ ‡åˆ†æ•°ï¼Œ"
                f"ç¡®ä¿è¡Œä¸ºè¡¨ç°çš„ä¸¥é‡ç¨‹åº¦ä¸åˆ†æ•°å®Œå…¨ä¸€è‡´ã€‚"
            )
        
        prompt += (
            "\n\nç”Ÿæˆè¦æ±‚ï¼š\n"
            "1. è¡Œä¸ºè¡¨ç°å¿…é¡»ä¸ç›®æ ‡åˆ†æ•°é«˜åº¦ä¸€è‡´\n"
            "2. åŒ…å«è¶³å¤Ÿçš„å…·ä½“è¡Œä¸ºç»†èŠ‚ä¾›è¯„ä¼°\n"
            "3. é¿å…è¿‡åº¦å¤¸å¼ æˆ–è¿‡åº¦è½»ææ·¡å†™\n"
            "4. ç¡®ä¿è¡Œä¸ºçš„é¢‘ç‡å’Œå¼ºåº¦ç¬¦åˆåˆ†æ•°è¦æ±‚\n"
        )
        
        return prompt
    
    def _extract_actual_scores(
        self,
        evaluation_result: Dict[str, Any],
        scales: List[str]
    ) -> Dict[str, float]:
        """ä»è¯„ä¼°ç»“æœä¸­æå–å®é™…åˆ†æ•°"""
        actual_scores = {}
        
        if 'ABC' in scales and 'abc_evaluation' in evaluation_result:
            actual_scores['abc_total'] = evaluation_result['abc_evaluation']['total_score']
        
        if 'DSM5' in scales and 'dsm5_evaluation' in evaluation_result:
            actual_scores['dsm5_core'] = evaluation_result['dsm5_evaluation']['core_symptom_average']
        
        if 'CARS' in scales and 'cars_evaluation' in evaluation_result:
            actual_scores['cars_total'] = evaluation_result['cars_evaluation']['total_score']
        
        if 'ASSQ' in scales and 'assq_evaluation' in evaluation_result:
            actual_scores['assq_total'] = evaluation_result['assq_evaluation']['total_score']
        
        return actual_scores
    
    def _calculate_score_distance(
        self,
        actual_scores: Dict[str, float],
        target_scores: Dict[str, float]
    ) -> float:
        """è®¡ç®—å®é™…åˆ†æ•°ä¸ç›®æ ‡åˆ†æ•°çš„è·ç¦»"""
        distance = 0.0
        count = 0
        
        for scale in target_scores:
            if scale in actual_scores:
                # å½’ä¸€åŒ–å·®å¼‚
                if scale == 'abc_total':
                    diff = abs(actual_scores[scale] - target_scores[scale]) / 158
                elif scale == 'dsm5_core':
                    diff = abs(actual_scores[scale] - target_scores[scale]) / 5
                elif scale == 'cars_total':
                    diff = abs(actual_scores[scale] - target_scores[scale]) / 60
                elif scale == 'assq_total':
                    diff = abs(actual_scores[scale] - target_scores[scale]) / 54
                else:
                    diff = abs(actual_scores[scale] - target_scores[scale])
                
                distance += diff
                count += 1
        
        return distance / count if count > 0 else 1.0
    
    def _check_tolerance(
        self,
        actual_scores: Dict[str, float],
        target_scores: Dict[str, float]
    ) -> bool:
        """æ£€æŸ¥å®é™…åˆ†æ•°æ˜¯å¦åœ¨å®¹å·®èŒƒå›´å†…"""
        for scale in target_scores:
            if scale in actual_scores:
                diff = abs(actual_scores[scale] - target_scores[scale])
                tolerance = self.score_tolerance.get(scale, 5)
                
                if diff > tolerance:
                    return False
        
        return True
    
    def _display_score_comparison(
        self,
        target_scores: Dict[str, float],
        actual_scores: Dict[str, float]
    ):
        """æ˜¾ç¤ºåˆ†æ•°å¯¹æ¯”"""
        if st:
            cols = st.columns(len(target_scores))
            
            for i, scale in enumerate(target_scores):
                with cols[i]:
                    target = target_scores[scale]
                    actual = actual_scores.get(scale, 0)
                    diff = actual - target
                    
                    # æ˜¾ç¤ºé‡è¡¨åç§°
                    scale_name = {
                        'abc_total': 'ABCæ€»åˆ†',
                        'dsm5_core': 'DSM5æ ¸å¿ƒ',
                        'cars_total': 'CARSæ€»åˆ†',
                        'assq_total': 'ASSQç­›æŸ¥'
                    }.get(scale, scale)
                    
                    st.metric(
                        scale_name,
                        f"{actual:.1f}",
                        f"{diff:+.1f}",
                        delta_color="inverse" if scale in ['abc_total', 'cars_total', 'assq_total'] else "normal"
                    )
                    st.caption(f"ç›®æ ‡: {target:.1f}")
    
    def _adjust_profile_based_on_gap(
        self,
        profile: Dict[str, Any],
        actual_scores: Dict[str, float],
        target_scores: Dict[str, float]
    ) -> Dict[str, Any]:
        """æ ¹æ®åˆ†æ•°å·®è·è°ƒæ•´profile"""
        adjusted = profile.copy()
        
        # è®¡ç®—éœ€è¦çš„è°ƒæ•´
        adjustments = {}
        for scale in target_scores:
            if scale in actual_scores:
                adjustments[scale] = target_scores[scale] - actual_scores[scale]
        
        # åº”ç”¨è°ƒæ•´
        if 'abc_total' in adjustments:
            gap = adjustments['abc_total']
            
            if gap > 20:  # å®é™…åˆ†æ•°å¤ªä½ï¼Œéœ€è¦åŠ é‡ç—‡çŠ¶
                adjusted['behavioral_characteristics'] = (
                    adjusted['behavioral_characteristics']
                    .replace("å¶å°”", "é¢‘ç¹")
                    .replace("è½»åº¦", "é‡åº¦")
                )
                adjusted['social_characteristics'] = (
                    adjusted['social_characteristics']
                    .replace("æœ‰æ—¶", "ç»å¸¸")
                    .replace("èƒ½å¤Ÿ", "å›°éš¾")
                )
            elif gap < -20:  # å®é™…åˆ†æ•°å¤ªé«˜ï¼Œéœ€è¦å‡è½»ç—‡çŠ¶
                adjusted['behavioral_characteristics'] = (
                    adjusted['behavioral_characteristics']
                    .replace("é¢‘ç¹", "å¶å°”")
                    .replace("é‡åº¦", "è½»åº¦")
                )
                adjusted['social_characteristics'] = (
                    adjusted['social_characteristics']
                    .replace("ç»å¸¸", "æœ‰æ—¶")
                    .replace("å›°éš¾", "èƒ½å¤Ÿ")
                )
        
        return adjusted
    
    def _prepare_final_result(
        self,
        dialogue: str,
        profile: Dict[str, Any],
        scene_config: Dict[str, Any],
        target_scores: Dict[str, float],
        actual_scores: Dict[str, float],
        evaluation_result: Dict[str, Any],
        generation_history: List[Dict[str, Any]],
        success: bool
    ) -> Dict[str, Any]:
        """å‡†å¤‡æœ€ç»ˆè¿”å›ç»“æœ"""
        # ç”Ÿæˆå”¯ä¸€ID
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        experiment_id = f"SCORE_GEN_{timestamp}"
        
        return {
            'experiment_id': experiment_id,
            'timestamp': datetime.datetime.now(),
            'generation_method': 'score_based',
            'success': success,
            'dialogue': dialogue,
            'autism_profile': profile,
            'scene_config': scene_config,
            'target_scores': target_scores,
            'actual_scores': actual_scores,
            'score_deviations': {
                scale: actual_scores.get(scale, 0) - target_scores[scale]
                for scale in target_scores
            },
            'evaluation_result': evaluation_result,
            'generation_history': generation_history,
            'notes': (
                f"åŸºäºç›®æ ‡åˆ†æ•°ç”Ÿæˆçš„å¯¹è¯ - "
                f"{'æˆåŠŸåŒ¹é…' if success else 'æœ€ä½³è¿‘ä¼¼'}"
            )
        }