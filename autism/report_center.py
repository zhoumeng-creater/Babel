"""å­¤ç‹¬ç—‡å¹³å°æŠ¥å‘Šä¸­å¿ƒé¡µé¢ - åŸºäºABCé‡è¡¨"""
import streamlit as st
import pandas as pd
import datetime
import json
import numpy as np

from common.config import EXCEL_AVAILABLE
from common.exporters import (
    export_to_csv, export_to_json, export_to_excel, 
    create_excel_workbook, apply_excel_styles, create_zip_package
)
from common.exporters.text_exporter import export_to_text
from .analyzer import generate_clinical_analysis, prepare_clinical_export_data


def page_report_center():
    """ABCæŠ¥å‘Šä¸­å¿ƒé¡µé¢"""
    st.header("ğŸ“Š ABCè¯„ä¼°æŠ¥å‘Šä¸­å¿ƒ")
    st.markdown("åŸºäºABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨ç”Ÿæˆä¸“ä¸šè¯„ä¼°æŠ¥å‘Šå’Œç ”ç©¶æ•°æ®")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.warning("ğŸ“Š æš‚æ— è¯„ä¼°æ•°æ®ï¼Œè¯·å…ˆè¿›è¡ŒABCè¯„ä¼°")
        st.stop()
    
    st.success(f"ğŸ“Š å½“å‰å…±æœ‰ {len(records)} æ¡ABCè¯„ä¼°è®°å½•å¯ç”ŸæˆæŠ¥å‘Š")
    
    # æŠ¥å‘Šç±»å‹é€‰æ‹©
    st.subheader("ğŸ“‹ é€‰æ‹©æŠ¥å‘Šç±»å‹")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("### ğŸ“„ æ ‡å‡†ABCæŠ¥å‘Š")
        
        # åŸºç¡€CSVæŠ¥å‘Š
        if st.button("ğŸ“Š ä¸‹è½½ABCè¯„ä¼°æ•°æ® (CSV)", use_container_width=True):
            export_data = prepare_clinical_export_data(records)
            csv_content = export_to_csv(export_data)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ABCè¯„ä¼°æ•°æ®",
                data=csv_content,
                file_name=f"abc_assessment_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime='text/csv'
            )
        
        # è¡Œä¸ºè®°å½•ä¸‹è½½
        if st.button("ğŸ’¬ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½• (TXT)", use_container_width=True):
            observation_content = create_observation_text(records)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½•",
                data=export_to_text(observation_content),
                file_name=f"abc_behavior_observations_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                mime='text/plain'
            )
        
        # JSONå®Œæ•´æ•°æ®
        if st.button("ğŸ”§ ä¸‹è½½å®Œæ•´ABCæ•°æ® (JSON)", use_container_width=True):
            json_data = create_complete_json_data(records)
            json_str = export_to_json(json_data)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ABCæ•°æ®",
                data=json_str.encode('utf-8'),
                file_name=f"abc_complete_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime='application/json'
            )
    
    with col2:
        st.write("### ğŸ“ˆ ä¸“ä¸šåˆ†ææŠ¥å‘Š")
        
        # ç”ŸæˆABCåˆ†ææŠ¥å‘Š
        if st.button("ğŸ“Š ç”ŸæˆABCç»Ÿè®¡åˆ†æ", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”ŸæˆABCåˆ†ææŠ¥å‘Š..."):
                analysis = generate_clinical_analysis(records)
            
            st.success("âœ… ABCåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
            
            # æ˜¾ç¤ºåˆ†æé¢„è§ˆ
            with st.expander("ğŸ“‹ ABCåˆ†ææŠ¥å‘Šé¢„è§ˆ", expanded=True):
                if analysis.get('è¯„ä¼°æ¦‚å†µ'):
                    st.write("**è¯„ä¼°æ¦‚å†µ:**")
                    for key, value in analysis['è¯„ä¼°æ¦‚å†µ'].items():
                        st.write(f"- {key}: {value}")
                
                if analysis.get('ABCæ€»åˆ†ç»Ÿè®¡'):
                    st.write("**ABCæ€»åˆ†ç»Ÿè®¡:**")
                    for key, value in analysis['ABCæ€»åˆ†ç»Ÿè®¡'].items():
                        st.write(f"- {key}: {value}")
                
                if analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ'):
                    st.write("**ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:**")
                    for key, value in analysis['ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ'].items():
                        st.write(f"- {key}: {value}")
                
                if analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®'):
                    st.write("**ä¸´åºŠå‘ç°ä¸å»ºè®®:**")
                    for finding in analysis['ä¸´åºŠå‘ç°ä¸å»ºè®®']:
                        st.write(f"- {finding}")
            
            # æä¾›åˆ†ææŠ¥å‘Šä¸‹è½½
            analysis_json = export_to_json(analysis)
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ABCåˆ†ææŠ¥å‘Š (JSON)",
                data=analysis_json.encode('utf-8'),
                file_name=f"abc_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime='application/json'
            )
        
        # Excelä¸“ä¸šæŠ¥å‘Š
        if EXCEL_AVAILABLE:
            if st.button("ğŸ“‹ ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š..."):
                    analysis = generate_clinical_analysis(records)
                    excel_data = create_abc_excel_report(records, analysis)
                
                if excel_data:
                    st.success("âœ… ä¸“ä¸šExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                    
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½ä¸“ä¸šExcelæŠ¥å‘Š",
                        data=excel_data,
                        file_name=f"abc_professional_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                    )
                else:
                    st.error("âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ ¼å¼")
        else:
            st.info("ğŸ’¡ ExcelæŠ¥å‘ŠåŠŸèƒ½éœ€è¦å®‰è£…openpyxlæ¨¡å—")
            st.code("pip install openpyxl")
            
            # æ›¿ä»£è¯¦ç»†æŠ¥å‘Š
            if st.button("ğŸ“Š ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š..."):
                    analysis = generate_clinical_analysis(records)
                
                # åˆ›å»ºè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
                detailed_report = create_detailed_text_report(records, analysis)
                
                st.success("âœ… è¯¦ç»†æ–‡æœ¬æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š",
                    data=export_to_text(detailed_report),
                    file_name=f"abc_detailed_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime='text/plain'
                )
        
        # ç ”ç©¶æ•°æ®åŒ…
        if st.button("ğŸ“¦ ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…", use_container_width=True, type="primary"):
            with st.spinner("æ­£åœ¨ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…..."):
                zip_data = create_research_package(records)
            
            st.success("âœ… å®Œæ•´ç ”ç©¶æ•°æ®åŒ…ç”Ÿæˆå®Œæˆï¼")
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ç ”ç©¶æ•°æ®åŒ… (ZIP)",
                data=zip_data,
                file_name=f"abc_research_package_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                mime='application/zip'
            )
    
    # æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ
    display_data_overview(records)
    
    # æ•°æ®é¢„è§ˆ
    display_data_preview(records)


def create_observation_text(records):
    """åˆ›å»ºABCè¡Œä¸ºè§‚å¯Ÿè®°å½•æ–‡æœ¬"""
    observation_content = []
    observation_content.append("=" * 70)
    observation_content.append("å­¤ç‹¬ç—‡å„¿ç«¥ABCè¡Œä¸ºè§‚å¯Ÿè®°å½•")
    observation_content.append("åŸºäºABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨")
    observation_content.append("=" * 70)
    observation_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    observation_content.append(f"è¯„ä¼°è®°å½•æ€»æ•°: {len(records)}")
    observation_content.append("=" * 70)
    observation_content.append("")
    
    for i, record in enumerate(records, 1):
        observation_content.append(f"\nã€ABCè¯„ä¼° {i}ã€‘")
        observation_content.append(f"è¯„ä¼°ID: {record['experiment_id']}")
        observation_content.append(f"è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
        observation_content.append(f"é…ç½®ç±»å‹: {record.get('template', 'è‡ªå®šä¹‰')}")
        observation_content.append(f"è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
        observation_content.append(f"è§‚å¯Ÿæ´»åŠ¨: {record.get('activity', 'æœªæŒ‡å®š')}")
        observation_content.append(f"è§¦å‘å› ç´ : {record.get('trigger', 'æœªæŒ‡å®š')}")
        observation_content.append(f"ABCæ€»åˆ†: {record['abc_total_score']}")
        observation_content.append(f"ä¸¥é‡ç¨‹åº¦: {record['abc_severity']}")
        observation_content.append("-" * 50)
        
        observation_content.append("å„é¢†åŸŸå¾—åˆ†:")
        for metric, score in record['evaluation_scores'].items():
            observation_content.append(f"  â€¢ {metric}: {score}")
        
        if 'identified_behaviors' in record and record['identified_behaviors']:
            observation_content.append("è¯†åˆ«åˆ°çš„è¡Œä¸º:")
            for domain, behaviors in record['identified_behaviors'].items():
                if behaviors:
                    observation_content.append(f"  {domain}:")
                    for behavior in behaviors:
                        observation_content.append(f"    - {behavior}")
        
        observation_content.append("è¡Œä¸ºè§‚å¯Ÿå¯¹è¯:")
        observation_content.append(record['dialogue'])
        observation_content.append("-" * 50)
        observation_content.append("")
    
    return observation_content


def create_complete_json_data(records):
    """åˆ›å»ºå®Œæ•´çš„ABC JSONæ•°æ®"""
    analysis = generate_clinical_analysis(records)
    
    json_data = {
        'abc_assessment_report': {
            'report_metadata': {
                'generation_time': datetime.datetime.now().isoformat(),
                'assessment_tool': 'ABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨',
                'total_assessments': len(records),
                'platform_version': 'ABCé‡è¡¨ç‰ˆ v1.0'
            },
            'assessment_summary': analysis,
            'detailed_assessments': []
        }
    }
    
    for record in records:
        assessment_record = record.copy()
        assessment_record['timestamp'] = record['timestamp'].isoformat()
        
        json_data['abc_assessment_report']['detailed_assessments'].append(assessment_record)
    
    return json_data


def create_abc_excel_report(records, analysis):
    """åˆ›å»ºABCä¸“ä¸šExcelæŠ¥å‘Š"""
    if not EXCEL_AVAILABLE:
        return None
    
    workbook = create_excel_workbook()
    
    # 1. ABCè¯„ä¼°æ¦‚è§ˆ
    overview_sheet = workbook.create_sheet("ABCè¯„ä¼°æ¦‚è§ˆ")
    overview_sheet.append(["å­¤ç‹¬ç—‡å„¿ç«¥ABCè¡Œä¸ºè¯„ä¼°æŠ¥å‘Š"])
    overview_sheet.append([])
    overview_sheet.append(["æŠ¥å‘Šç”Ÿæˆæ—¶é—´", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
    overview_sheet.append(["è¯„ä¼°å·¥å…·", "ABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨ï¼ˆ57é¡¹ï¼‰"])
    overview_sheet.append([])
    
    overview_sheet.append(["è¯„ä¼°æ¦‚å†µ"])
    for key, value in analysis.get('è¯„ä¼°æ¦‚å†µ', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["ABCæ€»åˆ†ç»Ÿè®¡"])
    for key, value in analysis.get('ABCæ€»åˆ†ç»Ÿè®¡', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ"])
    for key, value in analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["ä¸´åºŠå‘ç°ä¸å»ºè®®"])
    for finding in analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []):
        overview_sheet.append([finding])
    
    # 2. è¯¦ç»†è¯„ä¼°æ•°æ®
    data_sheet = workbook.create_sheet("è¯¦ç»†è¯„ä¼°æ•°æ®")
    headers = ["è¯„ä¼°ID", "æ—¶é—´", "é…ç½®ç±»å‹", "ABCä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "è§‚å¯Ÿæ´»åŠ¨", 
              "è§¦å‘å› ç´ ", "ABCæ€»åˆ†", "æ„Ÿè§‰é¢†åŸŸ", "äº¤å¾€é¢†åŸŸ", "èº¯ä½“è¿åŠ¨", 
              "è¯­è¨€é¢†åŸŸ", "ç¤¾äº¤è‡ªç†", "ä¸»è¦è¡Œä¸ºè¡¨ç°", "å¤‡æ³¨"]
    data_sheet.append(headers)
    
    for record in records:
        scores = record['evaluation_scores']
        
        # æå–ä¸»è¦è¡Œä¸º
        main_behaviors = []
        if 'identified_behaviors' in record:
            for behaviors in record['identified_behaviors'].values():
                main_behaviors.extend(behaviors[:2])  # æ¯ä¸ªé¢†åŸŸå–å‰2ä¸ª
        main_behaviors_str = '; '.join(main_behaviors[:5])  # æœ€å¤šæ˜¾ç¤º5ä¸ª
        
        row = [
            record['experiment_id'],
            record['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
            record.get('template', 'è‡ªå®šä¹‰'),
            record['abc_severity'],
            record['scene'],
            record.get('activity', ''),
            record.get('trigger', ''),
            record['abc_total_score'],
            scores['æ„Ÿè§‰é¢†åŸŸå¾—åˆ†'],
            scores['äº¤å¾€é¢†åŸŸå¾—åˆ†'],
            scores['èº¯ä½“è¿åŠ¨é¢†åŸŸå¾—åˆ†'],
            scores['è¯­è¨€é¢†åŸŸå¾—åˆ†'],
            scores['ç¤¾äº¤ä¸è‡ªç†é¢†åŸŸå¾—åˆ†'],
            main_behaviors_str,
            record.get('notes', '')
        ]
        data_sheet.append(row)
    
    # 3. å„é¢†åŸŸå¾—åˆ†åˆ†æ
    domain_sheet = workbook.create_sheet("å„é¢†åŸŸå¾—åˆ†åˆ†æ")
    if analysis.get('å„é¢†åŸŸå¾—åˆ†åˆ†æ'):
        domain_headers = ["é¢†åŸŸ", "å¹³å‡åˆ†", "æœ€é«˜åˆ†", "æœ€ä½åˆ†", "å æ»¡åˆ†æ¯”ä¾‹"]
        domain_sheet.append(domain_headers)
        
        for domain, stats in analysis['å„é¢†åŸŸå¾—åˆ†åˆ†æ'].items():
            row = [
                domain.replace("å¾—åˆ†", ""),
                stats['å¹³å‡åˆ†'],
                stats['æœ€é«˜åˆ†'],
                stats['æœ€ä½åˆ†'],
                stats['å æ»¡åˆ†æ¯”ä¾‹']
            ]
            domain_sheet.append(row)
    
    # 4. é«˜é¢‘è¡Œä¸ºåˆ†æ
    if analysis.get('é«˜é¢‘è¡Œä¸ºè¡¨ç°'):
        behavior_sheet = workbook.create_sheet("é«˜é¢‘è¡Œä¸ºåˆ†æ")
        behavior_sheet.append(["è¡Œä¸ºè¡¨ç°", "å‡ºç°æ¬¡æ•°å’Œæ¯”ä¾‹"])
        
        for behavior, frequency in list(analysis['é«˜é¢‘è¡Œä¸ºè¡¨ç°'].items())[:20]:
            behavior_sheet.append([behavior, frequency])
    
    # 5. è¡Œä¸ºæ¸…å•
    behavior_list_sheet = workbook.create_sheet("ABCè¡Œä¸ºæ¸…å•")
    behavior_list_sheet.append(["è¯„ä¼°ID", "è¯†åˆ«åˆ°çš„æ‰€æœ‰è¡Œä¸º"])
    
    for record in records:
        if 'identified_behaviors' in record:
            all_behaviors = []
            for domain, behaviors in record['identified_behaviors'].items():
                for behavior in behaviors:
                    all_behaviors.append(f"[{domain}] {behavior}")
            
            behavior_list_sheet.append([
                record['experiment_id'],
                '; '.join(all_behaviors)
            ])
    
    # 6. å¯¹è¯è®°å½•
    dialogue_sheet = workbook.create_sheet("å¯¹è¯è®°å½•")
    dialogue_sheet.append(["è¯„ä¼°ID", "ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "å¯¹è¯å†…å®¹"])
    
    for record in records:
        dialogue_sheet.append([
            record['experiment_id'],
            record['abc_severity'],
            record['scene'],
            record['dialogue']
        ])
    
    # åº”ç”¨ä¸“ä¸šæ ·å¼
    apply_excel_styles(workbook, header_color="4472C4", header_font_color="FFFFFF")
    
    # ç‰¹æ®Šæ ·å¼å¤„ç†
    for sheet in workbook.worksheets:
        for row in sheet.iter_rows():
            for cell in row:
                if cell.value and any(keyword in str(cell.value) for keyword in ['é‡åº¦', 'ä¸­åº¦', 'å­¤ç‹¬ç—‡']):
                    from openpyxl.styles import PatternFill
                    cell.fill = PatternFill(start_color="FFE6E6", end_color="FFE6E6", fill_type="solid")
    
    return export_to_excel(workbook)


def create_detailed_text_report(records, analysis):
    """åˆ›å»ºABCè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š"""
    detailed_report = []
    detailed_report.append("å­¤ç‹¬ç—‡å„¿ç«¥ABCè¯„ä¼°è¯¦ç»†æŠ¥å‘Š")
    detailed_report.append("=" * 50)
    detailed_report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    detailed_report.append(f"è¯„ä¼°å·¥å…·: ABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨")
    detailed_report.append(f"è¯„ä¼°æ ‡å‡†: æ€»åˆ†â‰¥67åˆ†ä¸ºå­¤ç‹¬ç—‡")
    detailed_report.append("")
    
    # æ·»åŠ è¯„ä¼°æ¦‚å†µ
    detailed_report.append("ä¸€ã€è¯„ä¼°æ¦‚å†µ")
    detailed_report.append("-" * 30)
    for key, value in analysis.get('è¯„ä¼°æ¦‚å†µ', {}).items():
        detailed_report.append(f"{key}: {value}")
    detailed_report.append("")
    
    # æ·»åŠ ABCæ€»åˆ†ç»Ÿè®¡
    detailed_report.append("äºŒã€ABCæ€»åˆ†ç»Ÿè®¡")
    detailed_report.append("-" * 30)
    for key, value in analysis.get('ABCæ€»åˆ†ç»Ÿè®¡', {}).items():
        detailed_report.append(f"{key}: {value}")
    detailed_report.append("")
    
    # æ·»åŠ ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ
    detailed_report.append("ä¸‰ã€ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ")
    detailed_report.append("-" * 30)
    for key, value in analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ', {}).items():
        detailed_report.append(f"{key}: {value}")
    detailed_report.append("")
    
    # æ·»åŠ å„é¢†åŸŸåˆ†æ
    if analysis.get('å„é¢†åŸŸå¾—åˆ†åˆ†æ'):
        detailed_report.append("å››ã€å„é¢†åŸŸå¾—åˆ†åˆ†æ")
        detailed_report.append("-" * 30)
        for domain, stats in analysis['å„é¢†åŸŸå¾—åˆ†åˆ†æ'].items():
            detailed_report.append(f"\n{domain}:")
            for key, value in stats.items():
                detailed_report.append(f"  - {key}: {value}")
        detailed_report.append("")
    
    # æ·»åŠ é«˜é¢‘è¡Œä¸º
    if analysis.get('é«˜é¢‘è¡Œä¸ºè¡¨ç°'):
        detailed_report.append("äº”ã€é«˜é¢‘è¡Œä¸ºè¡¨ç°ï¼ˆå‰10é¡¹ï¼‰")
        detailed_report.append("-" * 30)
        for i, (behavior, frequency) in enumerate(list(analysis['é«˜é¢‘è¡Œä¸ºè¡¨ç°'].items())[:10], 1):
            detailed_report.append(f"{i}. {behavior}: {frequency}")
        detailed_report.append("")
    
    # æ·»åŠ ä¸´åºŠå‘ç°
    detailed_report.append("å…­ã€ä¸´åºŠå‘ç°ä¸å»ºè®®")
    detailed_report.append("-" * 30)
    for i, finding in enumerate(analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []), 1):
        detailed_report.append(f"{i}. {finding}")
    detailed_report.append("")
    
    # æ·»åŠ ä¸ªæ¡ˆæ˜ç»†
    detailed_report.append("ä¸ƒã€ä¸ªæ¡ˆè¯„ä¼°æ˜ç»†")
    detailed_report.append("-" * 30)
    for i, record in enumerate(records, 1):
        detailed_report.append(f"\nä¸ªæ¡ˆ {i}: {record['experiment_id']}")
        detailed_report.append(f"  è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M')}")
        detailed_report.append(f"  ABCæ€»åˆ†: {record['abc_total_score']}")
        detailed_report.append(f"  ä¸¥é‡ç¨‹åº¦: {record['abc_severity']}")
        detailed_report.append(f"  è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
    
    return detailed_report


def create_research_package(records):
    """åˆ›å»ºç ”ç©¶æ•°æ®åŒ…"""
    # ç”Ÿæˆåˆ†æ
    analysis = generate_clinical_analysis(records)
    
    # å‡†å¤‡å„ç§æ ¼å¼çš„æ•°æ®
    files_dict = {}
    
    # 1. åŸºç¡€ABCæ•°æ®CSV
    export_data = prepare_clinical_export_data(records)
    files_dict["01_ABCè¯„ä¼°æ•°æ®.csv"] = export_to_csv(export_data)
    
    # 2. ä¸“ä¸šåˆ†ææŠ¥å‘Š
    if EXCEL_AVAILABLE:
        excel_data = create_abc_excel_report(records, analysis)
        if excel_data:
            files_dict["02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx"] = excel_data
    
    if "02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx" not in files_dict:
        # Excelä¸å¯ç”¨æ—¶çš„æ–‡æœ¬æŠ¥å‘Š
        detailed_report = create_detailed_text_report(records, analysis)
        files_dict["02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt"] = '\n'.join(detailed_report)
    
    # 3. å®Œæ•´ç ”ç©¶æ•°æ®JSON
    complete_data = create_complete_json_data(records)
    files_dict["03_å®Œæ•´ç ”ç©¶æ•°æ®.json"] = export_to_json(complete_data)
    
    # 4. è¡Œä¸ºè§‚å¯Ÿè®°å½•
    observation_content = create_observation_text(records)
    files_dict["04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt"] = '\n'.join(observation_content)
    
    # 5. READMEæ–‡ä»¶
    readme_content = create_readme_content(records, EXCEL_AVAILABLE)
    files_dict["README.txt"] = readme_content
    
    return create_zip_package(files_dict)


def create_readme_content(records, excel_available):
    """åˆ›å»ºREADMEå†…å®¹"""
    readme_content = f"""
å­¤ç‹¬ç—‡å„¿ç«¥AIæ¨¡æ‹Ÿå®éªŒå¹³å° - ABCé‡è¡¨ç‰ˆ
ç ”ç©¶æ•°æ®åŒ…è¯´æ˜æ–‡æ¡£
======================================

ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
è¯„ä¼°è®°å½•æ•°: {len(records)}
è¯„ä¼°å·¥å…·: ABCå­¤ç‹¬ç—‡è¡Œä¸ºé‡è¡¨ï¼ˆAutism Behavior Checklistï¼‰

æ–‡ä»¶è¯´æ˜:
--------
1. 01_ABCè¯„ä¼°æ•°æ®.csv
   - åŒ…å«æ‰€æœ‰è¯„ä¼°çš„æ ¸å¿ƒæ•°æ®
   - é€‚ç”¨äºç»Ÿè®¡åˆ†æå’Œæ•°æ®å¯è§†åŒ–
   - åŒ…å«ABCæ€»åˆ†å’Œå„é¢†åŸŸå¾—åˆ†

"""
    if excel_available:
        readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx
   - å¤šå·¥ä½œè¡¨Excelä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æã€è¡Œä¸ºæ¸…å•å’Œè¯¦ç»†è®°å½•
   - é€‚ç”¨äºä¸´åºŠæŠ¥å‘Šå’Œå­¦æœ¯ç ”ç©¶
"""
    else:
        readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt
   - è¯¦ç»†çš„æ–‡æœ¬æ ¼å¼ä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æå’Œä¸´åºŠè§£é‡Š
   - æ³¨æ„: ExcelåŠŸèƒ½ä¸å¯ç”¨ï¼Œå¦‚éœ€Excelæ ¼å¼è¯·å®‰è£…openpyxl
"""

    readme_content += """
3. 03_å®Œæ•´ç ”ç©¶æ•°æ®.json
   - åŒ…å«æ‰€æœ‰åŸå§‹æ•°æ®å’Œå…ƒæ•°æ®
   - é€‚ç”¨äºç¨‹åºå¤„ç†å’Œæ·±åº¦åˆ†æ
   - åŒ…å«å®Œæ•´çš„è¡Œä¸ºè¯†åˆ«è®°å½•

4. 04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt
   - æ‰€æœ‰è¯„ä¼°çš„å¯¹è¯è®°å½•
   - ç”¨äºè´¨æ€§åˆ†æå’Œè¡Œä¸ºæ¨¡å¼ç ”ç©¶
   - åŒ…å«è¯†åˆ«åˆ°çš„å…·ä½“è¡Œä¸º

5. README.txt
   - æœ¬è¯´æ˜æ–‡æ¡£

ABCé‡è¡¨è¯´æ˜:
-----------
ABCé‡è¡¨åŒ…å«57ä¸ªè¡Œä¸ºé¡¹ç›®ï¼Œåˆ†ä¸º5ä¸ªé¢†åŸŸï¼š
- æ„Ÿè§‰é¢†åŸŸï¼ˆ9é¡¹ï¼‰ï¼šæ„Ÿè§‰å¼‚å¸¸ç›¸å…³è¡Œä¸º
- äº¤å¾€é¢†åŸŸï¼ˆ12é¡¹ï¼‰ï¼šç¤¾äº¤äº’åŠ¨éšœç¢
- èº¯ä½“è¿åŠ¨é¢†åŸŸï¼ˆ12é¡¹ï¼‰ï¼šåˆ»æ¿é‡å¤åŠ¨ä½œ
- è¯­è¨€é¢†åŸŸï¼ˆ13é¡¹ï¼‰ï¼šè¯­è¨€æ²Ÿé€šç¼ºé™·
- ç¤¾äº¤ä¸è‡ªç†é¢†åŸŸï¼ˆ11é¡¹ï¼‰ï¼šç”Ÿæ´»è‡ªç†å’Œé€‚åº”

è¯„åˆ†æ ‡å‡†ï¼š
- æ€»åˆ†â‰¥67åˆ†ï¼šå­¤ç‹¬ç—‡
- æ€»åˆ†53-66åˆ†ï¼šè½»åº¦å­¤ç‹¬ç—‡
- æ€»åˆ†40-52åˆ†ï¼šè¾¹ç¼˜çŠ¶æ€/å¯ç–‘
- æ€»åˆ†<40åˆ†ï¼šéå­¤ç‹¬ç—‡

ä½¿ç”¨å»ºè®®:
--------
1. ä¸´åºŠåº”ç”¨:
   - ä½¿ç”¨ABCæ€»åˆ†è¿›è¡Œåˆæ­¥ç­›æŸ¥
   - åˆ†æå„é¢†åŸŸå¾—åˆ†ç¡®å®šå¹²é¢„é‡ç‚¹
   - å…³æ³¨é«˜é¢‘è¡Œä¸ºåˆ¶å®šä¸ªä½“åŒ–æ–¹æ¡ˆ

2. ç ”ç©¶åº”ç”¨:
   - ä½¿ç”¨å®Œæ•´æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ
   - è¡Œä¸ºæ¨¡å¼åˆ†æå’Œåˆ†ç±»ç ”ç©¶
   - å¹²é¢„æ•ˆæœè¯„ä¼°

3. æ•™å­¦åº”ç”¨:
   - ABCé‡è¡¨ä½¿ç”¨åŸ¹è®­
   - è¡Œä¸ºè¯†åˆ«æŠ€èƒ½è®­ç»ƒ
   - æ¡ˆä¾‹æ•™å­¦å’Œè®¨è®º

æŠ€æœ¯æ”¯æŒ:
--------
- å¦‚éœ€ExcelåŠŸèƒ½ï¼Œè¯·å®‰è£…: pip install openpyxl
- æ•°æ®åˆ†æå»ºè®®ä½¿ç”¨: pandas, numpy, scipy
- å¯è§†åŒ–å»ºè®®ä½¿ç”¨: matplotlib, plotly

å‚è€ƒæ–‡çŒ®:
--------
- Krug, D. A., Arick, J., & Almond, P. (1980). 
  Behavior checklist for identifying severely handicapped 
  individuals with high levels of autistic behavior. 
  Journal of Child Psychology and Psychiatry, 21(3), 221-229.

- ä¸­æ–‡ç‰ˆABCé‡è¡¨çš„ä¿¡æ•ˆåº¦ç ”ç©¶

è´¨é‡ä¿è¯:
--------
æœ¬å¹³å°ä¸¥æ ¼éµå¾ªABCé‡è¡¨çš„åŸå§‹è®¾è®¡ï¼Œ
ç¡®ä¿è¡Œä¸ºè¯†åˆ«å’Œè¯„åˆ†çš„å‡†ç¡®æ€§ï¼Œ
æ‰€æœ‰è¯„ä¼°ç»“æœå‡å¯è¿½æº¯åˆ°å…·ä½“è¡Œä¸ºè¡¨ç°ã€‚

ç‰ˆæƒå£°æ˜:
--------
æœ¬æ•°æ®åŒ…ä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä¸´åºŠå®è·µä½¿ç”¨ï¼Œ
è¯·éµå¾ªç›¸å…³ä¼¦ç†è§„èŒƒå’Œæ•°æ®ä¿æŠ¤æ³•è§„ã€‚
"""
    return readme_content


def display_data_overview(records):
    """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡æ¦‚è§ˆ"""
    st.subheader("ğŸ“ˆ æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ")
    
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    
    with col_stat1:
        st.metric("ABCè¯„ä¼°æ€»æ•°", len(records))
    
    with col_stat2:
        avg_total = np.mean([r['abc_total_score'] for r in records])
        st.metric("å¹³å‡ABCæ€»åˆ†", f"{avg_total:.1f}")
    
    with col_stat3:
        severities = [r['abc_severity'] for r in records]
        autism_count = len([s for s in severities if 'å­¤ç‹¬ç—‡' in s and 'é' not in s])
        st.metric("å­¤ç‹¬ç—‡é˜³æ€§æ•°", f"{autism_count} ({autism_count/len(records)*100:.1f}%)")
    
    with col_stat4:
        if records:
            time_span = (max(r['timestamp'] for r in records) - min(r['timestamp'] for r in records)).days
            st.metric("è¯„ä¼°æ—¶é—´è·¨åº¦(å¤©)", time_span)


def display_data_preview(records):
    """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
    st.subheader("ğŸ“Š ABCæ•°æ®é¢„è§ˆ")
    
    preview_data = []
    for record in records[:10]:
        preview_data.append({
            'è¯„ä¼°ID': record['experiment_id'][:20] + '...' if len(record['experiment_id']) > 20 else record['experiment_id'],
            'æ—¶é—´': record['timestamp'].strftime('%m-%d %H:%M'),
            'ABCæ€»åˆ†': record['abc_total_score'],
            'ä¸¥é‡ç¨‹åº¦': record['abc_severity'],
            'è¯„ä¼°æƒ…å¢ƒ': record['scene'].replace('ç»“æ„åŒ–', 'ç»“æ„'),
            'è¡Œä¸ºæ•°': sum(len(behaviors) for behaviors in record.get('identified_behaviors', {}).values())
        })
    
    df_preview = pd.DataFrame(preview_data)
    st.dataframe(df_preview, use_container_width=True)
    
    if len(records) > 10:
        st.info(f"æ˜¾ç¤ºå‰10æ¡è®°å½•ï¼Œå…±{len(records)}æ¡ã€‚å®Œæ•´æ•°æ®è¯·é€šè¿‡ä¸Šæ–¹ä¸‹è½½åŠŸèƒ½è·å–ã€‚")