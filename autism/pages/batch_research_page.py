"""æ‰¹é‡ç ”ç©¶é¡µé¢ - å¢å¼ºç‰ˆï¼ˆæ”¯æŒå¤šé‡è¡¨é€‰æ‹©ï¼‰"""
import streamlit as st
import pandas as pd
import numpy as np

from common.batch_processor import run_batch_processing
from autism.configs import UNIFIED_AUTISM_PROFILES, CLINICAL_SCENE_CONFIG
# ä¿®æ”¹å¯¼å…¥ï¼šä½¿ç”¨å¢å¼ºç‰ˆå‡½æ•°
from autism.evaluation import (
    run_enhanced_experiment,  # ä½¿ç”¨å¢å¼ºç‰ˆ
    generate_enhanced_batch,   # ä½¿ç”¨å¢å¼ºç‰ˆæ‰¹é‡ç”Ÿæˆ
    AVAILABLE_SCALES,
    DEFAULT_SCALES,
    COMPREHENSIVE_SCALES
)
from autism.ui_components.visualization import create_assessment_comparison_plot
from autism.ui_components.result_display import analyze_batch_consistency, create_severity_comparison_df


def page_batch_research():
    """æ‰¹é‡ç ”ç©¶é¡µé¢ - æ”¯æŒå¤šé‡è¡¨è¯„ä¼°"""
    st.header("ğŸ”¬ æ‰¹é‡ä¸´åºŠç ”ç©¶")
    st.markdown("æ‰¹é‡ç”Ÿæˆè¡Œä¸ºæ ·æœ¬ï¼Œæ”¯æŒå¤šç§é‡è¡¨ç»„åˆçš„è¯„ä¼°å’Œå¯¹æ¯”åˆ†æ")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ¯ ç ”ç©¶è®¾è®¡")
        
        # ç ”ç©¶è§„æ¨¡é€‰æ‹©
        research_scale = st.radio(
            "é€‰æ‹©ç ”ç©¶è§„æ¨¡",
            ["è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰", "æ ‡å‡†ç ”ç©¶", "å¤§æ ·æœ¬ç ”ç©¶"],
            help="æ ¹æ®ç ”ç©¶éœ€è¦é€‰æ‹©åˆé€‚çš„æ ·æœ¬è§„æ¨¡"
        )
        
        if research_scale == "è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰":
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())[:2]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:2]
            default_repeats = 1
            st.info("ğŸš€ è¯•ç‚¹ç ”ç©¶ï¼šéªŒè¯è¯„ä¼°æ•ˆæœï¼Œçº¦éœ€5-8åˆ†é’Ÿ")
        elif research_scale == "æ ‡å‡†ç ”ç©¶":
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())[:3]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:3]
            default_repeats = 2
            st.info("â³ æ ‡å‡†ç ”ç©¶ï¼šè·å¾—å¯é æ•°æ®ï¼Œçº¦éœ€20-30åˆ†é’Ÿ")
        else:
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())
            default_repeats = 2
            st.warning("â° å¤§æ ·æœ¬ç ”ç©¶ï¼šå®Œæ•´ç ”ç©¶æ•°æ®ï¼Œçº¦éœ€60-90åˆ†é’Ÿ")
        
        # ä¸¥é‡ç¨‹åº¦å’Œæƒ…å¢ƒé€‰æ‹©
        selected_severities = st.multiselect(
            "é€‰æ‹©ä¸¥é‡ç¨‹åº¦ç»„", 
            list(UNIFIED_AUTISM_PROFILES.keys()),
            default=default_severities
        )
        
        selected_contexts = st.multiselect(
            "é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ",
            list(CLINICAL_SCENE_CONFIG.keys()),
            default=default_contexts
        )
        
        repeats_per_combo = st.slider(
            "æ¯ç»„åˆé‡å¤æ¬¡æ•°", 
            1, 3, 
            default_repeats,
            help="å¢åŠ é‡å¤æ¬¡æ•°æé«˜ç»Ÿè®¡å¯é æ€§"
        )
        
        # âœ¨ æ–°å¢ï¼šé‡è¡¨é€‰æ‹©åŠŸèƒ½
        with st.expander("âš™ï¸ é«˜çº§é€‰é¡¹ - é‡è¡¨é€‰æ‹©", expanded=False):
            st.write("**é€‰æ‹©è¯„ä¼°é‡è¡¨ç»„åˆ**")
            
            scale_mode = st.radio(
                "é‡è¡¨æ¨¡å¼",
                ["æ ‡å‡†åŒé‡è¡¨ï¼ˆABC+DSM-5ï¼‰", "å…¨é¢å››é‡è¡¨", "å¿«é€Ÿç­›æŸ¥ï¼ˆASSQï¼‰", "è‡ªå®šä¹‰é€‰æ‹©"],
                horizontal=False
            )
            
            if scale_mode == "æ ‡å‡†åŒé‡è¡¨ï¼ˆABC+DSM-5ï¼‰":
                selected_scales = DEFAULT_SCALES
                st.info("âœ… ä½¿ç”¨ABCå’ŒDSM-5åŒé‡è¯„ä¼°")
            elif scale_mode == "å…¨é¢å››é‡è¡¨":
                selected_scales = COMPREHENSIVE_SCALES
                st.warning("â±ï¸ å…¨é¢è¯„ä¼°éœ€è¦æ›´å¤šæ—¶é—´")
            elif scale_mode == "å¿«é€Ÿç­›æŸ¥ï¼ˆASSQï¼‰":
                selected_scales = ['ASSQ']
                st.info("âš¡ ä»…ä½¿ç”¨ASSQå¿«é€Ÿç­›æŸ¥")
            else:
                # è‡ªå®šä¹‰é€‰æ‹©
                selected_scales = []
                col_a, col_b = st.columns(2)
                with col_a:
                    if st.checkbox("ABCé‡è¡¨", value=True, key="batch_abc"):
                        selected_scales.append('ABC')
                    if st.checkbox("CARSé‡è¡¨", value=False, key="batch_cars"):
                        selected_scales.append('CARS')
                with col_b:
                    if st.checkbox("DSM-5æ ‡å‡†", value=True, key="batch_dsm5"):
                        selected_scales.append('DSM5')
                    if st.checkbox("ASSQç­›æŸ¥", value=False, key="batch_assq"):
                        selected_scales.append('ASSQ')
            
            # æ˜¾ç¤ºé€‰ä¸­çš„é‡è¡¨
            if selected_scales:
                st.write(f"**å°†ä½¿ç”¨çš„é‡è¡¨**: {', '.join([AVAILABLE_SCALES[s]['name'] for s in selected_scales])}")
            else:
                # é»˜è®¤ä½¿ç”¨åŒé‡è¡¨
                selected_scales = DEFAULT_SCALES
        
        # å‡†å¤‡å®éªŒé…ç½®
        if selected_severities and selected_contexts:
            severity_dict = {k: UNIFIED_AUTISM_PROFILES[k] for k in selected_severities}
            context_dict = {k: CLINICAL_SCENE_CONFIG[k] for k in selected_contexts}
            
            # ä½¿ç”¨å¢å¼ºç‰ˆæ‰¹é‡ç”Ÿæˆ
            experiments = generate_enhanced_batch(
                severity_dict, 
                context_dict, 
                repeats_per_combo,
                selected_scales  # ä¼ å…¥é€‰æ‹©çš„é‡è¡¨
            )
            
            # è®¡ç®—è¯„ä¼°æ€»æ•°
            total_assessments = len(experiments) * len(selected_scales)
            st.info(f"ğŸ“Š å°†ç”Ÿæˆ {len(experiments)} ä¸ªè¡Œä¸ºæ ·æœ¬ï¼Œè¿›è¡Œ {total_assessments} æ¬¡é‡è¡¨è¯„ä¼°")
            
            # ç ”ç©¶è®¾è®¡é¢„è§ˆ
            with st.expander("ç ”ç©¶è®¾è®¡é¢„è§ˆ", expanded=False):
                preview_df = pd.DataFrame([
                    {
                        'ä¸¥é‡ç¨‹åº¦': exp['template'],
                        'è¯„ä¼°æƒ…å¢ƒ': exp['scene'],
                        'è§‚å¯Ÿæ´»åŠ¨': exp['activity'],
                        'è§¦å‘å› ç´ ': exp['trigger'],
                        'è¯„ä¼°é‡è¡¨': ', '.join([AVAILABLE_SCALES[s]['name'] for s in exp['selected_scales']])
                    } for exp in experiments[:10]
                ])
                st.dataframe(preview_df)
                if len(experiments) > 10:
                    st.write(f"*...è¿˜æœ‰ {len(experiments) - 10} ä¸ªè¯„ä¼°*")
    
    with col2:
        st.subheader("ğŸš€ æ‰§è¡Œç ”ç©¶")
        
        # Session stateç®¡ç†
        if 'batch_ready' not in st.session_state:
            st.session_state.batch_ready = False
        if 'batch_running' not in st.session_state:
            st.session_state.batch_running = False
        
        if selected_severities and selected_contexts and selected_scales:
            # é¢„ä¼°æ—¶é—´ï¼ˆè€ƒè™‘å¤šé‡è¡¨ï¼‰
            time_per_sample = 0.5 * len(selected_scales)  # æ¯ä¸ªé‡è¡¨çº¦0.5åˆ†é’Ÿ
            estimated_minutes = len(experiments) * time_per_sample
            
            st.info(f"ğŸ“Š è¯„ä¼°æ•°é‡: {len(experiments)}")
            st.info(f"ğŸ“‹ é‡è¡¨æ•°é‡: {len(selected_scales)}")
            st.info(f"â° é¢„è®¡æ—¶é—´: {estimated_minutes:.1f} åˆ†é’Ÿ")
            
            if not st.session_state.batch_ready and not st.session_state.batch_running:
                if st.button("âš¡ å‡†å¤‡å¼€å§‹ç ”ç©¶", use_container_width=True):
                    st.session_state.batch_ready = True
                    st.rerun()
            
            elif st.session_state.batch_ready and not st.session_state.batch_running:
                st.warning("â° **é‡è¦**: ç”±äºAPIé™åˆ¶ï¼Œæ‰¹é‡ç ”ç©¶éœ€è¦è¾ƒé•¿æ—¶é—´")
                st.info(f"ğŸ’¡ æ¯ä¸ªæ ·æœ¬å°†è¿›è¡Œ{len(selected_scales)}ä¸ªé‡è¡¨è¯„ä¼°")
                
                col_btn1, col_btn2 = st.columns(2)
                
                with col_btn1:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        st.session_state.batch_ready = False
                        st.rerun()
                
                with col_btn2:
                    if st.button("âœ… å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True):
                        st.session_state.batch_running = True
                        st.session_state.batch_ready = False
                        st.rerun()
            
            elif st.session_state.batch_running:
                _run_batch_research_enhanced(experiments, selected_scales)
        
        else:
            if not selected_severities:
                st.error("è¯·é€‰æ‹©ä¸¥é‡ç¨‹åº¦")
            if not selected_contexts:
                st.error("è¯·é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ")
            if not selected_scales:
                st.error("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªè¯„ä¼°é‡è¡¨")


def _run_batch_research_enhanced(experiments, selected_scales):
    """æ‰§è¡Œå¢å¼ºç‰ˆæ‰¹é‡ç ”ç©¶"""
    st.success(f"ğŸ”¬ å¤šé‡è¡¨æ‰¹é‡ç ”ç©¶è¿›è¡Œä¸­...")
    st.info(f"ä½¿ç”¨é‡è¡¨: {', '.join([AVAILABLE_SCALES[s]['name'] for s in selected_scales])}")
    
    progress_container = st.container()
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
        result_container = st.empty()
    
    def update_progress(current, total):
        progress = current / total
        progress_bar.progress(progress)
        remaining_time = (total - current) * 0.5 * len(selected_scales) / 60
        status_text.text(f"ç ”ç©¶è¿›åº¦: {current}/{total} ({progress:.1%}) - é¢„è®¡è¿˜éœ€ {remaining_time:.1f} åˆ†é’Ÿ")
    
    try:
        # ä½¿ç”¨å¢å¼ºç‰ˆè¯„ä¼°å‡½æ•°
        results = run_batch_processing(
            experiments, 
            run_enhanced_experiment,  # ä½¿ç”¨å¢å¼ºç‰ˆå‡½æ•°
            update_progress,
            "å¤šé‡è¡¨è¯„ä¼°"
        )
        
        successful_results = [r for r in results if 'error' not in r]
        failed_results = [r for r in results if 'error' in r]
        
        # ä¿å­˜ç»“æœ
        st.session_state.current_batch_results = successful_results
        st.session_state.experiment_records.extend(successful_results)
        
        # æ¸…ç†è¿›åº¦æ˜¾ç¤º
        progress_bar.empty()
        status_text.empty()
        st.session_state.batch_running = False
        
        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        with result_container:
            st.success(f"âœ… æ‰¹é‡ç ”ç©¶å®Œæˆï¼")
            
            col_r1, col_r2, col_r3 = st.columns(3)
            with col_r1:
                st.metric("æˆåŠŸè¯„ä¼°", len(successful_results))
            with col_r2:
                st.metric("å¤±è´¥è¯„ä¼°", len(failed_results))
            with col_r3:
                success_rate = len(successful_results) / len(results) * 100
                st.metric("æˆåŠŸç‡", f"{success_rate:.1f}%")
            
            # åˆ†æç»“æœ
            if successful_results:
                st.subheader("ğŸ“Š ç ”ç©¶ç»“æœåˆ†æ")
                
                # æ ¹æ®ä½¿ç”¨çš„é‡è¡¨æ˜¾ç¤ºä¸åŒçš„åˆ†æ
                tabs = []
                if 'ABC' in selected_scales:
                    tabs.append("ABCé‡è¡¨åˆ†æ")
                if 'DSM5' in selected_scales:
                    tabs.append("DSM-5åˆ†æ")
                if 'CARS' in selected_scales:
                    tabs.append("CARSé‡è¡¨åˆ†æ")
                if 'ASSQ' in selected_scales:
                    tabs.append("ASSQç­›æŸ¥åˆ†æ")
                if len(selected_scales) > 1:
                    tabs.append("é‡è¡¨å¯¹æ¯”")
                
                if tabs:
                    tab_objects = st.tabs(tabs)
                    tab_idx = 0
                    
                    # ABCåˆ†æ
                    if 'ABC' in selected_scales:
                        with tab_objects[tab_idx]:
                            display_abc_batch_analysis(successful_results)
                        tab_idx += 1
                    
                    # DSM-5åˆ†æ
                    if 'DSM5' in selected_scales:
                        with tab_objects[tab_idx]:
                            display_dsm5_batch_analysis(successful_results)
                        tab_idx += 1
                    
                    # CARSåˆ†æ
                    if 'CARS' in selected_scales:
                        with tab_objects[tab_idx]:
                            display_cars_batch_analysis(successful_results)
                        tab_idx += 1
                    
                    # ASSQåˆ†æ
                    if 'ASSQ' in selected_scales:
                        with tab_objects[tab_idx]:
                            display_assq_batch_analysis(successful_results)
                        tab_idx += 1
                    
                    # é‡è¡¨å¯¹æ¯”
                    if len(selected_scales) > 1:
                        with tab_objects[tab_idx]:
                            display_scale_comparison_analysis(successful_results, selected_scales)
            
            # ä¸‹è½½é€‰é¡¹
            if st.button("ğŸ’¾ ä¿å­˜ç ”ç©¶æ•°æ®", use_container_width=True):
                save_batch_research_data(successful_results, selected_scales)
                st.success("æ•°æ®å·²ä¿å­˜ï¼")
                
    except Exception as e:
        st.error(f"æ‰¹é‡ç ”ç©¶å¤±è´¥: {str(e)}")
        st.session_state.batch_running = False


def display_abc_batch_analysis(results):
    """æ˜¾ç¤ºABCé‡è¡¨æ‰¹é‡åˆ†æ"""
    abc_scores = []
    for r in results:
        if 'abc_evaluation' in r:
            abc_scores.append(r['abc_evaluation']['total_score'])
    
    if abc_scores:
        df = pd.DataFrame({'ABCæ€»åˆ†': abc_scores})
        st.metric("å¹³å‡ABCæ€»åˆ†", f"{np.mean(abc_scores):.1f}")
        st.bar_chart(df)


def display_dsm5_batch_analysis(results):
    """æ˜¾ç¤ºDSM-5æ‰¹é‡åˆ†æ"""
    dsm5_scores = []
    for r in results:
        if 'dsm5_evaluation' in r:
            dsm5_scores.append(r['dsm5_evaluation']['core_symptom_average'])
    
    if dsm5_scores:
        df = pd.DataFrame({'DSM-5æ ¸å¿ƒç—‡çŠ¶': dsm5_scores})
        st.metric("å¹³å‡æ ¸å¿ƒç—‡çŠ¶", f"{np.mean(dsm5_scores):.2f}")
        st.line_chart(df)


def display_cars_batch_analysis(results):
    """æ˜¾ç¤ºCARSé‡è¡¨æ‰¹é‡åˆ†æ"""
    cars_scores = []
    for r in results:
        if 'cars_evaluation' in r:
            cars_scores.append(r['cars_evaluation']['total_score'])
    
    if cars_scores:
        df = pd.DataFrame({'CARSæ€»åˆ†': cars_scores})
        st.metric("å¹³å‡CARSæ€»åˆ†", f"{np.mean(cars_scores):.1f}")
        st.bar_chart(df)


def display_assq_batch_analysis(results):
    """æ˜¾ç¤ºASSQç­›æŸ¥æ‰¹é‡åˆ†æ"""
    assq_scores = []
    positive_count = 0
    for r in results:
        if 'assq_evaluation' in r:
            score = r['assq_evaluation']['total_score']
            assq_scores.append(score)
            if r['assq_evaluation']['positive_screen']:
                positive_count += 1
    
    if assq_scores:
        st.metric("å¹³å‡ASSQåˆ†æ•°", f"{np.mean(assq_scores):.1f}")
        st.metric("é˜³æ€§ç­›æŸ¥ç‡", f"{positive_count/len(assq_scores)*100:.1f}%")


def display_scale_comparison_analysis(results, scales):
    """æ˜¾ç¤ºé‡è¡¨å¯¹æ¯”åˆ†æ"""
    st.write("### é‡è¡¨ä¸€è‡´æ€§åˆ†æ")
    
    consistency_count = 0
    total_count = 0
    
    for result in results:
        if 'scale_comparison' in result:
            if result['scale_comparison'].get('consistency', {}).get('overall') == 'ä¸€è‡´':
                consistency_count += 1
            total_count += 1
    
    if total_count > 0:
        consistency_rate = consistency_count / total_count * 100
        st.metric("é‡è¡¨ä¸€è‡´æ€§ç‡", f"{consistency_rate:.1f}%")
        
        if consistency_rate < 70:
            st.warning("âš ï¸ é‡è¡¨é—´ä¸€è‡´æ€§è¾ƒä½ï¼Œå»ºè®®å¢åŠ æ ·æœ¬é‡æˆ–è°ƒæ•´è¯„ä¼°æ–¹æ³•")
        else:
            st.success("âœ… é‡è¡¨é—´ä¸€è‡´æ€§è‰¯å¥½")


def save_batch_research_data(results, scales):
    """ä¿å­˜æ‰¹é‡ç ”ç©¶æ•°æ®"""
    # å®ç°æ•°æ®ä¿å­˜é€»è¾‘
    pass