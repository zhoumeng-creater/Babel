"""å­¤ç‹¬ç—‡è¯„ä¼°æ•°æ®å¯¼å…¥é¡µé¢"""
import streamlit as st
import pandas as pd
from typing import Optional
import datetime

from common.importer import get_importer, ImportStatus
from common.data_storage_manager import DataStorageManager


def page_data_import():
    """æ•°æ®å¯¼å…¥é¡µé¢"""
    st.header("ğŸ“¥ æ•°æ®å¯¼å…¥")
    st.markdown("å¯¼å…¥å†å²è¯„ä¼°æ•°æ®ï¼Œæ”¯æŒCSVã€JSONã€Excelå’ŒZIPæ ¼å¼")
    
    # åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
    storage_manager = DataStorageManager(assessment_type='autism')
    
    # æ˜¾ç¤ºå½“å‰æ•°æ®ç»Ÿè®¡
    col1, col2, col3 = st.columns(3)
    summary = storage_manager.get_import_summary()
    
    with col1:
        st.metric("æ€»è®°å½•æ•°", summary['total_records'])
    with col2:
        st.metric("å¯¼å…¥è®°å½•", summary['imported_records'])
    with col3:
        st.metric("æœ¬åœ°è®°å½•", summary['native_records'])
    
    if summary['last_import']:
        st.info(f"æœ€åå¯¼å…¥æ—¶é—´: {summary['last_import'].strftime('%Y-%m-%d %H:%M:%S')}")
    
    st.divider()
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.subheader("ğŸ“¤ é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶")
    
    uploaded_file = st.file_uploader(
        "æ‹–æ‹½æ–‡ä»¶åˆ°æ­¤å¤„æˆ–ç‚¹å‡»æµè§ˆ",
        type=['csv', 'json', 'xlsx', 'xls', 'zip'],
        help="æ”¯æŒCSVã€JSONã€Excelå’ŒZIPå‹ç¼©åŒ…æ ¼å¼"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        file_info = {
            'filename': uploaded_file.name,
            'size': uploaded_file.size,
            'type': uploaded_file.type
        }
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**æ–‡ä»¶ä¿¡æ¯:**")
            st.write(f"- æ–‡ä»¶å: {file_info['filename']}")
            st.write(f"- å¤§å°: {_format_file_size(file_info['size'])}")
            st.write(f"- ç±»å‹: {file_info['type']}")
        
        with col2:
            # å¯¼å…¥é€‰é¡¹
            st.write("**å¯¼å…¥é€‰é¡¹:**")
            merge_strategy = st.selectbox(
                "æ•°æ®åˆå¹¶ç­–ç•¥",
                options=['append', 'skip_duplicates', 'replace'],
                format_func=lambda x: {
                    'append': 'è¿½åŠ æ‰€æœ‰æ•°æ®',
                    'skip_duplicates': 'è·³è¿‡é‡å¤è®°å½•',
                    'replace': 'æ›¿æ¢ç°æœ‰æ•°æ®'
                }[x],
                help="é€‰æ‹©å¦‚ä½•å¤„ç†å¯¼å…¥çš„æ•°æ®"
            )
            
            if merge_strategy == 'replace':
                st.warning("âš ï¸ æ›¿æ¢æ¨¡å¼å°†æ¸…ç©ºæ‰€æœ‰ç°æœ‰æ•°æ®ï¼")
        
        # å¯¼å…¥æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹å¯¼å…¥", type="primary"):
            process_import(uploaded_file, merge_strategy, storage_manager)
    
    # å¯¼å…¥å¸®åŠ©
    with st.expander("â“ å¯¼å…¥å¸®åŠ©"):
        st.markdown("""
        ### æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        
        1. **CSVæ–‡ä»¶** (.csv)
           - æ”¯æŒUTF-8ã€GBKç­‰å¸¸è§ç¼–ç 
           - è‡ªåŠ¨è¯†åˆ«åˆ†éš”ç¬¦
           - å¯åŒ…å«å­¤ç‹¬ç—‡è¯„ä¼°çš„å„ç§æ•°æ®
        
        2. **JSONæ–‡ä»¶** (.json)
           - æ”¯æŒå•æ¡æˆ–å¤šæ¡è®°å½•
           - ä¿ç•™å®Œæ•´çš„æ•°æ®ç»“æ„
           - é€‚åˆç¨‹åºé—´æ•°æ®äº¤æ¢
        
        3. **Excelæ–‡ä»¶** (.xlsx, .xls)
           - æ”¯æŒå¤šå·¥ä½œè¡¨
           - è‡ªåŠ¨è¯†åˆ«æ•°æ®ç±»å‹
           - é€‚åˆæ‰¹é‡æ•°æ®ç®¡ç†
        
        4. **ZIPå‹ç¼©åŒ…** (.zip)
           - å¯åŒ…å«å¤šä¸ªæ–‡ä»¶
           - æ”¯æŒæ··åˆæ ¼å¼
           - é€‚åˆå®Œæ•´é¡¹ç›®å¯¼å…¥
        
        ### æ•°æ®æ ¼å¼è¦æ±‚
        
        - å¿…éœ€å­—æ®µï¼š`è¯„ä¼°æ—¶é—´`/`timestamp`ã€`è¯„ä¼°æƒ…å¢ƒ`/`scene`
        - æ”¯æŒç»Ÿä¸€è¯„ä¼°ã€ABCè¯„ä¼°ã€DSM-5è¯„ä¼°ç­‰å¤šç§æ ¼å¼
        - è‡ªåŠ¨è¯†åˆ«å¹¶è½¬æ¢ä¸åŒç‰ˆæœ¬çš„æ•°æ®
        
        ### åˆå¹¶ç­–ç•¥è¯´æ˜
        
        - **è¿½åŠ æ‰€æœ‰æ•°æ®**ï¼šå°†å¯¼å…¥çš„æ•°æ®å…¨éƒ¨æ·»åŠ åˆ°ç°æœ‰æ•°æ®åé¢
        - **è·³è¿‡é‡å¤è®°å½•**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶è·³è¿‡ç›¸ä¼¼çš„è®°å½•
        - **æ›¿æ¢ç°æœ‰æ•°æ®**ï¼šæ¸…ç©ºç°æœ‰æ•°æ®ï¼Œåªä¿ç•™å¯¼å…¥çš„æ•°æ®
        """)


def process_import(uploaded_file, merge_strategy: str, storage_manager: DataStorageManager):
    """å¤„ç†æ–‡ä»¶å¯¼å…¥"""
    try:
        # è·å–æ–‡ä»¶æ‰©å±•å
        file_ext = uploaded_file.name.split('.')[-1].lower()
        
        # è·å–å¯¹åº”çš„å¯¼å…¥å™¨
        importer_class = get_importer(file_ext)
        importer = importer_class(assessment_type='autism')
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        status_text.text("æ­£åœ¨è¯»å–æ–‡ä»¶...")
        progress_bar.progress(20)
        
        file_content = uploaded_file.read()
        
        # å¯¼å…¥æ•°æ®
        status_text.text("æ­£åœ¨è§£ææ•°æ®...")
        progress_bar.progress(40)
        
        result = importer.import_data(file_content)
        
        # æ£€æŸ¥å¯¼å…¥ç»“æœ
        if result.status == ImportStatus.FAILED:
            progress_bar.progress(100)
            st.error("âŒ å¯¼å…¥å¤±è´¥")
            
            # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
            if result.errors:
                st.write("**é”™è¯¯è¯¦æƒ…:**")
                for error in result.errors[:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ªé”™è¯¯
                    st.write(f"- è¡Œ{error.get('row', 'N/A')}: {error['message']}")
                if len(result.errors) > 10:
                    st.write(f"...è¿˜æœ‰{len(result.errors) - 10}ä¸ªé”™è¯¯")
            return
        
        # åˆå¹¶æ•°æ®
        status_text.text("æ­£åœ¨åˆå¹¶æ•°æ®...")
        progress_bar.progress(60)
        
        merged_count, conflicts = storage_manager.merge_imported_data(
            result.records, 
            merge_strategy
        )
        
        # å®Œæˆ
        progress_bar.progress(100)
        status_text.empty()
        
        # æ˜¾ç¤ºç»“æœ
        if result.status == ImportStatus.SUCCESS:
            st.success(f"âœ… æˆåŠŸå¯¼å…¥ {merged_count} æ¡è®°å½•")
        elif result.status == ImportStatus.PARTIAL:
            st.warning(f"âš ï¸ éƒ¨åˆ†å¯¼å…¥æˆåŠŸ: {merged_count}/{result.total_count} æ¡è®°å½•")
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è§£æè®°å½•", result.total_count)
        with col2:
            st.metric("æˆåŠŸå¯¼å…¥", merged_count)
        with col3:
            st.metric("è·³è¿‡/å¤±è´¥", result.failed_count + result.skipped_count)
        
        # æ˜¾ç¤ºå†²çªä¿¡æ¯
        if conflicts:
            with st.expander(f"âš ï¸ å‘ç° {len(conflicts)} ä¸ªå†²çª"):
                for conflict in conflicts[:20]:
                    st.write(f"- {conflict}")
                if len(conflicts) > 20:
                    st.write(f"...è¿˜æœ‰{len(conflicts) - 20}ä¸ªå†²çª")
        
        # æ˜¾ç¤ºè­¦å‘Šä¿¡æ¯
        if result.warnings:
            with st.expander(f"âš ï¸ {len(result.warnings)} ä¸ªè­¦å‘Š"):
                for warning in result.warnings[:20]:
                    st.write(f"- {warning}")
        
        # æ˜¾ç¤ºå…ƒæ•°æ®
        if result.metadata:
            with st.expander("ğŸ“Š å¯¼å…¥å…ƒæ•°æ®"):
                if 'files_processed' in result.metadata:
                    st.write(f"**å¤„ç†çš„æ–‡ä»¶:** {', '.join(result.metadata['files_processed'])}")
                if 'files_skipped' in result.metadata:
                    st.write(f"**è·³è¿‡çš„æ–‡ä»¶:** {', '.join(result.metadata['files_skipped'])}")
        
        # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ–°æ•°æ®
        st.rerun()
        
    except Exception as e:
        st.error(f"âŒ å¯¼å…¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        st.exception(e)


def _format_file_size(size: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size < 1024.0:
            return f"{size:.1f} {unit}"
        size /= 1024.0
    return f"{size:.1f} TB"