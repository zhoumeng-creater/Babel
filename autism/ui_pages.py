"""å­¤ç‹¬ç—‡å¹³å°UIé¡µé¢ç»„ä»¶ - æ”¯æŒç»Ÿä¸€ç”Ÿæˆã€åŒæ ‡å‡†è¯„ä¼°"""
import streamlit as st
import pandas as pd
import datetime
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from scipy import stats

from common.batch_processor import run_batch_processing
from common.ui_components import display_metric_with_color
from .config import (
    UNIFIED_AUTISM_PROFILES, CLINICAL_SCENE_CONFIG, 
    ABC_EVALUATION_METRICS, ABC_BEHAVIOR_ITEMS,
    DSM5_EVALUATION_METRICS
)
from .evaluator import run_single_experiment, generate_experiment_batch
from .analyzer import (
    generate_clinical_analysis, 
    extract_behavior_specific_samples,
    calculate_sample_similarity,
    find_similar_samples,
    analyze_behavior_associations,
    get_behavior_summary_stats,
    get_behavior_summary_stats
)


def page_quick_assessment():
    """å¿«é€Ÿè¯„ä¼°é¡µé¢ - ç»Ÿä¸€ç”Ÿæˆï¼ŒåŒæ ‡å‡†è¯„ä¼°"""
    st.header("ğŸ©º å¿«é€Ÿä¸´åºŠè¯„ä¼°")
    st.markdown("ç”Ÿæˆå­¤ç‹¬ç—‡å„¿ç«¥è¡Œä¸ºè¡¨ç°ï¼ŒåŒæ—¶è¿›è¡ŒABCå’ŒDSM-5åŒé‡è¯„ä¼°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ é€‰æ‹©è¯„ä¼°å¯¹è±¡")
        
        # ä½¿ç”¨ç»Ÿä¸€çš„ä¸¥é‡ç¨‹åº¦é…ç½®
        selected_severity = st.selectbox("é€‰æ‹©ä¸¥é‡ç¨‹åº¦", list(UNIFIED_AUTISM_PROFILES.keys()))
        profile = UNIFIED_AUTISM_PROFILES[selected_severity]
        
        # æ˜¾ç¤ºç»Ÿä¸€ç‰¹å¾
        with st.expander("æŸ¥çœ‹å­¤ç‹¬ç—‡ç‰¹å¾é…ç½®", expanded=True):
            st.write(f"**ç±»å‹**: {profile['name']}")
            st.write(f"**ç¤¾äº¤ç‰¹å¾**: {profile['social_characteristics']}")
            st.write(f"**æ²Ÿé€šç‰¹å¾**: {profile['communication_characteristics']}")
            st.write(f"**è¡Œä¸ºç‰¹å¾**: {profile['behavioral_characteristics']}")
            st.write(f"**è®¤çŸ¥ç‰¹å¾**: {profile['cognitive_characteristics']}")
            st.write(f"**æƒ…ç»ªç‰¹å¾**: {profile['emotional_characteristics']}")
            st.write(f"**æ—¥å¸¸ç”Ÿæ´»**: {profile['daily_living']}")
            
            st.write("**å…¸å‹è¡Œä¸ºç¤ºä¾‹**:")
            for i, example in enumerate(profile['behavioral_examples'][:3], 1):
                st.write(f"{i}. {example}")
            
            if len(profile['behavioral_examples']) > 3:
                st.write(f"...è¿˜æœ‰{len(profile['behavioral_examples'])-3}ä¸ªè¡Œä¸ºç¤ºä¾‹")
        
        selected_scene = st.selectbox("é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ", list(CLINICAL_SCENE_CONFIG.keys()))
        
        scene_data = CLINICAL_SCENE_CONFIG[selected_scene]
        
        # æ˜¾ç¤ºåœºæ™¯ä¿¡æ¯
        with st.expander("è¯„ä¼°æƒ…å¢ƒè¯¦æƒ…"):
            st.write(f"**ç›®æ ‡**: {scene_data['target']}")
            st.write(f"**è§‚å¯Ÿè¦ç‚¹**: {', '.join(scene_data['observation_points'])}")
        
        selected_activity = st.selectbox("é€‰æ‹©è§‚å¯Ÿæ´»åŠ¨", scene_data['activities'])
        selected_trigger = st.selectbox("é€‰æ‹©è§¦å‘å› ç´ ", scene_data['triggers'])
    
    with col2:
        st.subheader("ğŸ”¬ æ‰§è¡Œè¯„ä¼°")
        
        st.info("ğŸ’¡ å°†ç”Ÿæˆä¸€æ¬¡è¡Œä¸ºè§‚å¯Ÿï¼ŒåŒæ—¶ä½¿ç”¨ABCé‡è¡¨å’ŒDSM-5æ ‡å‡†è¿›è¡Œè¯„ä¼°")
        
        if st.button("ğŸ©º å¼€å§‹åŒé‡è¯„ä¼°", type="primary", use_container_width=True):
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
            
            experiment_config = {
                'template': selected_severity,
                'scene': selected_scene,
                'activity': selected_activity,
                'trigger': selected_trigger,
                'autism_profile': profile.copy(),
                'experiment_id': f"UNI_{selected_severity[:4]}_{timestamp}"
            }
            
            with st.spinner("ğŸ¤– æ­£åœ¨ç”Ÿæˆä¸´åºŠè¯„ä¼°å¯¹è¯..."):
                result = run_single_experiment(experiment_config)
            
            if 'error' not in result:
                st.session_state.experiment_records.append(result)
                
                st.success(f"âœ… åŒé‡è¯„ä¼°å®Œæˆï¼ID: {result['experiment_id']}")
                
                # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                st.subheader("ğŸ“Š åŒé‡è¯„ä¼°ç»“æœå¯¹æ¯”")
                
                # åˆ›å»ºä¸¤åˆ—æ˜¾ç¤ºä¸¤ç§è¯„ä¼°ç»“æœ
                col_abc, col_dsm5 = st.columns(2)
                
                with col_abc:
                    st.markdown("### ğŸ“‹ ABCé‡è¡¨è¯„ä¼°")
                    
                    # ABCè¯„ä¼°ç»“æœ
                    abc_eval = result['abc_evaluation']
                    total_score = abc_eval['total_score']
                    severity = abc_eval['severity']
                    
                    if total_score >= 67:
                        st.error(f"**ABCæ€»åˆ†: {total_score}**")
                        st.error(f"**åˆ¤å®š: {severity}**")
                    elif total_score >= 53:
                        st.warning(f"**ABCæ€»åˆ†: {total_score}**")
                        st.warning(f"**åˆ¤å®š: {severity}**")
                    else:
                        st.info(f"**ABCæ€»åˆ†: {total_score}**")
                        st.info(f"**åˆ¤å®š: {severity}**")
                    
                    st.write("**å„é¢†åŸŸå¾—åˆ†**:")
                    for domain, score in abc_eval['domain_scores'].items():
                        max_score = ABC_EVALUATION_METRICS[domain]['max_score']
                        percentage = score / max_score * 100
                        st.write(f"â€¢ {domain}: {score}/{max_score} ({percentage:.0f}%)")
                    
                    # æ˜¾ç¤ºè¯†åˆ«åˆ°çš„ä¸»è¦è¡Œä¸º
                    if abc_eval['identified_behaviors']:
                        st.write("**è¯†åˆ«åˆ°çš„ä¸»è¦è¡Œä¸º**:")
                        behavior_count = 0
                        for domain, behaviors in abc_eval['identified_behaviors'].items():
                            if behaviors and behavior_count < 5:
                                for behavior in behaviors[:2]:
                                    st.write(f"â€¢ {behavior}")
                                    behavior_count += 1
                                    if behavior_count >= 5:
                                        break
                
                with col_dsm5:
                    st.markdown("### ğŸ§  DSM-5æ ‡å‡†è¯„ä¼°")
                    
                    # DSM-5è¯„ä¼°ç»“æœ
                    dsm5_eval = result['dsm5_evaluation']
                    core_avg = dsm5_eval['core_symptom_average']
                    
                    if core_avg >= 4.0:
                        st.error(f"**æ ¸å¿ƒç—‡çŠ¶å‡å€¼: {core_avg:.2f}/5**")
                        st.error("**éœ€è¦éå¸¸å¤§é‡æ”¯æŒ**")
                    elif core_avg >= 3.0:
                        st.warning(f"**æ ¸å¿ƒç—‡çŠ¶å‡å€¼: {core_avg:.2f}/5**")
                        st.warning("**éœ€è¦å¤§é‡æ”¯æŒ**")
                    else:
                        st.info(f"**æ ¸å¿ƒç—‡çŠ¶å‡å€¼: {core_avg:.2f}/5**")
                        st.info("**éœ€è¦æ”¯æŒ**")
                    
                    st.write("**å„ç»´åº¦è¯„åˆ†**:")
                    for metric, score in dsm5_eval['scores'].items():
                        severity_label = "è½»åº¦" if score < 2.5 else "ä¸­åº¦" if score < 3.5 else "é‡åº¦"
                        st.write(f"â€¢ {metric}: {score:.2f}/5 ({severity_label})")
                    
                    # æ˜¾ç¤ºä¸´åºŠè§‚å¯Ÿ
                    if dsm5_eval['clinical_observations']:
                        st.write("**ä¸´åºŠè§‚å¯Ÿè¦ç‚¹**:")
                        obs_count = 0
                        for category, observations in dsm5_eval['clinical_observations'].items():
                            if observations and obs_count < 5:
                                for obs in observations[:1]:
                                    st.write(f"â€¢ [{category}] {obs}")
                                    obs_count += 1
                                    if obs_count >= 5:
                                        break
                
                # è¯„ä¼°ä¸€è‡´æ€§åˆ†æ
                st.subheader("ğŸ”„ è¯„ä¼°ä¸€è‡´æ€§åˆ†æ")
                
                # ç®€å•çš„ä¸€è‡´æ€§åˆ¤æ–­
                abc_severe = total_score >= 67
                dsm5_severe = core_avg >= 3.5
                
                if abc_severe == dsm5_severe:
                    st.success("âœ… ä¸¤ç§è¯„ä¼°æ ‡å‡†çš„ä¸¥é‡ç¨‹åº¦åˆ¤æ–­åŸºæœ¬ä¸€è‡´")
                else:
                    st.warning("âš ï¸ ä¸¤ç§è¯„ä¼°æ ‡å‡†çš„ä¸¥é‡ç¨‹åº¦åˆ¤æ–­å­˜åœ¨å·®å¼‚")
                    if abc_severe and not dsm5_severe:
                        st.info("ABCé‡è¡¨æ˜¾ç¤ºè¾ƒä¸¥é‡ï¼Œä½†DSM-5è¯„ä¼°ç›¸å¯¹è¾ƒè½»")
                    else:
                        st.info("DSM-5è¯„ä¼°æ˜¾ç¤ºè¾ƒä¸¥é‡ï¼Œä½†ABCé‡è¡¨å¾—åˆ†ç›¸å¯¹è¾ƒä½")
                
                # å¯¹è¯é¢„è§ˆ
                with st.expander("æŸ¥çœ‹è¡Œä¸ºè§‚å¯Ÿå¯¹è¯", expanded=False):
                    dialogue_lines = result['dialogue'].split('\n')[:15]
                    for line in dialogue_lines:
                        if ':' in line and line.strip():
                            if 'å­¤ç‹¬ç—‡å„¿ç«¥' in line:
                                st.markdown(f"ğŸ§’ {line}")
                            else:
                                st.markdown(f"ğŸ‘¤ {line}")
                    
                    if len(result['dialogue'].split('\n')) > 15:
                        st.markdown("*...æŸ¥çœ‹å®Œæ•´è®°å½•è¯·å‰å¾€'è¯„ä¼°è®°å½•ç®¡ç†'*")
                        
            else:
                st.error(f"âŒ è¯„ä¼°å¤±è´¥: {result['error']}")


def page_batch_research():
    """æ‰¹é‡ç ”ç©¶é¡µé¢ - ç»Ÿä¸€ç”Ÿæˆï¼ŒåŒæ ‡å‡†è¯„ä¼°"""
    st.header("ğŸ”¬ æ‰¹é‡ä¸´åºŠç ”ç©¶")
    st.markdown("æ‰¹é‡ç”Ÿæˆè¡Œä¸ºæ ·æœ¬ï¼ŒåŒæ—¶è¿›è¡ŒABCå’ŒDSM-5åŒé‡è¯„ä¼°å¯¹æ¯”")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ¯ ç ”ç©¶è®¾è®¡")
        
        research_scale = st.radio(
            "é€‰æ‹©ç ”ç©¶è§„æ¨¡",
            ["è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰", "æ ‡å‡†ç ”ç©¶", "å¤§æ ·æœ¬ç ”ç©¶"],
            help="æ ¹æ®ç ”ç©¶éœ€è¦é€‰æ‹©åˆé€‚çš„æ ·æœ¬è§„æ¨¡"
        )
        
        if research_scale == "è¯•ç‚¹ç ”ç©¶ï¼ˆæ¨èï¼‰":
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())[:2]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:2]
            default_repeats = 1
            st.info("ğŸš€ è¯•ç‚¹ç ”ç©¶ï¼šéªŒè¯åŒé‡è¯„ä¼°æ•ˆæœï¼Œçº¦éœ€5-8åˆ†é’Ÿ")
        elif research_scale == "æ ‡å‡†ç ”ç©¶":
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())[:3]
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())[:3]
            default_repeats = 2
            st.info("â³ æ ‡å‡†ç ”ç©¶ï¼šè·å¾—å¯é å¯¹æ¯”æ•°æ®ï¼Œçº¦éœ€20-30åˆ†é’Ÿ")
        else:
            default_severities = list(UNIFIED_AUTISM_PROFILES.keys())
            default_contexts = list(CLINICAL_SCENE_CONFIG.keys())
            default_repeats = 2
            st.warning("â° å¤§æ ·æœ¬ç ”ç©¶ï¼šå®Œæ•´å¯¹æ¯”ç ”ç©¶æ•°æ®ï¼Œçº¦éœ€60-90åˆ†é’Ÿ")
        
        selected_severities = st.multiselect(
            "é€‰æ‹©ä¸¥é‡ç¨‹åº¦ç»„", 
            list(UNIFIED_AUTISM_PROFILES.keys()),
            default=default_severities
        )
        
        selected_contexts = st.multiselect(
            "é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ",
            list(CLINICAL_SCENE_CONFIG.keys()),
            default=default_contexts
        )
        
        repeats_per_combo = st.slider(
            "æ¯ç»„åˆé‡å¤æ¬¡æ•°", 
            1, 3, 
            default_repeats,
            help="å¢åŠ é‡å¤æ¬¡æ•°æé«˜ç»Ÿè®¡å¯é æ€§"
        )
        
        if selected_severities and selected_contexts:
            severity_dict = {k: UNIFIED_AUTISM_PROFILES[k] for k in selected_severities}
            context_dict = {k: CLINICAL_SCENE_CONFIG[k] for k in selected_contexts}
            
            experiments = generate_experiment_batch(
                severity_dict, 
                context_dict, 
                repeats_per_combo
            )
            
            st.info(f"ğŸ“Š å°†ç”Ÿæˆ {len(experiments)} ä¸ªè¡Œä¸ºæ ·æœ¬ï¼Œæ¯ä¸ªè¿›è¡ŒåŒé‡è¯„ä¼°")
            
            # ç ”ç©¶è®¾è®¡é¢„è§ˆ
            with st.expander("ç ”ç©¶è®¾è®¡é¢„è§ˆ", expanded=False):
                preview_df = pd.DataFrame([
                    {
                        'ä¸¥é‡ç¨‹åº¦': exp['template'],
                        'è¯„ä¼°æƒ…å¢ƒ': exp['scene'],
                        'è§‚å¯Ÿæ´»åŠ¨': exp['activity'],
                        'è§¦å‘å› ç´ ': exp['trigger']
                    } for exp in experiments[:10]
                ])
                st.dataframe(preview_df)
                if len(experiments) > 10:
                    st.write(f"*...è¿˜æœ‰ {len(experiments) - 10} ä¸ªè¯„ä¼°*")
    
    with col2:
        st.subheader("ğŸš€ æ‰§è¡Œç ”ç©¶")
        
        if 'batch_ready' not in st.session_state:
            st.session_state.batch_ready = False
        if 'batch_running' not in st.session_state:
            st.session_state.batch_running = False
        
        if selected_severities and selected_contexts:
            estimated_minutes = len(experiments) * 25 / 60
            st.info(f"ğŸ“Š è¯„ä¼°æ•°é‡: {len(experiments)}")
            st.info(f"â° é¢„è®¡æ—¶é—´: {estimated_minutes:.1f} åˆ†é’Ÿ")
            st.info(f"ğŸ“ˆ å°†äº§ç”Ÿ: {len(experiments)*2} ä¸ªè¯„ä¼°ç»“æœ")
            
            if not st.session_state.batch_ready and not st.session_state.batch_running:
                if st.button("âš¡ å‡†å¤‡å¼€å§‹ç ”ç©¶", use_container_width=True):
                    st.session_state.batch_ready = True
                    st.rerun()
            
            elif st.session_state.batch_ready and not st.session_state.batch_running:
                st.warning("â° **é‡è¦**: ç”±äºAPIé™åˆ¶ï¼Œæ‰¹é‡ç ”ç©¶éœ€è¦è¾ƒé•¿æ—¶é—´")
                st.info("ğŸ’¡ æ¯ä¸ªæ ·æœ¬å°†åŒæ—¶è¿›è¡ŒABCå’ŒDSM-5è¯„ä¼°")
                
                col_btn1, col_btn2 = st.columns(2)
                
                with col_btn1:
                    if st.button("âŒ å–æ¶ˆ", use_container_width=True):
                        st.session_state.batch_ready = False
                        st.rerun()
                
                with col_btn2:
                    if st.button("âœ… å¼€å§‹ç ”ç©¶", type="primary", use_container_width=True):
                        st.session_state.batch_running = True
                        st.session_state.batch_ready = False
                        st.rerun()
            
            elif st.session_state.batch_running:
                st.success("ğŸ”¬ åŒé‡è¯„ä¼°ç ”ç©¶è¿›è¡Œä¸­...")
                
                progress_container = st.container()
                with progress_container:
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    result_container = st.empty()
                
                def update_progress(current, total):
                    progress = current / total
                    progress_bar.progress(progress)
                    remaining_time = (total - current) * 25 / 60
                    status_text.text(f"ç ”ç©¶è¿›åº¦: {current}/{total} ({progress:.1%}) - é¢„è®¡è¿˜éœ€ {remaining_time:.1f} åˆ†é’Ÿ")
                
                try:
                    results = run_batch_processing(
                        experiments, 
                        run_single_experiment, 
                        update_progress,
                        "åŒé‡è¯„ä¼°"
                    )
                    
                    successful_results = [r for r in results if 'error' not in r]
                    failed_results = [r for r in results if 'error' in r]
                    
                    st.session_state.experiment_records.extend(successful_results)
                    st.session_state.current_batch_results = successful_results
                    
                    with result_container:
                        st.success(f"âœ… åŒé‡è¯„ä¼°ç ”ç©¶å®Œæˆï¼")
                        st.write(f"**æˆåŠŸè¯„ä¼°**: {len(successful_results)} ä¸ªæ ·æœ¬")
                        st.write(f"**è¯„ä¼°ç»“æœ**: {len(successful_results)*2} ä¸ªï¼ˆABC+DSM-5ï¼‰")
                        
                        if failed_results:
                            st.error(f"**å¤±è´¥è¯„ä¼°**: {len(failed_results)} ä¸ª")
                        
                        if successful_results:
                            st.subheader("ğŸ“ˆ åŒé‡è¯„ä¼°ç»“æœæ¦‚è§ˆ")
                            
                            # åˆ†æè¯„ä¼°ä¸€è‡´æ€§
                            consistency_analysis = analyze_batch_consistency(successful_results)
                            
                            col_cons1, col_cons2, col_cons3 = st.columns(3)
                            with col_cons1:
                                st.metric("æ ·æœ¬æ€»æ•°", len(successful_results))
                            with col_cons2:
                                st.metric("ä¸€è‡´ç‡", f"{consistency_analysis['consistency_rate']:.1f}%")
                            with col_cons3:
                                st.metric("ç›¸å…³ç³»æ•°", f"{consistency_analysis['correlation']:.3f}")
                            
                            # æ˜¾ç¤ºä¸¥é‡ç¨‹åº¦å¯¹æ¯”
                            comparison_df = create_severity_comparison_df(successful_results)
                            st.dataframe(comparison_df, use_container_width=True)
                            
                            # å¯è§†åŒ–å¯¹æ¯”
                            fig = create_assessment_comparison_plot(successful_results)
                            st.plotly_chart(fig, use_container_width=True)
                    
                    st.session_state.batch_running = False
                    
                    if st.button("ğŸ”„ è¿›è¡Œæ–°ç ”ç©¶", use_container_width=True):
                        st.session_state.batch_ready = False
                        st.session_state.batch_running = False
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"âŒ ç ”ç©¶å‡ºé”™: {str(e)}")
                    st.session_state.batch_running = False
                    if st.button("ğŸ”„ é‡æ–°å°è¯•", use_container_width=True):
                        st.rerun()
        
        else:
            st.error("è¯·å…ˆé€‰æ‹©ä¸¥é‡ç¨‹åº¦å’Œè¯„ä¼°æƒ…å¢ƒ")


def page_custom_assessment():
    """ä¸ªæ€§åŒ–è¯„ä¼°è®¾è®¡é¡µé¢ - ç»Ÿä¸€ç”Ÿæˆï¼ŒåŒæ ‡å‡†è¯„ä¼°"""
    st.header("âš™ï¸ ä¸ªæ€§åŒ–è¯„ä¼°è®¾è®¡")
    st.markdown("è‡ªå®šä¹‰å­¤ç‹¬ç—‡ç‰¹å¾ï¼Œç”Ÿæˆè¡Œä¸ºè¡¨ç°å¹¶è¿›è¡ŒåŒé‡è¯„ä¼°")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ­ è¯„ä¼°æƒ…å¢ƒè®¾ç½®")
        selected_scene = st.selectbox("é€‰æ‹©è¯„ä¼°æƒ…å¢ƒ", list(CLINICAL_SCENE_CONFIG.keys()))
        scene_data = CLINICAL_SCENE_CONFIG[selected_scene]
        
        st.info(f"**è¯„ä¼°ç›®æ ‡**: {scene_data['target']}")
        
        # æ˜¾ç¤ºè§‚å¯Ÿè¦ç‚¹
        with st.expander("ä¸´åºŠè§‚å¯Ÿè¦ç‚¹"):
            for point in scene_data['observation_points']:
                st.write(f"â€¢ {point}")
        
        selected_activity = st.selectbox("é€‰æ‹©è§‚å¯Ÿæ´»åŠ¨", scene_data['activities'])
        selected_trigger = st.selectbox("é€‰æ‹©è§¦å‘å› ç´ ", scene_data['triggers'])
    
    with col2:
        st.subheader("ğŸ‘¤ ç‰¹å¾é…ç½®")
        
        template_base = st.selectbox("åŸºäºæ¨¡æ¿", ["è‡ªå®šä¹‰"] + list(UNIFIED_AUTISM_PROFILES.keys()))
        
        if template_base != "è‡ªå®šä¹‰":
            base_profile = UNIFIED_AUTISM_PROFILES[template_base].copy()
            st.info(f"åŸºäº: {base_profile['name']}")
        else:
            base_profile = {
                'name': "è‡ªå®šä¹‰é…ç½®",
                'social_characteristics': "ç¤¾äº¤èƒ½åŠ›å—é™ï¼Œå€¾å‘ç‹¬å¤„",
                'communication_characteristics': "è¯­è¨€å‘å±•è¿Ÿç¼“ï¼Œç†è§£å›°éš¾",
                'behavioral_characteristics': "æœ‰é‡å¤åˆ»æ¿è¡Œä¸ºï¼Œå…´è¶£ç‹­çª„",
                'cognitive_characteristics': "è®¤çŸ¥å‘å±•ä¸å‡è¡¡",
                'emotional_characteristics': "æƒ…ç»ªè°ƒèŠ‚å›°éš¾",
                'daily_living': "éœ€è¦æ”¯æŒå’Œå¼•å¯¼",
                'overall_functioning': "need_support",
                'behavioral_examples': ["é‡å¤æŸäº›åŠ¨ä½œ", "å¯¹å˜åŒ–æ•æ„Ÿ", "è¯­è¨€ä½¿ç”¨ç‰¹æ®Š"]
            }
        
        st.write("**è‡ªå®šä¹‰ç‰¹å¾æè¿°**")
        
        social_char = st.text_area(
            "ç¤¾äº¤ç‰¹å¾", 
            base_profile['social_characteristics'],
            height=60,
            help="æè¿°ç¤¾äº¤äº’åŠ¨çš„ç‰¹ç‚¹"
        )
        
        comm_char = st.text_area(
            "æ²Ÿé€šç‰¹å¾", 
            base_profile['communication_characteristics'],
            height=60,
            help="æè¿°è¯­è¨€å’Œæ²Ÿé€šèƒ½åŠ›"
        )
        
        behavior_char = st.text_area(
            "è¡Œä¸ºç‰¹å¾", 
            base_profile['behavioral_characteristics'],
            height=60,
            help="æè¿°é‡å¤åˆ»æ¿è¡Œä¸ºå’Œå…´è¶£"
        )
        
        cognitive_char = st.text_area(
            "è®¤çŸ¥ç‰¹å¾", 
            base_profile['cognitive_characteristics'],
            height=60,
            help="æè¿°è®¤çŸ¥å’Œå­¦ä¹ èƒ½åŠ›"
        )
        
        emotional_char = st.text_area(
            "æƒ…ç»ªç‰¹å¾", 
            base_profile['emotional_characteristics'],
            height=60,
            help="æè¿°æƒ…ç»ªè¡¨è¾¾å’Œè°ƒèŠ‚"
        )
        
        daily_living = st.text_area(
            "æ—¥å¸¸ç”Ÿæ´»", 
            base_profile['daily_living'],
            height=60,
            help="æè¿°è‡ªç†å’Œé€‚åº”èƒ½åŠ›"
        )
        
        # åŠŸèƒ½æ°´å¹³é€‰æ‹©
        functioning_level = st.select_slider(
            "æ•´ä½“åŠŸèƒ½æ°´å¹³",
            options=['mainstream_with_support', 'need_support', 'need_substantial_support', 'need_very_substantial_support'],
            value=base_profile.get('overall_functioning', 'need_support'),
            format_func=lambda x: {
                'mainstream_with_support': 'ä¸»æµ+æ”¯æŒ',
                'need_support': 'éœ€è¦æ”¯æŒ', 
                'need_substantial_support': 'éœ€è¦å¤§é‡æ”¯æŒ',
                'need_very_substantial_support': 'éœ€è¦éå¸¸å¤§é‡æ”¯æŒ'
            }[x]
        )
        
        # è¡Œä¸ºç¤ºä¾‹
        st.write("**å…¸å‹è¡Œä¸ºç¤ºä¾‹** (æ¯è¡Œä¸€ä¸ª)")
        behavior_examples_text = st.text_area(
            "è¡Œä¸ºç¤ºä¾‹",
            '\n'.join(base_profile.get('behavioral_examples', [])),
            height=100,
            help="è¾“å…¥å…·ä½“çš„è¡Œä¸ºè¡¨ç°ç¤ºä¾‹"
        )
        
        behavior_examples = [ex.strip() for ex in behavior_examples_text.split('\n') if ex.strip()]
        
        # æ„å»ºè‡ªå®šä¹‰é…ç½®
        custom_profile = {
            'name': f"è‡ªå®šä¹‰ - {template_base}" if template_base != "è‡ªå®šä¹‰" else "å®Œå…¨è‡ªå®šä¹‰",
            'social_characteristics': social_char,
            'communication_characteristics': comm_char,
            'behavioral_characteristics': behavior_char,
            'cognitive_characteristics': cognitive_char,
            'emotional_characteristics': emotional_char,
            'daily_living': daily_living,
            'overall_functioning': functioning_level,
            'behavioral_examples': behavior_examples
        }
    
    # æ‰§è¡Œä¸ªæ€§åŒ–è¯„ä¼°
    st.subheader("ğŸ”¬ æ‰§è¡Œä¸ªæ€§åŒ–åŒé‡è¯„ä¼°")
    
    if st.button("ğŸ©º å¼€å§‹ä¸ªæ€§åŒ–è¯„ä¼°", type="primary", use_container_width=True):
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S_%f')[:-3]
        
        experiment_config = {
            'template': template_base if template_base != "è‡ªå®šä¹‰" else "ä¸ªæ€§åŒ–é…ç½®",
            'scene': selected_scene,
            'activity': selected_activity,
            'trigger': selected_trigger,
            'autism_profile': custom_profile,
            'experiment_id': f"CUSTOM_{timestamp}"
        }
        
        with st.spinner("ğŸ¤– æ­£åœ¨ç”Ÿæˆä¸ªæ€§åŒ–è¯„ä¼°..."):
            result = run_single_experiment(experiment_config)
        
        if 'error' not in result:
            st.session_state.experiment_records.append(result)
            
            st.success(f"âœ… ä¸ªæ€§åŒ–åŒé‡è¯„ä¼°å®Œæˆï¼ID: {result['experiment_id']}")
            
            # æ˜¾ç¤ºè¯¦ç»†è¯„ä¼°ç»“æœ
            st.subheader("ğŸ“Š ä¸ªæ€§åŒ–è¯„ä¼°è¯¦ç»†ç»“æœ")
            
            # åˆ›å»ºæ ‡ç­¾é¡µæ˜¾ç¤ºä¸¤ç§è¯„ä¼°
            tab_abc, tab_dsm5, tab_compare = st.tabs(["ABCé‡è¡¨è¯„ä¼°", "DSM-5æ ‡å‡†è¯„ä¼°", "å¯¹æ¯”åˆ†æ"])
            
            with tab_abc:
                display_abc_detailed_results(result['abc_evaluation'])
            
            with tab_dsm5:
                display_dsm5_detailed_results(result['dsm5_evaluation'])
            
            with tab_compare:
                display_assessment_comparison(result)
                
        else:
            st.error(f"âŒ è¯„ä¼°å¤±è´¥: {result['error']}")
    
    # ä¿å­˜é…ç½®
    if st.button("ğŸ’¾ ä¿å­˜è¯„ä¼°é…ç½®", use_container_width=True):
        st.session_state.custom_autism_profile = custom_profile
        st.session_state.custom_scene_config = {
            'scene': selected_scene,
            'activity': selected_activity,
            'trigger': selected_trigger
        }
        st.success("âœ… ä¸ªæ€§åŒ–é…ç½®å·²ä¿å­˜ï¼")


def page_data_analysis():
    """æ•°æ®åˆ†æé¡µé¢ - æ”¯æŒåŒé‡è¯„ä¼°æ•°æ®åˆ†æ"""
    st.header("ğŸ“ˆ ä¸´åºŠæ•°æ®åˆ†æ")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.warning("ğŸ“Š æš‚æ— è¯„ä¼°æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œä¸´åºŠè¯„ä¼°")
        st.stop()
    
    # ç”Ÿæˆåˆ†æ
    analysis = generate_clinical_analysis(records)
    
    # æ•°æ®æ¦‚è§ˆ
    st.subheader("ğŸ¥ è¯„ä¼°æ•°æ®æ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("è¯„ä¼°æ€»æ•°", len(records))
    with col2:
        st.metric("è¯„ä¼°æƒ…å¢ƒæ•°", len(set(r['scene'] for r in records)))
    with col3:
        # è®¡ç®—å¹³å‡ABCæ€»åˆ†
        avg_abc = np.mean([r['abc_evaluation']['total_score'] for r in records])
        st.metric("å¹³å‡ABCæ€»åˆ†", f"{avg_abc:.1f}")
    with col4:
        # è®¡ç®—å¹³å‡DSM-5æ ¸å¿ƒç—‡çŠ¶
        avg_dsm5 = np.mean([r['dsm5_evaluation']['core_symptom_average'] for r in records])
        st.metric("å¹³å‡DSM-5æ ¸å¿ƒ", f"{avg_dsm5:.2f}")
    
    # è¯„ä¼°ä¸€è‡´æ€§åˆ†æ
    st.subheader("ğŸ”„ ABCä¸DSM-5è¯„ä¼°ä¸€è‡´æ€§åˆ†æ")
    
    consistency_results = get_behavior_summary_stats(records)
    
    col_cons1, col_cons2, col_cons3 = st.columns(3)
    with col_cons1:
        st.metric("Pearsonç›¸å…³ç³»æ•°", f"{consistency_results['correlation']:.3f}")
        st.write(f"på€¼: {consistency_results['p_value']:.4f}")
    with col_cons2:
        st.metric("ä¸€è‡´æ€§æ¯”ä¾‹", f"{consistency_results['agreement_rate']:.1f}%")
        st.write("(ä¸¥é‡ç¨‹åº¦åˆ¤æ–­ä¸€è‡´)")
    with col_cons3:
        st.metric("è¯„åˆ†å·®å¼‚", f"{consistency_results['mean_difference']:.2f}")
        st.write("(æ ‡å‡†åŒ–å)")
    
    # æ•£ç‚¹å›¾æ˜¾ç¤ºç›¸å…³æ€§
    fig_scatter = create_correlation_scatter(records)
    st.plotly_chart(fig_scatter, use_container_width=True)
    
    # åˆ†åˆ«æ˜¾ç¤ºä¸¤ç§è¯„ä¼°çš„ç»“æœ
    tab1, tab2, tab3 = st.tabs(["ABCé‡è¡¨åˆ†æ", "DSM-5æ ‡å‡†åˆ†æ", "ç»¼åˆå¯¹æ¯”"])
    
    with tab1:
        display_abc_analysis(records, analysis)
    
    with tab2:
        display_dsm5_analysis(records, analysis)
    
    with tab3:
        display_comprehensive_comparison(records, analysis)
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ
    if len(records) > 10:
        st.subheader("ğŸ“ ç»Ÿè®¡å­¦åˆ†æ")
        display_statistical_analysis(records)


def page_records_management():
    """è¯„ä¼°è®°å½•ç®¡ç†é¡µé¢ - æ”¯æŒåŒé‡è¯„ä¼°æ•°æ®"""
    st.header("ğŸ“š è¯„ä¼°è®°å½•ç®¡ç†")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.info("ğŸ“ æš‚æ— è¯„ä¼°è®°å½•")
        st.stop()
    
    st.subheader(f"ğŸ“Š å…±æœ‰ {len(records)} æ¡è¯„ä¼°è®°å½•")
    
    # é«˜çº§ç­›é€‰é€‰é¡¹
    col_filter1, col_filter2, col_filter3, col_filter4 = st.columns(4)
    
    with col_filter1:
        severity_filter = st.selectbox(
            "æŒ‰ä¸¥é‡ç¨‹åº¦ç­›é€‰",
            ["å…¨éƒ¨"] + list(set([r.get('template', 'è‡ªå®šä¹‰') for r in records]))
        )
    
    with col_filter2:
        context_filter = st.selectbox(
            "æŒ‰è¯„ä¼°æƒ…å¢ƒç­›é€‰",
            ["å…¨éƒ¨"] + list(set([r['scene'] for r in records]))
        )
    
    with col_filter3:
        # åŸºäºABCæˆ–DSM-5çš„ç­›é€‰
        score_filter = st.selectbox(
            "æŒ‰è¯„åˆ†ç­›é€‰",
            ["å…¨éƒ¨", "ABCé«˜åˆ†(â‰¥67)", "ABCä½åˆ†(<53)", "DSM5é‡åº¦(â‰¥3.5)", "DSM5è½»åº¦(<2.5)"]
        )
    
    with col_filter4:
        sort_by = st.selectbox(
            "æ’åºæ–¹å¼", 
            ["æ—¶é—´å€’åº", "æ—¶é—´æ­£åº", "ABCæ€»åˆ†", "DSM-5æ ¸å¿ƒç—‡çŠ¶", "ä¸€è‡´æ€§"]
        )
    
    # åº”ç”¨ç­›é€‰
    filtered_records = records.copy()
    
    if severity_filter != "å…¨éƒ¨":
        filtered_records = [r for r in filtered_records if r.get('template', 'è‡ªå®šä¹‰') == severity_filter]
    
    if context_filter != "å…¨éƒ¨":
        filtered_records = [r for r in filtered_records if r['scene'] == context_filter]
    
    if score_filter != "å…¨éƒ¨":
        if score_filter == "ABCé«˜åˆ†(â‰¥67)":
            filtered_records = [r for r in filtered_records if r['abc_evaluation']['total_score'] >= 67]
        elif score_filter == "ABCä½åˆ†(<53)":
            filtered_records = [r for r in filtered_records if r['abc_evaluation']['total_score'] < 53]
        elif score_filter == "DSM5é‡åº¦(â‰¥3.5)":
            filtered_records = [r for r in filtered_records if r['dsm5_evaluation']['core_symptom_average'] >= 3.5]
        elif score_filter == "DSM5è½»åº¦(<2.5)":
            filtered_records = [r for r in filtered_records if r['dsm5_evaluation']['core_symptom_average'] < 2.5]
    
    # åº”ç”¨æ’åº
    if sort_by == "æ—¶é—´æ­£åº":
        filtered_records = sorted(filtered_records, key=lambda x: x['timestamp'])
    elif sort_by == "ABCæ€»åˆ†":
        filtered_records = sorted(filtered_records, key=lambda x: x['abc_evaluation']['total_score'], reverse=True)
    elif sort_by == "DSM-5æ ¸å¿ƒç—‡çŠ¶":
        filtered_records = sorted(filtered_records, key=lambda x: x['dsm5_evaluation']['core_symptom_average'], reverse=True)
    elif sort_by == "ä¸€è‡´æ€§":
        # æŒ‰ABCå’ŒDSM-5è¯„ä¼°çš„ä¸€è‡´æ€§æ’åº
        def get_consistency(record):
            abc_severe = record['abc_evaluation']['total_score'] >= 67
            dsm5_severe = record['dsm5_evaluation']['core_symptom_average'] >= 3.5
            return 1 if abc_severe == dsm5_severe else 0
        filtered_records = sorted(filtered_records, key=get_consistency, reverse=True)
    else:  # æ—¶é—´å€’åº
        filtered_records = sorted(filtered_records, key=lambda x: x['timestamp'], reverse=True)
    
    st.write(f"ç­›é€‰åè®°å½•æ•°: {len(filtered_records)}")
    
    # è®°å½•åˆ—è¡¨æ˜¾ç¤º
    for i, record in enumerate(filtered_records):
        
        # è·å–åŒé‡è¯„ä¼°ç»“æœ
        abc_total = record['abc_evaluation']['total_score']
        abc_severity = record['abc_evaluation']['severity']
        dsm5_core = record['dsm5_evaluation']['core_symptom_average']
        
        # åˆ¤æ–­ä¸€è‡´æ€§
        abc_severe = abc_total >= 67
        dsm5_severe = dsm5_core >= 3.5
        consistency = "âœ…" if abc_severe == dsm5_severe else "âš ï¸"
        
        # æ˜¾ç¤ºæ ‡é¢˜
        display_title = (f"{consistency} {record['experiment_id']} - "
                        f"ABC:{abc_total} | DSM5:{dsm5_core:.2f} - "
                        f"{record['timestamp'].strftime('%m-%d %H:%M')}")
        
        with st.expander(display_title):
            
            # åŸºæœ¬ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.write("**ğŸ“‹ è¯„ä¼°åŸºæœ¬ä¿¡æ¯:**")
                st.write(f"â€¢ é…ç½®ç±»å‹: {record.get('template', 'è‡ªå®šä¹‰')}")
                st.write(f"â€¢ è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
                st.write(f"â€¢ è§‚å¯Ÿæ´»åŠ¨: {record.get('activity', 'æœªæŒ‡å®š')}")
                st.write(f"â€¢ è§¦å‘å› ç´ : {record.get('trigger', 'æœªæŒ‡å®š')}")
                st.write(f"â€¢ è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
            
            with col2:
                st.write("**ğŸ“Š ABCé‡è¡¨è¯„ä¼°:**")
                st.write(f"â€¢ æ€»åˆ†: {abc_total}")
                st.write(f"â€¢ ä¸¥é‡ç¨‹åº¦: {abc_severity}")
                st.write("â€¢ å„é¢†åŸŸå¾—åˆ†:")
                for domain, score in record['abc_evaluation']['domain_scores'].items():
                    st.write(f"  - {domain}: {score}")
            
            with col3:
                st.write("**ğŸ§  DSM-5æ ‡å‡†è¯„ä¼°:**")
                st.write(f"â€¢ æ ¸å¿ƒç—‡çŠ¶å‡å€¼: {dsm5_core:.2f}")
                st.write("â€¢ å„ç»´åº¦è¯„åˆ†:")
                for metric, score in record['dsm5_evaluation']['scores'].items():
                    if metric in ['ç¤¾äº¤äº’åŠ¨è´¨é‡', 'æ²Ÿé€šäº¤æµèƒ½åŠ›', 'åˆ»æ¿é‡å¤è¡Œä¸º']:
                        st.write(f"  - {metric}: {score:.2f} â­")
                    else:
                        st.write(f"  - {metric}: {score:.2f}")
            
            # å¯¹è¯è®°å½•
            st.write("**ğŸ’¬ è¡Œä¸ºè§‚å¯Ÿå¯¹è¯è®°å½•:**")
            dialogue_text = record['dialogue']
            
            unique_key = f"dialogue_{i}_{record['experiment_id']}_{record['timestamp'].strftime('%Y%m%d_%H%M%S')}"
            st.text_area("", dialogue_text, height=200, key=unique_key)
            
            # å¿«é€Ÿæ“ä½œæŒ‰é’®
            col_btn1, col_btn2, col_btn3, col_btn4 = st.columns(4)  
            
            with col_btn1:
                if st.button(f"ğŸ“‹ ç”ŸæˆæŠ¥å‘Š", key=f"report_{record['experiment_id']}"):
                    st.info("åŒé‡è¯„ä¼°æŠ¥å‘Šç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­...")
            
            with col_btn2:
                if st.button(f"ğŸ“ˆ è¯¦ç»†åˆ†æ", key=f"analysis_{record['experiment_id']}"):
                    display_single_record_analysis(record)
            
            with col_btn3:
                if st.button(f"ğŸ”„ é‡å¤è¯„ä¼°", key=f"repeat_{record['experiment_id']}"):
                    st.info("é‡å¤è¯„ä¼°åŠŸèƒ½å¼€å‘ä¸­...")
            
            with col_btn4:
                if st.button(f"ğŸ” æŸ¥æ‰¾ç›¸ä¼¼", key=f"similar_{record['experiment_id']}"):
                    with st.spinner("æ­£åœ¨æŸ¥æ‰¾ç›¸ä¼¼æ ·æœ¬..."):
                        similar_samples = find_similar_samples(
                            record, 
                            st.session_state.experiment_records,
                            threshold=0.7,
                            max_results=5
                        )
                    
                    if similar_samples:
                        st.write("**ç›¸ä¼¼æ ·æœ¬ï¼š**")
                        for idx, item in enumerate(similar_samples, 1):
                            similar_record = item['record']
                            st.write(f"{idx}. {similar_record['experiment_id']} - "
                                   f"ç›¸ä¼¼åº¦: {item['similarity']:.2%}")
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸ä¼¼åº¦è¶…è¿‡70%çš„æ ·æœ¬")


# ==================== è¾…åŠ©å‡½æ•° ====================

def analyze_batch_consistency(results):
    """åˆ†ææ‰¹é‡ç»“æœçš„è¯„ä¼°ä¸€è‡´æ€§"""
    consistent_count = 0
    abc_scores = []
    dsm5_scores = []
    
    for record in results:
        abc_severe = record['abc_evaluation']['total_score'] >= 67
        dsm5_severe = record['dsm5_evaluation']['core_symptom_average'] >= 3.5
        
        if abc_severe == dsm5_severe:
            consistent_count += 1
        
        # æ ‡å‡†åŒ–åˆ†æ•°ä»¥ä¾¿è®¡ç®—ç›¸å…³æ€§
        abc_normalized = record['abc_evaluation']['total_score'] / 158  # ABCæœ€é«˜åˆ†158
        dsm5_normalized = record['dsm5_evaluation']['core_symptom_average'] / 5  # DSM-5æœ€é«˜5åˆ†
        
        abc_scores.append(abc_normalized)
        dsm5_scores.append(dsm5_normalized)
    
    # è®¡ç®—ç›¸å…³ç³»æ•°
    if len(results) > 1:
        correlation = np.corrcoef(abc_scores, dsm5_scores)[0, 1]
    else:
        correlation = 0
    
    return {
        'consistency_rate': (consistent_count / len(results)) * 100 if results else 0,
        'correlation': correlation,
        'abc_scores': abc_scores,
        'dsm5_scores': dsm5_scores
    }


def create_severity_comparison_df(results):
    """åˆ›å»ºä¸¥é‡ç¨‹åº¦å¯¹æ¯”æ•°æ®æ¡†"""
    comparison_data = []
    
    # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
    severity_groups = {}
    for record in results:
        severity = record.get('template', 'è‡ªå®šä¹‰')
        if severity not in severity_groups:
            severity_groups[severity] = {
                'abc_scores': [],
                'dsm5_scores': []
            }
        
        severity_groups[severity]['abc_scores'].append(record['abc_evaluation']['total_score'])
        severity_groups[severity]['dsm5_scores'].append(record['dsm5_evaluation']['core_symptom_average'])
    
    # è®¡ç®—æ¯ç»„çš„ç»Ÿè®¡æ•°æ®
    for severity, data in severity_groups.items():
        comparison_data.append({
            'ä¸¥é‡ç¨‹åº¦': severity,
            'æ ·æœ¬æ•°': len(data['abc_scores']),
            'ABCå¹³å‡åˆ†': f"{np.mean(data['abc_scores']):.1f}",
            'ABCæ ‡å‡†å·®': f"{np.std(data['abc_scores']):.1f}",
            'DSM5å¹³å‡åˆ†': f"{np.mean(data['dsm5_scores']):.2f}",
            'DSM5æ ‡å‡†å·®': f"{np.std(data['dsm5_scores']):.2f}"
        })
    
    return pd.DataFrame(comparison_data)


def create_assessment_comparison_plot(results):
    """åˆ›å»ºè¯„ä¼°å¯¹æ¯”å¯è§†åŒ–"""
    # å‡†å¤‡æ•°æ®
    data = []
    for record in results:
        data.append({
            'ä¸¥é‡ç¨‹åº¦': record.get('template', 'è‡ªå®šä¹‰'),
            'ABCæ€»åˆ†': record['abc_evaluation']['total_score'],
            'DSM-5æ ¸å¿ƒç—‡çŠ¶': record['dsm5_evaluation']['core_symptom_average'] * 30  # ç¼©æ”¾åˆ°ç›¸ä¼¼èŒƒå›´
        })
    
    df = pd.DataFrame(data)
    
    # åˆ›å»ºåˆ†ç»„æ¡å½¢å›¾
    fig = px.bar(
        df.groupby('ä¸¥é‡ç¨‹åº¦').mean().reset_index(),
        x='ä¸¥é‡ç¨‹åº¦',
        y=['ABCæ€»åˆ†', 'DSM-5æ ¸å¿ƒç—‡çŠ¶'],
        title='ä¸åŒä¸¥é‡ç¨‹åº¦çš„ABCä¸DSM-5è¯„åˆ†å¯¹æ¯”',
        labels={'value': 'è¯„åˆ†', 'variable': 'è¯„ä¼°æ ‡å‡†'},
        barmode='group'
    )
    
    return fig


def display_abc_detailed_results(abc_eval):
    """æ˜¾ç¤ºABCè¯„ä¼°è¯¦ç»†ç»“æœ"""
    st.write(f"### ABCæ€»åˆ†: {abc_eval['total_score']}")
    st.write(f"### ä¸¥é‡ç¨‹åº¦: {abc_eval['severity']}")
    
    # å„é¢†åŸŸå¾—åˆ†é›·è¾¾å›¾
    domain_scores = abc_eval['domain_scores']
    domain_names = list(domain_scores.keys())
    domain_values = list(domain_scores.values())
    domain_max_values = [ABC_EVALUATION_METRICS[d]['max_score'] for d in domain_names]
    domain_percentages = [v/m*100 for v, m in zip(domain_values, domain_max_values)]
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=domain_percentages,
        theta=[d.replace("å¾—åˆ†", "") for d in domain_names],
        fill='toself',
        name='å¾—åˆ†ç™¾åˆ†æ¯”'
    ))
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )),
        showlegend=False,
        title="ABCå„é¢†åŸŸå¾—åˆ†ç™¾åˆ†æ¯”"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # è¯†åˆ«åˆ°çš„è¡Œä¸º
    if abc_eval['identified_behaviors']:
        st.write("### è¯†åˆ«åˆ°çš„è¡Œä¸º")
        for domain, behaviors in abc_eval['identified_behaviors'].items():
            if behaviors:
                st.write(f"**{domain}**:")
                for behavior in behaviors:
                    st.write(f"â€¢ {behavior}")


def display_dsm5_detailed_results(dsm5_eval):
    """æ˜¾ç¤ºDSM-5è¯„ä¼°è¯¦ç»†ç»“æœ"""
    st.write(f"### æ ¸å¿ƒç—‡çŠ¶å¹³å‡åˆ†: {dsm5_eval['core_symptom_average']:.2f}/5")
    
    # å„ç»´åº¦è¯„åˆ†æ¡å½¢å›¾
    scores = dsm5_eval['scores']
    
    fig = go.Figure()
    fig.add_trace(go.Bar(
        x=list(scores.keys()),
        y=list(scores.values()),
        marker_color=['red' if v >= 4 else 'orange' if v >= 3 else 'green' for v in scores.values()]
    ))
    fig.update_layout(
        title="DSM-5å„ç»´åº¦è¯„åˆ†",
        yaxis_range=[0, 5],
        yaxis_title="ä¸¥é‡ç¨‹åº¦ (1-5åˆ†)"
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ä¸´åºŠè§‚å¯Ÿ
    if dsm5_eval['clinical_observations']:
        st.write("### ä¸´åºŠè§‚å¯Ÿè¦ç‚¹")
        for category, observations in dsm5_eval['clinical_observations'].items():
            if observations:
                st.write(f"**{category}**:")
                for obs in observations:
                    st.write(f"â€¢ {obs}")


def display_assessment_comparison(record):
    """æ˜¾ç¤ºå•ä¸ªè®°å½•çš„è¯„ä¼°å¯¹æ¯”"""
    abc_eval = record['abc_evaluation']
    dsm5_eval = record['dsm5_evaluation']
    
    # ä¸¥é‡ç¨‹åº¦å¯¹æ¯”
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ABCæ€»åˆ†", abc_eval['total_score'])
        st.write(f"åˆ¤å®š: {abc_eval['severity']}")
    
    with col2:
        st.metric("DSM-5æ ¸å¿ƒç—‡çŠ¶", f"{dsm5_eval['core_symptom_average']:.2f}")
        severity_label = "é‡åº¦" if dsm5_eval['core_symptom_average'] >= 3.5 else "ä¸­åº¦" if dsm5_eval['core_symptom_average'] >= 2.5 else "è½»åº¦"
        st.write(f"åˆ¤å®š: {severity_label}")
    
    # ä¸€è‡´æ€§åˆ¤æ–­
    abc_severe = abc_eval['total_score'] >= 67
    dsm5_severe = dsm5_eval['core_symptom_average'] >= 3.5
    
    if abc_severe == dsm5_severe:
        st.success("âœ… ä¸¤ç§è¯„ä¼°æ ‡å‡†çš„ä¸¥é‡ç¨‹åº¦åˆ¤æ–­ä¸€è‡´")
    else:
        st.warning("âš ï¸ ä¸¤ç§è¯„ä¼°æ ‡å‡†çš„ä¸¥é‡ç¨‹åº¦åˆ¤æ–­å­˜åœ¨å·®å¼‚")
    
    # è¯¦ç»†å¯¹æ¯”
    st.write("### è¯„ä¼°ç‰¹ç‚¹å¯¹æ¯”")
    
    comparison_text = []
    
    # ABCç‰¹ç‚¹
    if 'identified_behaviors' in abc_eval:
        total_behaviors = sum(len(behaviors) for behaviors in abc_eval['identified_behaviors'].values())
        comparison_text.append(f"â€¢ ABCè¯†åˆ«äº† {total_behaviors} ä¸ªå…·ä½“è¡Œä¸º")
    
    # DSM-5ç‰¹ç‚¹
    if 'clinical_observations' in dsm5_eval:
        total_observations = sum(len(obs) for obs in dsm5_eval['clinical_observations'].values())
        comparison_text.append(f"â€¢ DSM-5è®°å½•äº† {total_observations} ç±»ä¸´åºŠè§‚å¯Ÿ")
    
    # ä¸»è¦å·®å¼‚
    if abc_eval['domain_scores'].get('è¯­è¨€é¢†åŸŸå¾—åˆ†', 0) > 30 and dsm5_eval['scores'].get('æ²Ÿé€šäº¤æµèƒ½åŠ›', 0) < 3:
        comparison_text.append("â€¢ ABCæ˜¾ç¤ºè¯­è¨€é—®é¢˜ä¸¥é‡ï¼Œä½†DSM-5è¯„ä¼°ç›¸å¯¹è¾ƒè½»")
    
    if abc_eval['domain_scores'].get('äº¤å¾€é¢†åŸŸå¾—åˆ†', 0) > 30 and dsm5_eval['scores'].get('ç¤¾äº¤äº’åŠ¨è´¨é‡', 0) < 3:
        comparison_text.append("â€¢ ABCæ˜¾ç¤ºç¤¾äº¤éšœç¢ä¸¥é‡ï¼Œä½†DSM-5è¯„ä¼°ç›¸å¯¹è¾ƒè½»")
    
    for text in comparison_text:
        st.write(text)


def create_correlation_scatter(records):
    """åˆ›å»ºABCä¸DSM-5ç›¸å…³æ€§æ•£ç‚¹å›¾"""
    abc_scores = []
    dsm5_scores = []
    severities = []
    
    for record in records:
        abc_scores.append(record['abc_evaluation']['total_score'])
        dsm5_scores.append(record['dsm5_evaluation']['core_symptom_average'])
        severities.append(record.get('template', 'è‡ªå®šä¹‰'))
    
    df = pd.DataFrame({
        'ABCæ€»åˆ†': abc_scores,
        'DSM-5æ ¸å¿ƒç—‡çŠ¶': dsm5_scores,
        'ä¸¥é‡ç¨‹åº¦': severities
    })
    
    fig = px.scatter(
        df,
        x='ABCæ€»åˆ†',
        y='DSM-5æ ¸å¿ƒç—‡çŠ¶',
        color='ä¸¥é‡ç¨‹åº¦',
        title='ABCæ€»åˆ†ä¸DSM-5æ ¸å¿ƒç—‡çŠ¶ç›¸å…³æ€§',
        labels={'ABCæ€»åˆ†': 'ABCæ€»åˆ†', 'DSM-5æ ¸å¿ƒç—‡çŠ¶': 'DSM-5æ ¸å¿ƒç—‡çŠ¶å‡åˆ†'},
        trendline="ols"
    )
    
    # æ·»åŠ è¯Šæ–­é˜ˆå€¼çº¿
    fig.add_hline(y=3.5, line_dash="dash", line_color="red", annotation_text="DSM-5é‡åº¦é˜ˆå€¼")
    fig.add_vline(x=67, line_dash="dash", line_color="red", annotation_text="ABCå­¤ç‹¬ç—‡é˜ˆå€¼")
    
    return fig


def display_abc_analysis(records, analysis):
    """æ˜¾ç¤ºABCé‡è¡¨åˆ†æç»“æœ"""
    st.write("### ğŸ“Š ABCé‡è¡¨è¯„ä¼°åˆ†æ")
    
    # ABCæ€»åˆ†åˆ†å¸ƒ
    abc_scores = [r['abc_evaluation']['total_score'] for r in records]
    
    fig_hist = px.histogram(
        x=abc_scores,
        nbins=20,
        title="ABCæ€»åˆ†åˆ†å¸ƒ",
        labels={'x': 'ABCæ€»åˆ†', 'y': 'é¢‘æ¬¡'}
    )
    fig_hist.add_vline(x=67, line_dash="dash", line_color="red", annotation_text="å­¤ç‹¬ç—‡é˜ˆå€¼")
    fig_hist.add_vline(x=53, line_dash="dash", line_color="orange", annotation_text="è½»åº¦é˜ˆå€¼")
    st.plotly_chart(fig_hist, use_container_width=True)
    
    # å„é¢†åŸŸå¾—åˆ†åˆ†æ
    domain_data = {domain: [] for domain in ABC_EVALUATION_METRICS.keys()}
    for record in records:
        for domain, score in record['abc_evaluation']['domain_scores'].items():
            domain_data[domain].append(score)
    
    # ç®±çº¿å›¾
    fig_box = go.Figure()
    for domain, scores in domain_data.items():
        fig_box.add_trace(go.Box(
            y=scores,
            name=domain.replace("å¾—åˆ†", ""),
            boxpoints='all',
            jitter=0.3,
            pointpos=-1.8
        ))
    fig_box.update_layout(
        title="ABCå„é¢†åŸŸå¾—åˆ†åˆ†å¸ƒ",
        yaxis_title="å¾—åˆ†"
    )
    st.plotly_chart(fig_box, use_container_width=True)
    
    # é«˜é¢‘è¡Œä¸ºåˆ†æ
    if st.checkbox("æŸ¥çœ‹é«˜é¢‘è¡Œä¸ºåˆ†æ"):
        behavior_stats = get_behavior_summary_stats(records)
        if behavior_stats['total_records'] > 0:
            st.write(f"**æ€»è¯„ä¼°è®°å½•**: {behavior_stats['total_records']}")
            st.write(f"**è¯†åˆ«çš„è¡Œä¸ºç§ç±»**: {behavior_stats['unique_behaviors_count']}")
            
            if behavior_stats['most_common']:
                st.write("**æœ€å¸¸è§çš„è¡Œä¸º**:")
                for behavior, stats in behavior_stats['most_common'][:10]:
                    st.write(f"â€¢ {behavior}: {stats['count']}æ¬¡ ({stats['percentage']:.1f}%)")


def display_dsm5_analysis(records, analysis):
    """æ˜¾ç¤ºDSM-5æ ‡å‡†åˆ†æç»“æœ"""
    st.write("### ğŸ§  DSM-5æ ‡å‡†è¯„ä¼°åˆ†æ")
    
    # æ ¸å¿ƒç—‡çŠ¶åˆ†å¸ƒ
    core_scores = [r['dsm5_evaluation']['core_symptom_average'] for r in records]
    
    fig_hist = px.histogram(
        x=core_scores,
        nbins=20,
        title="DSM-5æ ¸å¿ƒç—‡çŠ¶åˆ†å¸ƒ",
        labels={'x': 'æ ¸å¿ƒç—‡çŠ¶å‡åˆ†', 'y': 'é¢‘æ¬¡'}
    )
    fig_hist.add_vline(x=3.5, line_dash="dash", line_color="red", annotation_text="é‡åº¦é˜ˆå€¼")
    fig_hist.add_vline(x=2.5, line_dash="dash", line_color="orange", annotation_text="ä¸­åº¦é˜ˆå€¼")
    st.plotly_chart(fig_hist, use_container_width=True)
    
    # å„ç»´åº¦é›·è¾¾å›¾
    avg_scores = {}
    for metric in DSM5_EVALUATION_METRICS.keys():
        scores = [r['dsm5_evaluation']['scores'][metric] for r in records]
        avg_scores[metric] = np.mean(scores)
    
    fig_radar = go.Figure()
    fig_radar.add_trace(go.Scatterpolar(
        r=list(avg_scores.values()),
        theta=list(avg_scores.keys()),
        fill='toself',
        name='å¹³å‡ä¸¥é‡ç¨‹åº¦'
    ))
    fig_radar.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[1, 5]
            )),
        showlegend=False,
        title="DSM-5å„ç»´åº¦å¹³å‡è¯„åˆ†"
    )
    st.plotly_chart(fig_radar, use_container_width=True)


def display_comprehensive_comparison(records, analysis):
    """æ˜¾ç¤ºç»¼åˆå¯¹æ¯”åˆ†æ"""
    st.write("### ğŸ”„ ABCä¸DSM-5ç»¼åˆå¯¹æ¯”")
    
    # å‡†å¤‡å¯¹æ¯”æ•°æ®
    comparison_data = []
    for record in records:
        comparison_data.append({
            'è¯„ä¼°ID': record['experiment_id'][:20] + '...',
            'ABCæ€»åˆ†': record['abc_evaluation']['total_score'],
            'ABCåˆ¤å®š': record['abc_evaluation']['severity'],
            'DSM5æ ¸å¿ƒ': f"{record['dsm5_evaluation']['core_symptom_average']:.2f}",
            'ä¸€è‡´æ€§': 'âœ…' if (record['abc_evaluation']['total_score'] >= 67) == (record['dsm5_evaluation']['core_symptom_average'] >= 3.5) else 'âŒ'
        })
    
    df_comp = pd.DataFrame(comparison_data[:20])  # æ˜¾ç¤ºå‰20æ¡
    st.dataframe(df_comp, use_container_width=True)
    
    if len(records) > 20:
        st.info(f"æ˜¾ç¤ºå‰20æ¡è®°å½•ï¼Œå…±{len(records)}æ¡")
    
    # ä¸€è‡´æ€§ç»Ÿè®¡
    consistent = sum(1 for d in comparison_data if d['ä¸€è‡´æ€§'] == 'âœ…')
    inconsistent = len(comparison_data) - consistent
    
    fig_pie = px.pie(
        values=[consistent, inconsistent],
        names=['ä¸€è‡´', 'ä¸ä¸€è‡´'],
        title='ABCä¸DSM-5è¯„ä¼°ä¸€è‡´æ€§',
        color_discrete_map={'ä¸€è‡´': 'green', 'ä¸ä¸€è‡´': 'red'}
    )
    st.plotly_chart(fig_pie, use_container_width=True)


def display_statistical_analysis(records):
    """æ˜¾ç¤ºç»Ÿè®¡å­¦åˆ†æ"""
    try:
        # å‡†å¤‡æ•°æ®
        severity_groups = {}
        for record in records:
            severity = record.get('template', 'è‡ªå®šä¹‰')
            if severity not in severity_groups:
                severity_groups[severity] = {
                    'abc_scores': [],
                    'dsm5_scores': []
                }
            severity_groups[severity]['abc_scores'].append(record['abc_evaluation']['total_score'])
            severity_groups[severity]['dsm5_scores'].append(record['dsm5_evaluation']['core_symptom_average'])
        
        if len(severity_groups) >= 2:
            # ABCæ–¹å·®åˆ†æ
            abc_groups = [scores['abc_scores'] for scores in severity_groups.values() if len(scores['abc_scores']) > 0]
            if len(abc_groups) >= 2:
                f_stat_abc, p_value_abc = stats.f_oneway(*abc_groups)
                
                st.write("**ABCæ€»åˆ†çš„å•å› ç´ æ–¹å·®åˆ†æ**:")
                st.write(f"- Fç»Ÿè®¡é‡: {f_stat_abc:.3f}")
                st.write(f"- på€¼: {p_value_abc:.4f}")
                
                if p_value_abc < 0.05:
                    st.success("âœ… ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´ABCæ€»åˆ†å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ (p < 0.05)")
                else:
                    st.info("â„¹ï¸ ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´ABCæ€»åˆ†å·®å¼‚æ— ç»Ÿè®¡å­¦æ„ä¹‰ (p â‰¥ 0.05)")
            
            # DSM-5æ–¹å·®åˆ†æ
            dsm5_groups = [scores['dsm5_scores'] for scores in severity_groups.values() if len(scores['dsm5_scores']) > 0]
            if len(dsm5_groups) >= 2:
                f_stat_dsm5, p_value_dsm5 = stats.f_oneway(*dsm5_groups)
                
                st.write("\n**DSM-5æ ¸å¿ƒç—‡çŠ¶çš„å•å› ç´ æ–¹å·®åˆ†æ**:")
                st.write(f"- Fç»Ÿè®¡é‡: {f_stat_dsm5:.3f}")
                st.write(f"- på€¼: {p_value_dsm5:.4f}")
                
                if p_value_dsm5 < 0.05:
                    st.success("âœ… ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´DSM-5æ ¸å¿ƒç—‡çŠ¶å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰ (p < 0.05)")
                else:
                    st.info("â„¹ï¸ ä¸åŒä¸¥é‡ç¨‹åº¦ç»„é—´DSM-5æ ¸å¿ƒç—‡çŠ¶å·®å¼‚æ— ç»Ÿè®¡å­¦æ„ä¹‰ (p â‰¥ 0.05)")
                
    except ImportError:
        st.info("ğŸ’¡ å®‰è£…scipyæ¨¡å—å¯å¯ç”¨ç»Ÿè®¡å­¦åˆ†æåŠŸèƒ½")


def display_single_record_analysis(record):
    """æ˜¾ç¤ºå•ä¸ªè®°å½•çš„è¯¦ç»†åˆ†æ"""
    st.write("### ğŸ“Š è¯¦ç»†è¯„ä¼°åˆ†æ")
    
    # åˆ›å»ºä¸¤åˆ—
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ABCé‡è¡¨åˆ†æ**")
        # é¥¼å›¾æ˜¾ç¤ºå„é¢†åŸŸè´¡çŒ®
        domain_scores = record['abc_evaluation']['domain_scores']
        fig = px.pie(
            values=list(domain_scores.values()),
            names=[d.replace("å¾—åˆ†", "") for d in domain_scores.keys()],
            title="ABCå„é¢†åŸŸå¾—åˆ†å æ¯”"
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.write("**DSM-5æ ‡å‡†åˆ†æ**")
        # é›·è¾¾å›¾æ˜¾ç¤ºå„ç»´åº¦
        scores = record['dsm5_evaluation']['scores']
        fig = go.Figure()
        fig.add_trace(go.Scatterpolar(
            r=list(scores.values()),
            theta=list(scores.keys()),
            fill='toself'
        ))
        fig.update_layout(
            polar=dict(radialaxis=dict(visible=True, range=[1, 5])),
            title="DSM-5å„ç»´åº¦è¯„åˆ†"
        )
        st.plotly_chart(fig, use_container_width=True)