"""å­¤ç‹¬ç—‡å¹³å°æŠ¥å‘Šä¸­å¿ƒé¡µé¢"""
import streamlit as st
import pandas as pd
import datetime
import json

from common.config import EXCEL_AVAILABLE
from common.exporters import (
    export_to_csv, export_to_json, export_to_excel, 
    create_excel_workbook, apply_excel_styles, create_zip_package
)
from common.exporters.text_exporter import export_to_text
from .analyzer import generate_clinical_analysis, prepare_clinical_export_data


def page_report_center():
    """ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒé¡µé¢"""
    st.header("ğŸ“Š ä¸´åºŠæŠ¥å‘Šä¸­å¿ƒ")
    st.markdown("åŸºäºå¾ªè¯å®è·µç”Ÿæˆä¸“ä¸šçš„ä¸´åºŠè¯„ä¼°æŠ¥å‘Šå’Œç ”ç©¶æ•°æ®")
    
    records = st.session_state.experiment_records
    
    if not records:
        st.warning("ğŸ“Š æš‚æ— è¯„ä¼°æ•°æ®ï¼Œè¯·å…ˆè¿›è¡Œä¸´åºŠè¯„ä¼°")
        st.stop()
    
    st.success(f"ğŸ“Š å½“å‰å…±æœ‰ {len(records)} æ¡ä¸´åºŠè¯„ä¼°è®°å½•å¯ç”ŸæˆæŠ¥å‘Š")
    
    # åˆ›å»ºä¸¤ä¸ªæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“Š ç”ŸæˆæŠ¥å‘Š", "ğŸ“¥ å¯¼å…¥æ•°æ®"])

    with tab1:
        # æŠ¥å‘Šç±»å‹é€‰æ‹©
        st.subheader("ğŸ“‹ é€‰æ‹©æŠ¥å‘Šç±»å‹")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("### ğŸ“„ æ ‡å‡†ä¸´åºŠæŠ¥å‘Š")
            
            # åŸºç¡€CSVæŠ¥å‘Š
            if st.button("ğŸ“Š ä¸‹è½½åŸºç¡€è¯„ä¼°æ•°æ® (CSV)", use_container_width=True):
                export_data = prepare_clinical_export_data(records)
                csv_content = export_to_csv(export_data)
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ä¸´åºŠè¯„ä¼°æ•°æ®",
                    data=csv_content,
                    file_name=f"autism_clinical_assessment_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime='text/csv'
                )
            
            # å¯¹è¯è®°å½•ä¸‹è½½
            if st.button("ğŸ’¬ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½• (TXT)", use_container_width=True):
                observation_content = create_observation_text(records)
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½è¡Œä¸ºè§‚å¯Ÿè®°å½•",
                    data=export_to_text(observation_content),
                    file_name=f"autism_clinical_observations_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime='text/plain'
                )
            
            # JSONå®Œæ•´æ•°æ®
            if st.button("ğŸ”§ ä¸‹è½½å®Œæ•´ä¸´åºŠæ•°æ® (JSON)", use_container_width=True):
                json_data = create_complete_json_data(records)
                json_str = export_to_json(json_data)
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ä¸´åºŠæ•°æ®",
                    data=json_str.encode('utf-8'),
                    file_name=f"autism_clinical_complete_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime='application/json'
                )
        
        with col2:
            st.write("### ğŸ“ˆ ä¸“ä¸šåˆ†ææŠ¥å‘Š")
            
            # ç”Ÿæˆä¸´åºŠåˆ†ææŠ¥å‘Š
            if st.button("ğŸ“Š ç”Ÿæˆä¸´åºŠç»Ÿè®¡åˆ†æ", use_container_width=True):
                with st.spinner("æ­£åœ¨ç”Ÿæˆä¸´åºŠåˆ†ææŠ¥å‘Š..."):
                    analysis = generate_clinical_analysis(records)
                
                st.success("âœ… ä¸´åºŠåˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                
                # æ˜¾ç¤ºåˆ†æé¢„è§ˆ
                with st.expander("ğŸ“‹ ä¸´åºŠåˆ†ææŠ¥å‘Šé¢„è§ˆ", expanded=True):
                    if analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ'):
                        st.write("**ä¸´åºŠè¯„ä¼°æ¦‚å†µ:**")
                        for key, value in analysis['ä¸´åºŠè¯„ä¼°æ¦‚å†µ'].items():
                            st.write(f"- {key}: {value}")
                    
                    if analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°'):
                        st.write("**æ•´ä½“ä¸´åºŠè¡¨ç°:**")
                        for key, value in analysis['æ•´ä½“ä¸´åºŠè¡¨ç°'].items():
                            st.write(f"- {key}: {value}")
                    
                    if analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®'):
                        st.write("**ä¸´åºŠå‘ç°ä¸å»ºè®®:**")
                        for finding in analysis['ä¸´åºŠå‘ç°ä¸å»ºè®®']:
                            st.write(f"- {finding}")
                
                # æä¾›åˆ†ææŠ¥å‘Šä¸‹è½½
                analysis_json = export_to_json(analysis)
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ä¸´åºŠåˆ†ææŠ¥å‘Š (JSON)",
                    data=analysis_json.encode('utf-8'),
                    file_name=f"autism_clinical_analysis_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                    mime='application/json'
                )
            
            # Excelä¸“ä¸šæŠ¥å‘Š
            if EXCEL_AVAILABLE:
                if st.button("ğŸ“‹ ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆä¸“ä¸šExcelæŠ¥å‘Š..."):
                        analysis = generate_clinical_analysis(records)
                        excel_data = create_clinical_excel_report(records, analysis)
                    
                    if excel_data:
                        st.success("âœ… ä¸“ä¸šExcelæŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                        
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½ä¸“ä¸šExcelæŠ¥å‘Š",
                            data=excel_data,
                            file_name=f"autism_clinical_professional_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                            mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                        )
                    else:
                        st.error("âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–æ ¼å¼")
            else:
                st.info("ğŸ’¡ ExcelæŠ¥å‘ŠåŠŸèƒ½éœ€è¦å®‰è£…openpyxlæ¨¡å—")
                st.code("pip install openpyxl")
                
                # æ›¿ä»£è¯¦ç»†æŠ¥å‘Š
                if st.button("ğŸ“Š ç”Ÿæˆè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š", use_container_width=True):
                    with st.spinner("æ­£åœ¨ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š..."):
                        analysis = generate_clinical_analysis(records)
                    
                    # åˆ›å»ºè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š
                    detailed_report = create_detailed_text_report(records, analysis)
                    
                    st.success("âœ… è¯¦ç»†æ–‡æœ¬æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                    
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½è¯¦ç»†æ–‡æœ¬æŠ¥å‘Š",
                        data=export_to_text(detailed_report),
                        file_name=f"autism_clinical_detailed_report_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime='text/plain'
                    )
            
            # ç ”ç©¶æ•°æ®åŒ…
            if st.button("ğŸ“¦ ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…", use_container_width=True, type="primary"):
                with st.spinner("æ­£åœ¨ç”Ÿæˆå®Œæ•´ç ”ç©¶æ•°æ®åŒ…..."):
                    zip_data = create_research_package(records)
                
                st.success("âœ… å®Œæ•´ç ”ç©¶æ•°æ®åŒ…ç”Ÿæˆå®Œæˆï¼")
                
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½å®Œæ•´ç ”ç©¶æ•°æ®åŒ… (ZIP)",
                    data=zip_data,
                    file_name=f"autism_clinical_research_package_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.zip",
                    mime='application/zip'
                )
        
        # æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ
        display_data_overview(records)
        
        # æ•°æ®é¢„è§ˆ
        display_data_preview(records)

    with tab2:
        # æ·»åŠ ç®€åŒ–çš„å¯¼å…¥åŠŸèƒ½
        st.subheader("ğŸ“¥ å¿«é€Ÿå¯¼å…¥å†å²æ•°æ®")
        st.markdown("ä»æ–‡ä»¶å¯¼å…¥å†å²å„¿ç«¥å‘å±•è§‚å¯Ÿæ•°æ®åˆ°ç³»ç»Ÿä¸­")
        
        uploaded_file = st.file_uploader(
            "é€‰æ‹©è¦å¯¼å…¥çš„æ–‡ä»¶",
            type=['csv', 'json', 'xlsx', 'xls', 'zip'],
            help="æ”¯æŒä»å¯¼å‡ºçš„æŠ¥å‘Šæ–‡ä»¶é‡æ–°å¯¼å…¥æ•°æ®"
        )
        
        if uploaded_file is not None:
            col1, col2 = st.columns([3, 1])
            
            with col1:
                st.info(f"ğŸ“„ å·²é€‰æ‹©æ–‡ä»¶: {uploaded_file.name} ({uploaded_file.size // 1024} KB)")
            
            with col2:
                if st.button("ğŸš€ å¯¼å…¥", type="primary"):
                    try:
                        from common.importers import get_importer
                        from common.data_storage_manager import DataStorageManager
                        
                        # è·å–å¯¼å…¥å™¨
                        file_ext = uploaded_file.name.split('.')[-1].lower()
                        importer_class = get_importer(file_ext)
                        importer = importer_class(assessment_type='children')
                        
                        # å¯¼å…¥æ•°æ®
                        with st.spinner("æ­£åœ¨å¯¼å…¥æ•°æ®..."):
                            file_content = uploaded_file.read()
                            result = importer.import_data(file_content)
                            
                            if result.status.value == 'success':
                                # åˆå¹¶æ•°æ®
                                storage_manager = DataStorageManager('children')
                                merged_count, _ = storage_manager.merge_imported_data(
                                    result.records, 
                                    merge_strategy='skip_duplicates'
                                )
                                
                                st.success(f"âœ… æˆåŠŸå¯¼å…¥ {merged_count} æ¡è§‚å¯Ÿè®°å½•")
                                st.rerun()
                            else:
                                st.error(f"å¯¼å…¥å¤±è´¥: {result.errors[0]['message'] if result.errors else 'æœªçŸ¥é”™è¯¯'}")
                                
                    except Exception as e:
                        st.error(f"å¯¼å…¥å‡ºé”™: {str(e)}")
        
        # å¯¼å…¥è¯´æ˜
        with st.expander("â„¹ï¸ å¯¼å…¥è¯´æ˜"):
            st.markdown("""
            - æ”¯æŒå¯¼å…¥ä¹‹å‰å¯¼å‡ºçš„æ‰€æœ‰æ ¼å¼æ–‡ä»¶
            - CSV/Excelæ–‡ä»¶ä¼šè‡ªåŠ¨è¯†åˆ«æ•°æ®æ ¼å¼
            - JSONæ–‡ä»¶ä¿ç•™å®Œæ•´çš„å‘å±•è§‚å¯Ÿæ•°æ®ç»“æ„
            - ZIPåŒ…å¯ä»¥åŒ…å«å¤šä¸ªæ–‡ä»¶æ‰¹é‡å¯¼å…¥
            - ç³»ç»Ÿä¼šè‡ªåŠ¨è·³è¿‡é‡å¤çš„è®°å½•
            
            **æç¤º**: å¦‚éœ€æ›´å¤šå¯¼å…¥é€‰é¡¹ï¼Œè¯·è®¿é—®"æ•°æ®å¯¼å…¥"é¡µé¢
            """)
        
        # æ·»åŠ è·³è½¬åˆ°å®Œæ•´å¯¼å…¥é¡µé¢çš„é“¾æ¥
        st.markdown("---")
        if st.button("ğŸ”§ å‰å¾€å®Œæ•´æ•°æ®å¯¼å…¥é¡µé¢"):
            st.switch_page("pages/data_import_page.py")



def create_observation_text(records):
    """åˆ›å»ºè§‚å¯Ÿè®°å½•æ–‡æœ¬"""
    observation_content = []
    observation_content.append("=" * 70)
    observation_content.append("å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¡Œä¸ºè§‚å¯Ÿè®°å½•")
    observation_content.append("åŸºäºDSM-5è¯Šæ–­æ ‡å‡† | å¾ªè¯è¯„ä¼°å·¥å…·")
    observation_content.append("=" * 70)
    observation_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    observation_content.append(f"è¯„ä¼°è®°å½•æ€»æ•°: {len(records)}")
    observation_content.append("=" * 70)
    observation_content.append("")
    
    for i, record in enumerate(records, 1):
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                       record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                       record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        observation_content.append(f"\nã€ä¸´åºŠè¯„ä¼° {i}ã€‘")
        observation_content.append(f"è¯„ä¼°ID: {record['experiment_id']}")
        observation_content.append(f"è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
        observation_content.append(f"ä¸¥é‡ç¨‹åº¦åˆ†çº§: {record.get('template', 'è‡ªå®šä¹‰')}")
        observation_content.append(f"è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
        observation_content.append(f"è§‚å¯Ÿæ´»åŠ¨: {record.get('activity', 'æœªæŒ‡å®š')}")
        observation_content.append(f"è§¦å‘å› ç´ : {record.get('trigger', 'æœªæŒ‡å®š')}")
        
        if record.get('autism_profile'):
            profile = record['autism_profile']
            observation_content.append(f"DSM-5ä¸¥é‡ç¨‹åº¦: {profile.get('dsm5_severity', '')}")
            observation_content.append(f"æ‰€éœ€æ”¯æŒæ°´å¹³: {profile.get('support_needs', '')}")
        
        observation_content.append(f"æ ¸å¿ƒç—‡çŠ¶ç»¼åˆä¸¥é‡åº¦: {core_severity:.2f}/5.0")
        observation_content.append("-" * 50)
        
        observation_content.append("ä¸´åºŠè¯„ä¼°å¾—åˆ†:")
        for metric, score in record['evaluation_scores'].items():
            observation_content.append(f"  â€¢ {metric}: {score}/5.0")
        
        if 'clinical_observations' in record and record['clinical_observations']:
            observation_content.append("ä¸´åºŠè§‚å¯Ÿè¦ç‚¹:")
            for category, observations in record['clinical_observations'].items():
                if observations:
                    observation_content.append(f"  {category}: {', '.join(observations)}")
        
        observation_content.append("è¡Œä¸ºè§‚å¯Ÿå¯¹è¯:")
        observation_content.append(record['dialogue'])
        observation_content.append("-" * 50)
        observation_content.append("")
    
    return observation_content


def create_complete_json_data(records):
    """åˆ›å»ºå®Œæ•´çš„JSONæ•°æ®"""
    analysis = generate_clinical_analysis(records)
    
    json_data = {
        'clinical_assessment_report': {
            'report_metadata': {
                'generation_time': datetime.datetime.now().isoformat(),
                'assessment_standard': 'DSM-5è¯Šæ–­æ ‡å‡†',
                'evaluation_tools': 'CARS, ABC, SCQ, M-CHATå‚è€ƒ',
                'total_assessments': len(records),
                'platform_version': 'åŒ»å­¦æ ‡å‡†ç‰ˆ v1.0'
            },
            'assessment_summary': analysis,
            'detailed_assessments': []
        }
    }
    
    for record in records:
        clinical_record = record.copy()
        clinical_record['timestamp'] = record['timestamp'].isoformat()
        
        # æ·»åŠ è®¡ç®—å­—æ®µ
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                       record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                       record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        clinical_record['core_symptom_severity'] = round(core_severity, 2)
        
        json_data['clinical_assessment_report']['detailed_assessments'].append(clinical_record)
    
    return json_data


def create_clinical_excel_report(records, analysis):
    """åˆ›å»ºä¸´åºŠæ ‡å‡†çš„ExcelæŠ¥å‘Š"""
    if not EXCEL_AVAILABLE:
        return None
    
    workbook = create_excel_workbook()
    
    # 1. ä¸´åºŠè¯„ä¼°æ¦‚è§ˆ
    overview_sheet = workbook.create_sheet("ä¸´åºŠè¯„ä¼°æ¦‚è§ˆ")
    overview_sheet.append(["å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¡Œä¸ºè¯„ä¼°æŠ¥å‘Šï¼ˆåŸºäºDSM-5æ ‡å‡†ï¼‰"])
    overview_sheet.append([])
    overview_sheet.append(["æŠ¥å‘Šç”Ÿæˆæ—¶é—´", datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')])
    overview_sheet.append(["è¯„ä¼°æ ‡å‡†", "DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡† + CARS/ABC/SCQé‡è¡¨"])
    overview_sheet.append([])
    
    overview_sheet.append(["è¯„ä¼°æ¦‚å†µ"])
    for key, value in analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["æ•´ä½“ä¸´åºŠè¡¨ç°"])
    for key, value in analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°', {}).items():
        overview_sheet.append([key, value])
    
    overview_sheet.append([])
    overview_sheet.append(["ä¸´åºŠå‘ç°ä¸å»ºè®®"])
    for finding in analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []):
        overview_sheet.append([finding])
    
    # 2. è¯¦ç»†è¯„ä¼°æ•°æ®
    data_sheet = workbook.create_sheet("è¯¦ç»†è¯„ä¼°æ•°æ®")
    headers = ["è¯„ä¼°ID", "æ—¶é—´", "ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "è§‚å¯Ÿæ´»åŠ¨", "è§¦å‘å› ç´ ",
              "ç¤¾äº¤äº’åŠ¨ç¼ºé™·", "æ²Ÿé€šäº¤æµç¼ºé™·", "åˆ»æ¿é‡å¤è¡Œä¸º", "æ„Ÿå®˜å¤„ç†å¼‚å¸¸", 
              "æƒ…ç»ªè°ƒèŠ‚å›°éš¾", "è®¤çŸ¥é€‚åº”ç¼ºé™·", "æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦",
              "DSM-5ä¸¥é‡ç¨‹åº¦", "æ‰€éœ€æ”¯æŒæ°´å¹³", "ç‰¹æ®Šå…´è¶£", "å¤‡æ³¨"]
    data_sheet.append(headers)
    
    for record in records:
        profile = record.get('autism_profile', {})
        scores = record['evaluation_scores']
        core_symptom_severity = (scores['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + scores['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + scores['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        row = [
            record['experiment_id'],
            record['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),
            record.get('template', 'è‡ªå®šä¹‰'),
            record['scene'],
            record.get('activity', ''),
            record.get('trigger', ''),
            scores['ç¤¾äº¤äº’åŠ¨è´¨é‡'],
            scores['æ²Ÿé€šäº¤æµèƒ½åŠ›'],
            scores['åˆ»æ¿é‡å¤è¡Œä¸º'],
            scores['æ„Ÿå®˜å¤„ç†èƒ½åŠ›'],
            scores['æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚'],
            scores['è®¤çŸ¥é€‚åº”åŠŸèƒ½'],
            f"{core_symptom_severity:.2f}",
            profile.get('dsm5_severity', ''),
            profile.get('support_needs', ''),
            profile.get('special_interests', ''),
            record.get('notes', '')
        ]
        data_sheet.append(row)
    
    # 3. ä¸¥é‡ç¨‹åº¦å¯¹æ¯”åˆ†æ
    if analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†æ'):
        severity_sheet = workbook.create_sheet("ä¸¥é‡ç¨‹åº¦åˆ†æ")
        severity_headers = ["ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æ¬¡æ•°", "ç¤¾äº¤ç¼ºé™·å‡å€¼", "æ²Ÿé€šç¼ºé™·å‡å€¼", 
                          "åˆ»æ¿è¡Œä¸ºå‡å€¼", "æ„Ÿå®˜å¼‚å¸¸å‡å€¼", "æƒ…ç»ªå›°éš¾å‡å€¼", "è®¤çŸ¥ç¼ºé™·å‡å€¼",
                          "æ ¸å¿ƒç—‡çŠ¶ç»¼åˆ"]
        severity_sheet.append(severity_headers)
        
        for severity, stats in analysis['ä¸¥é‡ç¨‹åº¦åˆ†æ'].items():
            core_avg = (stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼'] + stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼'] + stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']) / 3
            row = [
                severity,
                stats['è¯„ä¼°æ¬¡æ•°'],
                f"{stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æ„Ÿå®˜å¤„ç†å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['æƒ…ç»ªè°ƒèŠ‚å¾—åˆ†_å‡å€¼']:.2f}",
                f"{stats['è®¤çŸ¥é€‚åº”å¾—åˆ†_å‡å€¼']:.2f}",
                f"{core_avg:.2f}"
            ]
            severity_sheet.append(row)
    
    # 4. ä¸´åºŠè§‚å¯Ÿè®°å½•
    if any('clinical_observations' in record for record in records):
        obs_sheet = workbook.create_sheet("ä¸´åºŠè§‚å¯Ÿè®°å½•")
        obs_sheet.append(["è¯„ä¼°ID", "ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ", "è¯­è¨€æ²Ÿé€šç‰¹ç‚¹", "é‡å¤è¡Œä¸ºè¡¨ç°", "æ„Ÿå®˜ååº”", "æƒ…ç»ªè°ƒèŠ‚"])
        
        for record in records:
            if 'clinical_observations' in record:
                obs = record['clinical_observations']
                row = [
                    record['experiment_id'],
                    '; '.join(obs.get('ç¤¾äº¤è¡Œä¸ºè§‚å¯Ÿ', [])),
                    '; '.join(obs.get('è¯­è¨€æ²Ÿé€šç‰¹ç‚¹', [])),
                    '; '.join(obs.get('é‡å¤è¡Œä¸ºè¡¨ç°', [])),
                    '; '.join(obs.get('æ„Ÿå®˜ååº”', [])),
                    '; '.join(obs.get('æƒ…ç»ªè°ƒèŠ‚', []))
                ]
                obs_sheet.append(row)
    
    # 5. å¯¹è¯è®°å½•ï¼ˆç”¨äºè´¨æ€§åˆ†æï¼‰
    dialogue_sheet = workbook.create_sheet("å¯¹è¯è®°å½•")
    dialogue_sheet.append(["è¯„ä¼°ID", "ä¸¥é‡ç¨‹åº¦", "è¯„ä¼°æƒ…å¢ƒ", "å¯¹è¯å†…å®¹"])
    
    for record in records:
        dialogue_sheet.append([
            record['experiment_id'],
            record.get('template', 'è‡ªå®šä¹‰'),
            record['scene'],
            record['dialogue']
        ])
    
    # åº”ç”¨ä¸“ä¸šæ ·å¼
    apply_excel_styles(workbook, header_color="366092", header_font_color="FFFFFF")
    
    # ç‰¹æ®Šæ ·å¼å¤„ç†
    for sheet in workbook.worksheets:
        for row in sheet.iter_rows():
            for cell in row:
                if cell.value and any(keyword in str(cell.value) for keyword in ['ä¸¥é‡', 'æ˜æ˜¾', 'éœ€è¦æ”¯æŒ']):
                    from openpyxl.styles import PatternFill
                    cell.fill = PatternFill(start_color="FFE6E6", end_color="FFE6E6", fill_type="solid")
    
    return export_to_excel(workbook)


def create_detailed_text_report(records, analysis):
    """åˆ›å»ºè¯¦ç»†æ–‡æœ¬æŠ¥å‘Š"""
    detailed_report = []
    detailed_report.append("å­¤ç‹¬ç—‡å„¿ç«¥ä¸´åºŠè¯„ä¼°è¯¦ç»†æŠ¥å‘Š")
    detailed_report.append("=" * 50)
    detailed_report.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    detailed_report.append(f"è¯„ä¼°æ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è¯Šæ–­æ ‡å‡†")
    detailed_report.append(f"å‚è€ƒå·¥å…·: CARS, ABC, SCQ, M-CHATé‡è¡¨")
    detailed_report.append("")
    
    # æ·»åŠ ä¸´åºŠè¯„ä¼°æ¦‚å†µ
    detailed_report.append("ä¸€ã€ä¸´åºŠè¯„ä¼°æ¦‚å†µ")
    detailed_report.append("-" * 30)
    for key, value in analysis.get('ä¸´åºŠè¯„ä¼°æ¦‚å†µ', {}).items():
        detailed_report.append(f"{key}: {value}")
    detailed_report.append("")
    
    # æ·»åŠ æ•´ä½“è¡¨ç°
    detailed_report.append("äºŒã€æ•´ä½“ä¸´åºŠè¡¨ç°")
    detailed_report.append("-" * 30)
    for key, value in analysis.get('æ•´ä½“ä¸´åºŠè¡¨ç°', {}).items():
        detailed_report.append(f"{key}: {value}")
    detailed_report.append("")
    
    # æ·»åŠ ä¸¥é‡ç¨‹åº¦åˆ†æ
    if analysis.get('ä¸¥é‡ç¨‹åº¦åˆ†æ'):
        detailed_report.append("ä¸‰ã€ä¸¥é‡ç¨‹åº¦ç»„é—´åˆ†æ")
        detailed_report.append("-" * 30)
        for severity, stats in analysis['ä¸¥é‡ç¨‹åº¦åˆ†æ'].items():
            detailed_report.append(f"\n{severity} (n={stats['è¯„ä¼°æ¬¡æ•°']}):")
            detailed_report.append(f"  - ç¤¾äº¤äº’åŠ¨ç¼ºé™·: {stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_å‡å€¼']:.2f} Â± {stats['ç¤¾äº¤äº’åŠ¨å¾—åˆ†_æ ‡å‡†å·®']:.2f}")
            detailed_report.append(f"  - æ²Ÿé€šäº¤æµç¼ºé™·: {stats['æ²Ÿé€šäº¤æµå¾—åˆ†_å‡å€¼']:.2f} Â± {stats['æ²Ÿé€šäº¤æµå¾—åˆ†_æ ‡å‡†å·®']:.2f}")
            detailed_report.append(f"  - åˆ»æ¿é‡å¤è¡Œä¸º: {stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_å‡å€¼']:.2f} Â± {stats['åˆ»æ¿è¡Œä¸ºå¾—åˆ†_æ ‡å‡†å·®']:.2f}")
        detailed_report.append("")
    
    # æ·»åŠ ä¸´åºŠå‘ç°
    detailed_report.append("å››ã€ä¸´åºŠå‘ç°ä¸å»ºè®®")
    detailed_report.append("-" * 30)
    for i, finding in enumerate(analysis.get('ä¸´åºŠå‘ç°ä¸å»ºè®®', []), 1):
        detailed_report.append(f"{i}. {finding}")
    detailed_report.append("")
    
    # æ·»åŠ ä¸ªæ¡ˆæ˜ç»†
    detailed_report.append("äº”ã€ä¸ªæ¡ˆè¯„ä¼°æ˜ç»†")
    detailed_report.append("-" * 30)
    for i, record in enumerate(records, 1):
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                       record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                       record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        detailed_report.append(f"\nä¸ªæ¡ˆ {i}: {record['experiment_id']}")
        detailed_report.append(f"  è¯„ä¼°æ—¶é—´: {record['timestamp'].strftime('%Y-%m-%d %H:%M')}")
        detailed_report.append(f"  ä¸¥é‡ç¨‹åº¦: {record.get('template', 'è‡ªå®šä¹‰')}")
        detailed_report.append(f"  è¯„ä¼°æƒ…å¢ƒ: {record['scene']}")
        detailed_report.append(f"  æ ¸å¿ƒç—‡çŠ¶ç»¼åˆ: {core_severity:.2f}/5.0")
        
        severity_level = "è½»åº¦" if core_severity < 2.5 else "ä¸­åº¦" if core_severity < 3.5 else "é‡åº¦"
        detailed_report.append(f"  ä¸¥é‡ç¨‹åº¦åˆ¤æ–­: {severity_level}")
    
    return detailed_report


def create_research_package(records):
    """åˆ›å»ºç ”ç©¶æ•°æ®åŒ…"""
    # ç”Ÿæˆåˆ†æ
    analysis = generate_clinical_analysis(records)
    
    # å‡†å¤‡å„ç§æ ¼å¼çš„æ•°æ®
    files_dict = {}
    
    # 1. åŸºç¡€å‘å±•æ•°æ®CSV
    export_data = prepare_clinical_export_data(records)
    files_dict["01_åŸºç¡€è¯„ä¼°æ•°æ®.csv"] = export_to_csv(export_data)
    
    # 2. ä¸“ä¸šåˆ†ææŠ¥å‘Š
    if EXCEL_AVAILABLE:
        excel_data = create_clinical_excel_report(records, analysis)
        if excel_data:
            files_dict["02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx"] = excel_data
    
    if "02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx" not in files_dict:
        # Excelä¸å¯ç”¨æ—¶çš„æ–‡æœ¬æŠ¥å‘Š
        detailed_report = create_detailed_text_report(records, analysis)
        files_dict["02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt"] = '\n'.join(detailed_report)
    
    # 3. å®Œæ•´ç ”ç©¶æ•°æ®JSON
    complete_data = create_complete_json_data(records)
    files_dict["03_å®Œæ•´ç ”ç©¶æ•°æ®.json"] = export_to_json(complete_data)
    
    # 4. è¡Œä¸ºè§‚å¯Ÿè®°å½•
    observation_content = create_observation_text(records)
    files_dict["04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt"] = '\n'.join(observation_content)
    
    # 5. READMEæ–‡ä»¶
    readme_content = create_readme_content(records, EXCEL_AVAILABLE)
    files_dict["README.txt"] = readme_content
    
    return create_zip_package(files_dict)


def create_readme_content(records, excel_available):
    """åˆ›å»ºREADMEå†…å®¹"""
    readme_content = f"""
å­¤ç‹¬ç—‡å„¿ç«¥AIæ¨¡æ‹Ÿå®éªŒå¹³å° - åŒ»å­¦æ ‡å‡†ç‰ˆ
ç ”ç©¶æ•°æ®åŒ…è¯´æ˜æ–‡æ¡£
======================================

ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
è¯„ä¼°è®°å½•æ•°: {len(records)}
è¯„ä¼°æ ‡å‡†: DSM-5å­¤ç‹¬ç—‡è°±ç³»éšœç¢è¯Šæ–­æ ‡å‡†

æ–‡ä»¶è¯´æ˜:
--------
1. 01_åŸºç¡€è¯„ä¼°æ•°æ®.csv
   - åŒ…å«æ‰€æœ‰è¯„ä¼°çš„æ ¸å¿ƒæ•°æ®
   - é€‚ç”¨äºç»Ÿè®¡åˆ†æå’Œæ•°æ®å¯è§†åŒ–
   - åŒ…å«DSM-5ç‰¹å¾é…ç½®å’Œè¯„ä¼°å¾—åˆ†

"""
    if excel_available:
        readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.xlsx
   - å¤šå·¥ä½œè¡¨Excelä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æã€å›¾è¡¨å’Œä¸´åºŠè§£é‡Š
   - é€‚ç”¨äºä¸´åºŠæŠ¥å‘Šå’Œå­¦æœ¯ç ”ç©¶
"""
    else:
        readme_content += """2. 02_ä¸“ä¸šåˆ†ææŠ¥å‘Š.txt
   - è¯¦ç»†çš„æ–‡æœ¬æ ¼å¼ä¸“ä¸šæŠ¥å‘Š
   - åŒ…å«ç»Ÿè®¡åˆ†æå’Œä¸´åºŠè§£é‡Š
   - æ³¨æ„: ExcelåŠŸèƒ½ä¸å¯ç”¨ï¼Œå¦‚éœ€Excelæ ¼å¼è¯·å®‰è£…openpyxl
"""

    readme_content += """
3. 03_å®Œæ•´ç ”ç©¶æ•°æ®.json
   - åŒ…å«æ‰€æœ‰åŸå§‹æ•°æ®å’Œå…ƒæ•°æ®
   - é€‚ç”¨äºç¨‹åºå¤„ç†å’Œæ·±åº¦åˆ†æ
   - åŒ…å«å®Œæ•´çš„ä¸´åºŠè§‚å¯Ÿè®°å½•

4. 04_è¡Œä¸ºè§‚å¯Ÿè®°å½•.txt
   - æ‰€æœ‰è¯„ä¼°çš„å¯¹è¯è®°å½•
   - ç”¨äºè´¨æ€§åˆ†æå’Œè¡Œä¸ºæ¨¡å¼ç ”ç©¶
   - ç¬¦åˆä¸´åºŠè§‚å¯Ÿè®°å½•æ ¼å¼

5. README.txt
   - æœ¬è¯´æ˜æ–‡æ¡£

è¯„ä¼°æŒ‡æ ‡è¯´æ˜:
-----------
æ‰€æœ‰è¯„ä¼°å¾—åˆ†é‡‡ç”¨1-5åˆ†åˆ¶ï¼Œå…¶ä¸­:
- 1åˆ†: æ— æ˜æ˜¾é—®é¢˜/æ­£å¸¸èŒƒå›´
- 2åˆ†: è½»åº¦é—®é¢˜/éœ€è¦å…³æ³¨
- 3åˆ†: ä¸­åº¦é—®é¢˜/éœ€è¦æ”¯æŒ
- 4åˆ†: æ˜æ˜¾é—®é¢˜/éœ€è¦å¤§é‡æ”¯æŒ
- 5åˆ†: ä¸¥é‡é—®é¢˜/éœ€è¦éå¸¸å¤§é‡æ”¯æŒ

æ ¸å¿ƒç—‡çŠ¶è¯„ä¼°:
- ç¤¾äº¤äº’åŠ¨è´¨é‡: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Aæ¡ç›®
- æ²Ÿé€šäº¤æµèƒ½åŠ›: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Aæ¡ç›®
- åˆ»æ¿é‡å¤è¡Œä¸º: åŸºäºDSM-5è¯Šæ–­æ ‡å‡†Bæ¡ç›®

ç›¸å…³åŠŸèƒ½è¯„ä¼°:
- æ„Ÿå®˜å¤„ç†èƒ½åŠ›: æ„Ÿå®˜å¼‚å¸¸å’Œæ„Ÿå®˜å¯»æ±‚/é€ƒé¿è¡Œä¸º
- æƒ…ç»ªè¡Œä¸ºè°ƒèŠ‚: æƒ…ç»ªè¯†åˆ«ã€è¡¨è¾¾å’Œè°ƒèŠ‚èƒ½åŠ›
- è®¤çŸ¥é€‚åº”åŠŸèƒ½: å­¦ä¹ èƒ½åŠ›å’Œé€‚åº”æ€§è¡Œä¸º

ä½¿ç”¨å»ºè®®:
--------
1. ä¸´åºŠåº”ç”¨:
   - ä½¿ç”¨åŸºç¡€æ•°æ®è¿›è¡Œç­›æŸ¥å’Œè¯„ä¼°
   - å‚è€ƒä¸“ä¸šæŠ¥å‘Šåˆ¶å®šå¹²é¢„è®¡åˆ’
   - ç»“åˆè¡Œä¸ºè§‚å¯Ÿè¿›è¡Œä¸ªæ¡ˆåˆ†æ

2. ç ”ç©¶åº”ç”¨:
   - ä½¿ç”¨å®Œæ•´æ•°æ®è¿›è¡Œç»Ÿè®¡åˆ†æ
   - å¯¹ç…§ç»„ç ”ç©¶å’Œçºµå‘ç ”ç©¶
   - å¹²é¢„æ•ˆæœè¯„ä¼°

3. æ•™å­¦åº”ç”¨:
   - æ¡ˆä¾‹æ•™å­¦å’Œä¸´åºŠåŸ¹è®­
   - è¯„ä¼°å·¥å…·ä½¿ç”¨åŸ¹è®­
   - è¡Œä¸ºè§‚å¯ŸæŠ€èƒ½è®­ç»ƒ

æŠ€æœ¯æ”¯æŒ:
--------
- å¦‚éœ€ExcelåŠŸèƒ½ï¼Œè¯·å®‰è£…: pip install openpyxl
- æ•°æ®åˆ†æå»ºè®®ä½¿ç”¨: pandas, numpy, scipy
- å¯è§†åŒ–å»ºè®®ä½¿ç”¨: matplotlib, plotly

å‚è€ƒæ ‡å‡†:
--------
- American Psychiatric Association. (2013). DSM-5
- Childhood Autism Rating Scale (CARS)
- Autism Behavior Checklist (ABC)
- Social Communication Questionnaire (SCQ)
- Modified Checklist for Autism in Toddlers (M-CHAT)

è´¨é‡ä¿è¯:
--------
æœ¬å¹³å°åŸºäºæœ€æ–°çš„DSM-5è¯Šæ–­æ ‡å‡†å’Œæƒå¨è¯„ä¼°å·¥å…·è®¾è®¡ï¼Œ
æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡å‡å‚è€ƒå›½é™…è®¤å¯çš„å­¤ç‹¬ç—‡è¯„ä¼°é‡è¡¨ï¼Œ
ç¡®ä¿è¯„ä¼°ç»“æœçš„ä¸“ä¸šæ€§å’Œå¯é æ€§ã€‚

ç‰ˆæƒå£°æ˜:
--------
æœ¬æ•°æ®åŒ…ä»…ä¾›å­¦æœ¯ç ”ç©¶å’Œä¸´åºŠå®è·µä½¿ç”¨ï¼Œ
è¯·éµå¾ªç›¸å…³ä¼¦ç†è§„èŒƒå’Œæ•°æ®ä¿æŠ¤æ³•è§„ã€‚
"""
    return readme_content


def display_data_overview(records):
    """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡æ¦‚è§ˆ"""
    st.subheader("ğŸ“ˆ æ•°æ®ç»Ÿè®¡æ¦‚è§ˆ")
    
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
    
    with col_stat1:
        st.metric("ä¸´åºŠè¯„ä¼°æ€»æ•°", len(records))
    
    with col_stat2:
        severities = [r.get('template', 'è‡ªå®šä¹‰') for r in records]
        unique_severities = len(set(severities))
        st.metric("æ¶‰åŠä¸¥é‡ç¨‹åº¦ç±»å‹", unique_severities)
    
    with col_stat3:
        contexts = [r['scene'] for r in records]
        unique_contexts = len(set(contexts))
        st.metric("æ¶‰åŠè¯„ä¼°æƒ…å¢ƒ", unique_contexts)
    
    with col_stat4:
        if records:
            time_span = (max(r['timestamp'] for r in records) - min(r['timestamp'] for r in records)).days
            st.metric("è¯„ä¼°æ—¶é—´è·¨åº¦(å¤©)", time_span)


def display_data_preview(records):
    """æ˜¾ç¤ºæ•°æ®é¢„è§ˆ"""
    st.subheader("ğŸ“Š ä¸´åºŠæ•°æ®é¢„è§ˆ")
    
    preview_data = []
    for record in records[:10]:
        # è®¡ç®—æ ¸å¿ƒç—‡çŠ¶ä¸¥é‡åº¦
        core_severity = (record['evaluation_scores']['ç¤¾äº¤äº’åŠ¨è´¨é‡'] + 
                        record['evaluation_scores']['æ²Ÿé€šäº¤æµèƒ½åŠ›'] + 
                        record['evaluation_scores']['åˆ»æ¿é‡å¤è¡Œä¸º']) / 3
        
        severity_level = "è½»åº¦" if core_severity < 2.5 else "ä¸­åº¦" if core_severity < 3.5 else "é‡åº¦"
        
        preview_data.append({
            'è¯„ä¼°ID': record['experiment_id'][:25] + '...' if len(record['experiment_id']) > 25 else record['experiment_id'],
            'æ—¶é—´': record['timestamp'].strftime('%m-%d %H:%M'),
            'ä¸¥é‡ç¨‹åº¦': record.get('template', 'è‡ªå®šä¹‰')[:8] + '...' if len(record.get('template', 'è‡ªå®šä¹‰')) > 8 else record.get('template', 'è‡ªå®šä¹‰'),
            'è¯„ä¼°æƒ…å¢ƒ': record['scene'].replace('ç»“æ„åŒ–', 'ç»“æ„'),
            'æ ¸å¿ƒç—‡çŠ¶': f"{core_severity:.2f}",
            'ç¨‹åº¦åˆ¤æ–­': severity_level
        })
    
    df_preview = pd.DataFrame(preview_data)
    st.dataframe(df_preview, use_container_width=True)
    
    if len(records) > 10:
        st.info(f"æ˜¾ç¤ºå‰10æ¡è®°å½•ï¼Œå…±{len(records)}æ¡ã€‚å®Œæ•´æ•°æ®è¯·é€šè¿‡ä¸Šæ–¹ä¸‹è½½åŠŸèƒ½è·å–ã€‚")